# Create Assistant¬∂
We're about ready to create the graph. In the previous section, we made the design decision to have a shared messages state between all the nodes. This is powerful in that each delegated assistant can see the entire user journey and have a shared context. This, however, means that weaker LLMs can easily get mixed up about there specific scope. To mark the "handoff" between the primary assistant and one of the delegated workflows (and complete the tool call from the router), we will add a ToolMessage to the state.

# Utility¬∂
Create a function to make an "entry" node for each workflow, stating "the current assistant is assistant_name".

```python
from typing import Callable

from langchain_core.messages import ToolMessage


def create_entry_node(assistant_name: str, new_dialog_state: str) -> Callable:
    def entry_node(state: State) -> dict:
        tool_call_id = state["messages"][-1].tool_calls[0]["id"]
        return {
            "messages": [
                ToolMessage(
                    content=f"The assistant is now the {assistant_name}. Reflect on the above conversation between the host assistant and the user."
                    f" The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are {assistant_name},"
                    " and the booking, update, other other action is not complete until after you have successfully invoked the appropriate tool."
                    " If the user changes their mind or needs help for other tasks, call the CompleteOrEscalate function to let the primary host assistant take control."
                    " Do not mention who you are - just act as the proxy for the assistant.",
                    tool_call_id=tool_call_id,
                )
            ],
            "dialog_state": new_dialog_state,
        }

    return entry_node
API Reference: ToolMessage
```
# Define Graph¬∂
Now it's time to start building our graph. As before, we'll start with a node to pre-populate the state with the user's current information.

```python
from typing import Literal

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph
from langgraph.prebuilt import tools_condition

builder = StateGraph(State)


def user_info(state: State):
    return {"user_info": fetch_user_flight_information.invoke({})}


builder.add_node("fetch_user_info", user_info)
builder.add_edge(START, "fetch_user_info")
API Reference: MemorySaver | StateGraph | tools_condition

```

# üåü **Understanding Graph Creation in Conversational AI Systems**  

In this explanation, we'll break down the concept of **graph creation** in conversational AI using **LangGraph**, specifically focusing on how multiple assistants (or workflows) collaborate while sharing a unified state. We'll cover:  
- What graphs mean in this context.  
- Why sharing state is powerful but tricky.  
- How to create entry nodes for different assistants.  
- How to define the graph to handle user information and tool messages.  
- Real-world examples of where this concept is used.  

We'll break it all down step by step, with simple explanations and examples. Let‚Äôs get started! üöÄ  

---

## üîó **What Is a Graph in Conversational AI?**  

In conversational AI systems, a **graph** represents the **flow of conversation** between the user and the AI, showing how the AI processes requests step by step.  
- Each **node** in the graph represents a particular action or assistant.  
- The **edges** represent the flow from one action to another.  

### ‚úÖ **Example:**  
Imagine you‚Äôre chatting with an airline's virtual assistant to:  
1. Check flight details.  
2. Update your booking.  
3. Request a refund.  

Each task would be handled by a different **assistant**, but they need to **share information** about your journey. The graph ensures that when you switch from one task to another, the conversation **flows smoothly** without repeating information.  

---

## üí° **Why Share a Common Messages State?**  

The design choice made here is to have a **shared messages state** between all the assistants.  

### üéØ **What Does This Mean?**  
All the assistants can see the **entire conversation history**, so when you switch from one assistant to another, the new assistant knows:  
- What you already asked.  
- Which tasks are incomplete.  
- The current context of the conversation.  

### ‚ö° **Why Is This Powerful?**  
- **Seamless Experience:** The user doesn't have to repeat themselves.  
- **Context-Aware Responses:** Each assistant knows where the conversation left off.  

### ‚ö†Ô∏è **The Challenge:**  
Weaker AI models (**LLMs**) might get **confused** because they see **everything** and might forget their **specific role**.  

### üîÑ **Solution:**  
We introduce a **ToolMessage** to **clearly indicate** when one assistant hands over the conversation to another.  

---

## üõ†Ô∏è **Creating an Entry Node for Each Assistant**  

To avoid confusion between different assistants, we create an **entry node**.  
- An **entry node** marks when the **primary assistant** hands over the task to a **specific assistant**.  
- It ensures the new assistant knows its **exact responsibility** in the conversation.  

### üíª **Code Explanation:**  

```python
from typing import Callable
from langchain_core.messages import ToolMessage

def create_entry_node(assistant_name: str, new_dialog_state: str) -> Callable:
    def entry_node(state: State) -> dict:
        tool_call_id = state["messages"][-1].tool_calls[0]["id"]
        return {
            "messages": [
                ToolMessage(
                    content=f"The assistant is now the {assistant_name}. Reflect on the above conversation between the host assistant and the user."
                    f" The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are {assistant_name},"
                    " and the booking, update, or other action is not complete until after you have successfully invoked the appropriate tool."
                    " If the user changes their mind, call the CompleteOrEscalate function to let the primary host assistant take control."
                    " Do not mention who you are - just act as the proxy for the assistant.",
                    tool_call_id=tool_call_id,
                )
            ],
            "dialog_state": new_dialog_state,
        }

    return entry_node
```

---

### üìù **Beginner-Friendly Explanation:**  
- **Function Purpose:** Creates a **node** (step) in the graph for each **assistant** when it takes over.  
- **`assistant_name`:** The name of the assistant (e.g., *FlightBookingAssistant*).  
- **`new_dialog_state`:** The updated state after the assistant takes over.  
- **`ToolMessage`:** A message saying, ‚ÄúHey, this assistant is now in charge!‚Äù It **does not tell the user** who the assistant is ‚Äî it just **acts** on the user‚Äôs request.  

### üéØ **Example:**  
You ask: *"I want to update my flight date."*  
- The **primary assistant** checks the request.  
- It realizes this is a **flight update task**, so it **hands over** to the **FlightUpdateAssistant** by calling this **entry node**, which gives the update assistant **full context** of the conversation.  

---

## üåê **Defining the Graph**  

Now that we have entry nodes for each assistant, we need to **build the entire conversation graph**.  
- The graph will show how the conversation **flows** from start to finish.  
- We will begin by **pre-populating** user information.  

### üíª **Code Explanation:**

```python
from typing import Literal
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph
from langgraph.prebuilt import tools_condition

builder = StateGraph(State)

def user_info(state: State):
    return {"user_info": fetch_user_flight_information.invoke({})}

builder.add_node("fetch_user_info", user_info)
builder.add_edge(START, "fetch_user_info")
```

---

### üìù **Beginner-Friendly Explanation:**  
- **`StateGraph`:** Creates a **graph** for conversation flow.  
- **`user_info` Function:**  
   - **Purpose:** Fetches the **user‚Äôs flight information** (like booking details, seat number, etc.).  
   - **Why?:** So any assistant working on a task **already knows** the user‚Äôs flight details.  
- **`add_node`:** Adds a **step** in the graph where **user information** is fetched.  
- **`add_edge`:** Connects the **start** of the conversation to this **fetch user info step**.  

### ‚úàÔ∏è **Real-World Example:**  
In an airline chatbot:  
- The **first step** is always to **fetch your flight information** after you say "Hi".  
- This way, no matter what you ask next‚Äî**changing flights**, **booking meals**, or **requesting upgrades**‚Äîthe assistant **already knows** your details.  

---

## üåü **Real-World Use Case: Airline Virtual Assistant**  

Imagine you are chatting with an airline's assistant:  
1. You say: *"I want to reschedule my flight."*  
2. The assistant checks your current flight details (**fetch_user_info node**).  
3. The **primary assistant** passes the task to the **FlightUpdateAssistant** (**entry node created using `create_entry_node`**).  
4. The **FlightUpdateAssistant** reschedules your flight and confirms the update.  
5. If you suddenly say: *"Actually, I want a refund instead,"* the assistant calls the **CompleteOrEscalate function** to let the **primary assistant** take control and pass the task to the **RefundAssistant**.  

### üéØ **Why This Matters:**  
This graph ensures:  
- ‚úÖ No repeated questions.  
- ‚úÖ Assistants know **exactly** what the user wants.  
- ‚úÖ Smooth handoffs between multiple assistants.  

---

## üéÅ **Key Takeaways**  
1. **Graph in Conversational AI**: Shows the flow of conversation between user and assistants.  
2. **Shared State**: All assistants share conversation history for seamless experiences.  
3. **Entry Node**: Marks handover between assistants so each assistant knows its role.  
4. **ToolMessage**: A special message signaling an assistant switch without confusing the user.  
5. **Graph Definition**: Shows how conversations progress step by step, fetching user info first.  

---

## üéâ **Conclusion**  
By structuring conversations as a **graph** and using techniques like **ToolMessage** and **entry nodes**, we create powerful AI assistants capable of handling complex user journeys without losing context.  

This approach is used in:  
- ‚úàÔ∏è **Airline booking assistants**  
- üè® **Hotel reservation systems**  
- üõí **E-commerce chatbots**  
- üí≥ **Banking virtual assistants**  

All these applications require **smooth handoffs** between various tasks while keeping the **user experience simple and intuitive**. üåü

# Another gpt Response:
# ü§ñ Creating a Shared Assistant Graph with Clear Handoffs

In this section, we learn how to create a **graph-based workflow** for a multi-agent chatbot. This approach uses a **shared messages state** so that every delegated assistant (or sub-agent) can see the entire conversation history. However, sharing all context can sometimes confuse weaker language models, especially when switching tasks. To prevent this, we insert a **"handoff" message** (a ToolMessage) into the state that clearly indicates which specialized assistant should take over.

This technique is especially useful in systems like travel booking assistants, where a **primary assistant** handles general queries, and specialized assistants (flight booking, hotel booking, etc.) take over when needed.

---

## üìå Key Concepts

### 1Ô∏è‚É£ **Shared Messages State**  
- **What it is:** A state that holds the complete conversation history.
- **Why it's useful:**  
  - Every assistant sees the full dialogue context.
  - It helps maintain continuity between different workflows.

### 2Ô∏è‚É£ **Handoff with ToolMessage**  
- **What it is:** A message inserted into the state that signals the transition from the primary assistant to a specialized assistant.
- **Why it's important:**  
  - It prevents confusion by clearly marking the start of a new, focused workflow.
  - It tells the new assistant, _"You are now in charge, and here's the context so far."_ 

### 3Ô∏è‚É£ **Entry Node Function**  
- **Purpose:**  
  - Acts as the first step in each specialized workflow.
  - Updates the dialogue state and adds a message indicating which assistant is now active.
  
---

## üîß Code Walkthrough

Let's break down the code step by step.

### üìù **Utility Function: `create_entry_node`**

This function creates an **entry node** for a specialized assistant. It injects a `ToolMessage` into the shared state to mark the handoff.

```python
from typing import Callable
from langchain_core.messages import ToolMessage

def create_entry_node(assistant_name: str, new_dialog_state: str) -> Callable:
    def entry_node(state: State) -> dict:
        # Retrieve the ID of the latest tool call from the last message in the state.
        tool_call_id = state["messages"][-1].tool_calls[0]["id"]
        # Create a new ToolMessage that indicates a handoff to a specialized assistant.
        return {
            "messages": [
                ToolMessage(
                    content=f"The assistant is now the {assistant_name}. Reflect on the above conversation between the host assistant and the user."
                            f" The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are {assistant_name},"
                            " and the booking, update, other other action is not complete until after you have successfully invoked the appropriate tool."
                            " If the user changes their mind or needs help for other tasks, call the CompleteOrEscalate function to let the primary host assistant take control."
                            " Do not mention who you are - just act as the proxy for the assistant.",
                    tool_call_id=tool_call_id,  # Link the message to the existing tool call.
                )
            ],
            "dialog_state": new_dialog_state,  # Update the dialogue state to the new specialized workflow.
        }
    return entry_node
```

#### üîç **Explanation:**

- **Function Signature:**  
  `create_entry_node(assistant_name: str, new_dialog_state: str)` returns a callable function.
  
- **Inside `entry_node`:**  
  - **Retrieve `tool_call_id`:**  
    - Accesses the most recent tool call ID from the shared state. This ties the handoff to the current conversation.
  - **Create `ToolMessage`:**  
    - The message content clearly informs that the active assistant is now `assistant_name`.
    - It instructs the new assistant to use its own tools to complete the task and to escalate back if needed.
  - **Update `dialog_state`:**  
    - Sets the new dialogue state so the system knows which specialized workflow is active.
    
- **Return:**  
  - The function returns a dictionary with updated messages and dialogue state.

---

## üåê **Defining the Graph**

After creating our entry node, we start building the overall conversation graph.

```python
from typing import Literal
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph
from langgraph.prebuilt import tools_condition

# Initialize the graph with the shared State type.
builder = StateGraph(State)

# Define a function to fetch user flight information.
def user_info(state: State):
    return {"user_info": fetch_user_flight_information.invoke({})}

# Add the node to fetch user info.
builder.add_node("fetch_user_info", user_info)
# Connect the start of the conversation to the user info node.
builder.add_edge(START, "fetch_user_info")
```

#### üîç **Explanation:**

- **`StateGraph(State)`:**  
  - Initializes a graph that uses our shared `State` structure.
  
- **User Information Node (`user_info`):**  
  - This function populates the state with current flight information by calling `fetch_user_flight_information.invoke({})`.
  - It ensures the assistant has up-to-date context before any further processing.

- **Adding Nodes and Edges:**
  - `builder.add_node("fetch_user_info", user_info)`  
    - Adds a node named `"fetch_user_info"` to the graph.
  - `builder.add_edge(START, "fetch_user_info")`  
    - Connects the start of the graph to the `"fetch_user_info"` node, ensuring that the conversation begins by gathering necessary user data.

---

## üèõÔ∏è **Real-World Example**

Imagine you are using a **travel booking assistant**:
- **Scenario:**  
  - You start a conversation with the primary assistant.
  - The assistant fetches your flight details (using the `user_info` node).
  - When you request to update your booking, the system inserts a handoff message using `create_entry_node`, which clearly signals, "The assistant is now the Flight Booking Assistant."
  - This ensures that the flight booking assistant receives the complete conversation context and knows it is now in charge of updating your flight booking.

This mechanism prevents confusion by:
- **Marking clear transitions** between different assistants.
- Allowing each specialized assistant to focus solely on its domain without interference from unrelated parts of the conversation.

---

## üéØ **Summary**

- **Shared State:**  
  - Keeps the full conversation context accessible to all assistants.
  
- **Handoff via ToolMessage:**  
  - Injects a clear marker into the conversation when switching from the primary assistant to a specialized one.
  
- **Graph Definition:**  
  - Sets up the conversation flow starting with user information retrieval.
  
- **Real-World Application:**  
  - Ensures seamless transitions in a travel booking system where different tasks (flight booking, hotel booking, etc.) are handled by domain-specific assistants.

By using this approach, we create a robust, modular, and clear workflow that enhances both the efficiency of the assistant and the user experience.