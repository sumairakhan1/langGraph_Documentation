Here’s a detailed, beginner-friendly explanation of **how to add a summary of conversation history in a chatbot**, including real-world applications, code breakdown, and examples.

---

# 📝 How to Add a Summary of Conversation History in a Chatbot  

## 🎯 **Why Do We Need Conversation Summarization?**  

When building AI chatbots, we often **store conversation history** to provide context-aware responses. However, if the conversation gets too long, it can:  

✅ Take up too much memory 💾  
✅ Make responses slower ⏳  
✅ Increase API costs 💰  

A great **solution** is to **summarize** older messages instead of keeping them all. This way, the chatbot remembers the conversation but uses less memory and keeps responses fast.

---

## 🌍 **Real-World Use Cases**  

🔹 **Customer Support Bots** – Summarizing past chat history helps agents quickly understand a user's issue without reading a long conversation.  
🔹 **AI Assistants** – AI like ChatGPT or Siri can remember key details instead of storing every word.  
🔹 **Medical Chatbots** – Doctors using AI-based assistants can get a **summary** of a patient's previous symptoms instead of scrolling through all messages.  

---

## ⚙️ **Steps to Implement Conversation Summarization**  

### 📌 **1. Check if Conversation is Too Long**  
   - We can do this by **counting the number of messages**.  

### 📌 **2. Summarize the Conversation**  
   - If the conversation is too long, use an **LLM (Large Language Model) like Anthropic Claude** to generate a **short summary**.  

### 📌 **3. Keep Only Recent Messages**  
   - **Delete** all messages except the last few, and store the summary instead.  

---

## 🛠 **Setting Up the Project**  

### **🔗 Install Required Packages**  

We need **LangGraph** and **LangChain-Anthropic** to build the chatbot.  

```python
%%capture --no-stderr
%pip install --quiet -U langgraph langchain_anthropic
```

### **🔐 Set API Keys**  

We need an **Anthropic API key** to use Claude AI for summarization.  

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("ANTHROPIC_API_KEY")
```

---

## 🤖 **Building the Chatbot with Conversation Summarization**  

### **1️⃣ Define the State of the Conversation**  

We create a **State class** that stores:  
✅ **messages** – Stores conversation history.  
✅ **summary** – Stores the generated summary.  

```python
from langgraph.graph import MessagesState

# Define State to hold messages and summary
class State(MessagesState):
    summary: str  # Store conversation summary
```

---

### **2️⃣ Define the Chatbot Model**  

We use the **Claude-3 Haiku model** from Anthropic.  

```python
from langchain_anthropic import ChatAnthropic

# Define the AI model for responses
model = ChatAnthropic(model_name="claude-3-haiku-20240307")
```

---

### **3️⃣ Define the Logic to Generate Responses**  

We modify the chatbot’s response based on whether a summary exists.

```python
from langchain_core.messages import SystemMessage

def call_model(state: State):
    summary = state.get("summary", "")
    
    # If a summary exists, include it in system messages
    if summary:
        system_message = SystemMessage(content=f"Summary of conversation earlier: {summary}")
        messages = [system_message] + state["messages"]
    else:
        messages = state["messages"]

    response = model.invoke(messages)
    return {"messages": [response]}
```

**💡 Explanation:**  
- If a summary **already exists**, we add it as a **SystemMessage** before new messages.  
- Then, we **send the updated conversation** to the AI model and get a response.  

---

### **4️⃣ Check if Summarization is Needed**  

We check if there are **more than 6 messages**.  

```python
from typing import Literal

def should_continue(state: State) -> Literal["summarize_conversation", "END"]:
    messages = state["messages"]

    # If more than 6 messages, summarize conversation
    if len(messages) > 6:
        return "summarize_conversation"
    
    return "END"
```

---

### **5️⃣ Generate a Conversation Summary**  

We summarize the conversation and **keep only the last two messages**.  

```python
from langchain_core.messages import HumanMessage, RemoveMessage

def summarize_conversation(state: State):
    summary = state.get("summary", "")

    # Use a different prompt if a summary already exists
    summary_prompt = (
        f"This is the summary so far: {summary}\n\nExtend the summary with new messages:"
        if summary else "Create a summary of the conversation above:"
    )

    # Add the summary request to conversation
    messages = state["messages"] + [HumanMessage(content=summary_prompt)]
    response = model.invoke(messages)

    # Keep only last two messages and delete older ones
    delete_messages = [RemoveMessage(id=m.id) for m in state["messages"][:-2]]

    return {"summary": response.content, "messages": delete_messages}
```

**💡 Explanation:**  
- If a summary already exists, we **extend** it.  
- Otherwise, we create a **new** summary.  
- We **delete old messages** except for the **last two**.  

---

## 🔄 **Building the Conversation Flow with LangGraph**  

### **1️⃣ Define a Graph for the Chatbot**  

```python
from langgraph.graph import StateGraph, START, END

workflow = StateGraph(State)

# Define conversation and summarization nodes
workflow.add_node("conversation", call_model)
workflow.add_node("summarize_conversation", summarize_conversation)

# Set entry point as 'conversation'
workflow.add_edge(START, "conversation")

# Add condition to check when to summarize
workflow.add_conditional_edges(
    "conversation", should_continue
)

# End conversation after summarization
workflow.add_edge("summarize_conversation", END)

# Compile the workflow
app = workflow.compile()
```

**💡 Explanation:**  
- We define **nodes** for normal conversation and summarization.  
- The chatbot starts with **"conversation"**.  
- If messages exceed 6, it moves to **"summarize_conversation"**.  
- Then, it **ends** the flow.  

---

## 🚀 **Testing the Chatbot**  

Let's **simulate** a conversation.

```python
def print_update(update):
    for k, v in update.items():
        for m in v["messages"]:
            print(m.content)
        if "summary" in v:
            print("📝 Summary:", v["summary"])

from langchain_core.messages import HumanMessage

# Start conversation
config = {"configurable": {"thread_id": "1"}}
input_message = HumanMessage(content="Hi! I'm Alice")
for event in app.stream({"messages": [input_message]}, config, stream_mode="updates"):
    print_update(event)

input_message = HumanMessage(content="What's my name?")
for event in app.stream({"messages": [input_message]}, config, stream_mode="updates"):
    print_update(event)

input_message = HumanMessage(content="Tell me a joke!")
for event in app.stream({"messages": [input_message]}, config, stream_mode="updates"):
    print_update(event)
```

---

## 🎯 **Key Takeaways**  

✅ **Conversation history can become too long, leading to higher costs and slow responses.**  
✅ **Summarizing past messages allows the chatbot to "remember" without storing everything.**  
✅ **LangChain + LangGraph make it easy to implement chatbots with smart memory.**  

---

## 🎯 **Final Thoughts**  

Adding a **conversation summary** is a **powerful optimization** for chatbots, making them **smarter and more efficient**. Whether you're building an AI assistant, a customer service bot, or a medical chatbot, this technique **helps keep responses relevant without storing too much data**.

Would you like to add any **custom features** like **user-specific memory** or **timestamp-based deletion**? 🚀