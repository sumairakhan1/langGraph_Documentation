# 4. How to stream events


# How to Stream Events in LangGraph

Event streaming is a powerful technique used in software applications to continuously receive and process data in real-time. In this guide, we'll explore how to stream events using LangGraph, a tool that supports this functionality. This method is useful when you want to receive continuous updates, such as new data being added to your application or receiving notifications of specific changes.

## üìù Prerequisites

Before you start streaming events, ensure you have the following:

- **LangGraph SDK**: A software development kit (SDK) that provides the necessary tools to interact with the LangGraph service.
- **Python, Javascript, or CURL**: You can use any of these languages to interact with the LangGraph API and stream events.

---

## üöÄ Setup for Streaming Events

### Python Setup Example
To begin streaming events, you must first set up a connection to your LangGraph instance by using the SDK. Here's how you can do that in Python:

```python
from langgraph_sdk import get_client

client = get_client(url=<DEPLOYMENT_URL>)  # Replace with your deployment URL
assistant_id = "agent"  # The assistant you want to interact with

# Create a new thread for communication
thread = await client.threads.create()
print(thread)
```

**Output:**

```json
{
    "thread_id": "3f4c64e0-f792-4a5e-aa07-a4404e06e0bd",
    "created_at": "2024-06-24T22:16:29.301522+00:00",
    "status": "idle"
}
```

This creates a "thread" that will be used to send and receive messages. 

---

## üîÑ Stream Graph in Events Mode

Now that your setup is ready, you can start streaming events from your graph. This means you will continuously receive updates in real-time as new events occur. The events can contain various data, such as metadata or specific responses based on your inputs.

### Python Example for Streaming Events

Here's an example of how to send a request and stream events using Python:

```python
input = {
    "messages": [
        {
            "role": "user",
            "content": "What's the weather in SF?",
        }
    ]
}

# Stream events from the LangGraph API
async for chunk in client.runs.stream(
    thread_id=thread["thread_id"],
    assistant_id=assistant_id,
    input=input,
    stream_mode="events",
):
    print(f"Receiving new event of type: {chunk.event}...")
    print(chunk.data)
```

**Example Output:**

```json
Receiving new event of type: metadata...
{'run_id': '1ef301a5-b867-67de-9e9e-a32e53c5b1f8'}

Receiving new event of type: events...
{'event': 'on_chain_start', 'data': {'input': {'messages': [{'role': 'human', 'content': "What's the weather in SF?"}]}}}
```

In this example, you send a question asking for the weather in San Francisco, and the application streams various events as it processes the question.

---

## üß© Key Event Types

When you stream events, the system provides different types of events that indicate the progress or stages of processing. Here are some of the most common event types you will encounter:

- **metadata**: This event type contains metadata related to the current processing state.
- **on_chain_start**: This event is triggered when a new process (or chain) begins.
- **on_chat_model_start**: This event is triggered when the chat model starts processing.
- **on_chat_model_stream**: This event streams chunks of data from the model, such as individual characters or words being processed.

### Example of Streaming a Response

```json
{
    'event': 'on_chat_model_stream',
    'data': {
        'chunk': {
            'content': 'b',
            'type': 'AIMessageChunk',
            'name': None,
            'id': 'run-cb1b98c1-c9e2-4a30-9d7a-38fa1f6224bd'
        }
    }
}
```

As you can see in this output, the system streams the response in pieces, in this case, the letter `'b'`. This allows you to build real-time responses and display them progressively, as they are being generated.

---

## üåç Real-World Example: Customer Support Chatbot

Streaming events can be used effectively in a **customer support chatbot**. In this scenario, when a customer asks a question (e.g., "What's the status of my order?"), the system can stream events as it processes the request and generates a response.

### Example:

1. **Customer sends a question**: "What‚Äôs the status of my order?"
2. **Bot processes the request**: The chatbot might break the processing down into smaller chunks, such as verifying the order details, checking the shipping status, etc.
3. **Real-time event stream**: As the bot gathers the necessary data, it streams events back to the user in real-time, such as "Verifying order status..." or "Fetching shipping info...".
4. **Final response**: The bot then sends the final status update, such as "Your order is on its way and will be delivered tomorrow!"

---

## ‚öôÔ∏è Conclusion

Streaming events is a powerful tool that enables your application to process and return data in real-time. It is especially useful in interactive applications like chatbots, notifications, and real-time analytics. By using the LangGraph SDK, you can easily set up event streaming and manage complex processes in a simple, manageable way.

This approach can be extended to numerous real-world applications, from customer service automation to interactive user experiences where timely updates are crucial.