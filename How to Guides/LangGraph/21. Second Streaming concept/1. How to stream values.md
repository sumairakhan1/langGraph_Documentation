# 1. How to stream values

# How to Stream Full State of Your Graph üìä

### Introduction: Streaming Graphs üåê

In this guide, we will explore how to stream the full state of your graph in a system, specifically focusing on the **`stream_mode="values"`** feature. This feature allows you to stream the entire state of the graph at each **superstep**, which means you get the complete data of the graph at any given point, not just the updates from individual nodes.

Before diving into how this works, it's important to understand some basic concepts and set up the necessary environment.

---

### Prerequisites: Setting Up Your Environment üîß

To get started with streaming your graph, you need to set up a few components. Here's the basic setup for a **Python** environment using a client to interact with the graph. You can replace the `<DEPLOYMENT_URL>` with the URL of your deployed graph service.

```python
from langgraph_sdk import get_client

client = get_client(url=<DEPLOYMENT_URL>)  # Connect to the deployed graph
assistant_id = "agent"  # Your agent's name in the graph

# Create a new thread (session) to interact with the graph
thread = await client.threads.create()
print(thread)
```

This will output something like the following, confirming the successful creation of a thread (session) to interact with your graph:

```json
{
  "thread_id": "bfc68029-1f7b-400f-beab-6f9032a52da4",
  "status": "idle",
  "config": {},
  "values": null
}
```

---

### Stream Graph in Values Mode üñ•Ô∏è

Now that we have set up the environment, let‚Äôs focus on streaming the full graph state at each superstep. In the **"values"** mode, instead of receiving updates from individual nodes, we get the entire state of the graph. This is especially useful when you want to see the entire state of the graph after every node completes its task.

Here's how to do it:

```python
input = {"messages": [{"role": "user", "content": "what's the weather in la"}]}  # Sample input for the graph

# Streaming the values
async for chunk in client.runs.stream(
    thread["thread_id"],  # The thread ID created earlier
    assistant_id,
    input=input,  # The input provided to the graph
    stream_mode="values"  # This is the key part that enables values streaming
):
    print(f"Receiving new event of type: {chunk.event}...")
    print(chunk.data)
    print("\n\n")
```

### Sample Output:

When streaming in **values** mode, you‚Äôll receive multiple events that show the state of the graph:

```json
Receiving new event of type: metadata...
{"run_id": "f08791ce-0a3d-44e0-836c-ff62cd2e2786"}

Receiving new event of type: values...
{
  "messages": [
    {
      "role": "human",
      "content": "what's the weather in la"
    }
  ]
}

Receiving new event of type: values...
{
  "messages": [
    {
      "content": "what's the weather in la",
      "type": "human",
      ...
    },
    {
      "content": "",
      "type": "ai",
      "tool_calls": [
        {
          "name": "tavily_search_results_json",
          "args": {
            "query": "weather in los angeles"
          },
          "id": "toolu_01E5mSaZWm5rWJnCqmt63v4g"
        }
      ],
      ...
    }
  ]
}
```

You can see that the `values` event returns the full state after each superstep, including the user's input and the AI's response along with tool calls to fetch weather data.

---

### Final Answer Stream Example üí¨

If you just want to receive the final result and not all intermediate states, you can filter out the unnecessary data and focus on the final answer like this:

```python
final_answer = None
async for chunk in client.runs.stream(
    thread["thread_id"],
    assistant_id,
    input=input,
    stream_mode="values"
):
    if chunk.event == "values":
        final_answer = chunk.data  # Capture the final answer
```

### Sample Final Output:

Here‚Äôs what the final output might look like once the complete process finishes:

```json
{
  "messages": [
    {
      "content": "what's the weather in la",
      "type": "human",
      ...
    },
    {
      "type": "ai",
      "tool_calls": [
        {
          "name": "tavily_search_results_json",
          "args": {
            "query": "weather in los angeles"
          },
          "id": "toolu_01E5mSaZWm5rWJnCqmt63v4g"
        }
      ],
      ...
    },
    {
      "content": "Based on the weather API results, the current weather in Los Angeles is overcast with a temperature of around 62¬∞F (17¬∞C). There are light winds from the west-southwest around 8-13 mph. The humidity is 65% and visibility is good at 9 miles. Overall, mild spring weather conditions in LA.",
      "type": "ai",
      ...
    }
  ]
}
```

This gives you the complete output, which includes both the user's query and the AI's response, along with any relevant tool calls and data fetching results.

---

### Real-World Use Case üåç

**Streaming Full Graph States** is particularly useful in systems where you need to track the entire evolution of data over time or ensure that you have complete visibility into a process. A real-world example of this could be:

#### **Customer Support Chatbots** üí¨
Imagine a customer service chatbot that answers customer queries by fetching data from various sources (weather, product availability, etc.). By using **stream_mode="values"**, you can monitor the entire conversation state, including the user‚Äôs question, the system's intermediate steps (e.g., fetching data), and the final response. This allows for real-time updates and ensures that the support team can view the entire context of a conversation as it progresses.

This could be extremely beneficial in use cases such as:
- **E-commerce support**: where a customer might ask for product recommendations and the AI fetches live data to give a relevant suggestion.
- **Travel industry**: providing up-to-date information on flights, weather, and hotel availability.

---

### Conclusion üéØ

By using **stream_mode="values"**, you can track the full state of your graph in real-time, receiving complete information at each step. This is different from **stream_mode="updates"**, which only gives you the changes, allowing for more detailed insights and analysis of how the graph evolves.

This method is applicable in scenarios where understanding the entire process flow is critical, such as customer service, data analysis, or complex decision-making systems.