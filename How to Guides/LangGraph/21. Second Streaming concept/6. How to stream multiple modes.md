# How to stream multiple modes

# How to Configure Multiple Streaming Modes at the Same Time 📡

In many real-world applications, you may need to stream data from a service while receiving multiple types of information simultaneously. This guide explains how to configure multiple streaming modes at the same time using the `LangGraph` SDK. Let's break it down into simple steps with explanations and real-world examples.

## Prerequisites for Streaming 🧑‍💻

Before diving into the setup, you need the following:

- **LangGraph SDK**: A software development kit that allows you to interact with a graph system for streaming data.
- **Client Setup**: You'll need to set up your client to connect to the graph deployment.
- **Thread Management**: A thread is where your requests will be processed, and each thread can contain multiple messages or tasks.

---

## Setting Up Your Client and Thread 🔧

### Step 1: Setting up the client and thread
In this example, we are using Python to set up the client and the thread.

```python
from langgraph_sdk import get_client

client = get_client(url=<DEPLOYMENT_URL>)  # Connect to the graph deployment
assistant_id = "agent"  # Use the deployed agent's name
# Create a new thread to handle the streaming request
thread = await client.threads.create()
print(thread)
```

This will create a connection to the graph system, identify the agent you're interacting with, and create a thread to process incoming requests. The output will show the thread details, including its ID and status.

---

## Stream Graph with Multiple Modes 📡

When working with multiple streaming modes, the system can produce different types of events, such as **messages**, **events**, and **debug**. Each of these types provides different information at different stages of the process.

### Step 2: Define your input
You need to define the input message that will be streamed. For example, let's send a request asking for the weather:

```python
input = {
    "messages": [
        {
            "role": "user",
            "content": "What's the weather in SF?",
        }
    ]
}
```

### Step 3: Start Streaming with Multiple Modes 🚀

To stream with multiple modes, you specify them in the `stream_mode` parameter. The modes could be:

- **Messages**: The actual content you send or receive.
- **Events**: The status updates or actions performed by the system.
- **Debug**: Additional diagnostic information, like timestamps or internal states.

```python
# Start streaming with multiple modes
async for chunk in client.runs.stream(
    thread_id=thread["thread_id"],
    assistant_id=assistant_id,
    input=input,
    stream_mode=["messages", "events", "debug"],
):
    print(f"Receiving new event of type: {chunk.event}...")
    print(chunk.data)
    print("\n\n")
```

In this case, we’re asking for three types of events to be streamed: **messages**, **events**, and **debug**. Each type gives you different pieces of information about what’s happening with your request.

---

## Example of Output 📊

Here’s an example of what you might see in the output when using multiple streaming modes:

### 1. **Metadata Event**
This event shows metadata about the stream, such as run IDs and thread IDs.

```
Receiving new event of type: metadata...
{'run_id': '1ef32717-bc30-6cf2-8a26-33f63567bc25'}
```

### 2. **Event (on_chain_start)**
This event shows the start of the process, including input messages sent to the system.

```
Receiving new event of type: events...
{'event': 'on_chain_start', 'data': {'input': {'messages': [{'role': 'human', 'content': "What's the weather in SF?"}]}}}
```

### 3. **Debug Event**
This event gives detailed debug information, like the system's internal configuration and the step-by-step process of the request.

```
Receiving new event of type: debug...
{'type': 'checkpoint', 'timestamp': '2024-06-24T21:34:06.116009+00:00', 'step': -1, 'payload': {'config': {...}}}
```

---

## Real-World Use Case: Customer Support Bot 🤖

### Scenario
Imagine you’re building a **customer support chatbot** for an e-commerce website. The bot needs to handle various tasks such as answering user queries, tracking order statuses, and offering promotions.

By using multiple streaming modes, you can:

- **Messages**: Get responses like "Your order is on its way."
- **Events**: Get status updates like "User query received," or "Bot is processing."
- **Debug**: Gather system information for troubleshooting, such as timestamps and internal configurations.

This ensures that you have detailed insights at every stage of the interaction, making it easier to debug, improve, and provide an optimized user experience.

---

## Conclusion 🎯

Streaming with multiple modes is essential for receiving and processing complex data efficiently. Whether you're building chatbots, customer service tools, or real-time analytics systems, this concept ensures you get the right data at the right time.

- **Messages** give you the main content (e.g., user questions, bot responses).
- **Events** track system actions and progress.
- **Debug** provides diagnostics to fine-tune and troubleshoot the process.

By setting up your system to stream multiple modes at once, you can make your application more interactive, responsive, and robust.

# o3 mini
# How to Configure Multiple Streaming Modes at the Same Time 🎥🔀

When working with complex graph-based systems, you might want to receive different types of feedback from a single run. Configuring multiple streaming modes simultaneously lets you do just that—stream various types of events (like messages, events, and debug information) in parallel. This guide explains the concept step-by-step.

---

## What Is Streaming in This Context? 🌊

**Streaming** refers to receiving data incrementally, as it’s generated, rather than waiting for the entire process to complete. In our case, streaming modes allow you to observe different aspects of your graph’s execution:

- **Messages Mode:** Streams the actual output messages, like parts of a conversation.
- **Events Mode:** Streams operational events (e.g., when a task starts or finishes).
- **Debug Mode:** Streams detailed debug information, such as checkpoints, tasks, and task results.

By configuring multiple streaming modes at the same time, you can receive all these outputs concurrently, offering a comprehensive view of your graph’s performance and behavior.

---

## Prerequisites 🛠️

Before you begin, ensure you have:
- **Streaming enabled** in your LangGraph deployment.
- The appropriate SDK installed (e.g., LangGraph SDK for Python).
- Basic familiarity with asynchronous programming (if using Python’s `async` features).

---

## Setup: Connecting to Your Graph 🌐

First, set up your client and thread to connect to your deployed graph. Here's an example in Python:

```python
from langgraph_sdk import get_client

# Connect to your deployed graph instance
client = get_client(url=<DEPLOYMENT_URL>)

# Define the graph/agent you want to use
assistant_id = "agent"

# Create a new thread (session) for the execution
thread = await client.threads.create()
print(thread)
```

**Sample Output:**

```json
{
    "thread_id": "bfc68029-1f7b-400f-beab-6f9032a52da4",
    "created_at": "2024-06-24T21:30:07.980789+00:00",
    "status": "idle",
    "config": {},
    "values": null
}
```

This output confirms that your session is active and ready to stream data.

---

## Streaming with Multiple Modes 🔄

When you configure multiple streaming modes, you pass a list of modes to the `stream_mode` parameter. This instructs the system to produce outputs for each mode during a run.

### Code Example:

```python
# Define the input for the graph (e.g., a user query)
input = {
    "messages": [
        {
            "role": "user",
            "content": "What's the weather in SF?",
        }
    ]
}

# Stream events with multiple streaming modes: messages, events, and debug
async for chunk in client.runs.stream(
    thread_id=thread["thread_id"],
    assistant_id=assistant_id,
    input=input,
    stream_mode=["messages", "events", "debug"],
):
    print(f"Receiving new event of type: {chunk.event}...")
    print(chunk.data)
    print("\n\n")
```

### What Happens Here? 🤔

- **Multiple Modes Configured:**  
  By passing `["messages", "events", "debug"]` to the `stream_mode` parameter, the system will simultaneously stream:
  - **Messages:** Actual response data (e.g., the final answer or partial message chunks).
  - **Events:** Key events like starting or ending of tasks.
  - **Debug:** Detailed information including checkpoints, task initiation, and task results.

- **Comprehensive Output:**  
  The response contains several event types such as:
  - **metadata:** Basic run information.
  - **events:** For example, when the chain starts.
  - **debug:** Checkpoint events, task events, and task_result events.
  - **messages/complete, messages/metadata, messages/partial:** Detailed outputs from the chat model.

### Sample Output Explanation:

1. **Metadata Event:**  
   ```json
   {
       "run_id": "1ef32717-bc30-6cf2-8a26-33f63567bc25"
   }
   ```
   - Contains the run identifier and basic info.

2. **Events Mode Output:**  
   ```json
   {
       "event": "on_chain_start",
       "data": {
           "input": {
               "messages": [
                   {"role": "human", "content": "What's the weather in SF?"}
               ]
           }
       },
       "name": "LangGraph",
       ...
   }
   ```
   - Indicates that the graph execution chain has started.

3. **Debug Mode Output:**  
   ```json
   {
       "type": "checkpoint",
       "timestamp": "2024-06-24T21:34:06.116009+00:00",
       "step": -1,
       "payload": {
           "config": { ... },
           "values": {"messages": []},
           "metadata": {"source": "input", "step": -1, "writes": {...}}
       }
   }
   ```
   - Provides a detailed snapshot of the graph state at a specific checkpoint.

---

## Real-World Example: Multi-Faceted Chatbot Monitoring 🤖

Imagine you're developing a customer support chatbot for a retail website. You want to ensure:
- **User messages** are processed correctly.
- **Operational events** (like API calls or database queries) are tracked.
- **Debug information** is available for troubleshooting and optimizing performance.

By configuring multiple streaming modes, you can:
- **Monitor the conversation** in real-time (messages mode).
- **Track each operational step** (events mode) to see if tasks are executing as expected.
- **Debug issues** if something goes wrong (debug mode).

This comprehensive view helps in quickly identifying issues, improving response times, and providing a better customer experience.

---

## Conclusion 🎯

Configuring multiple streaming modes at the same time is a powerful feature for developers working with complex graph-based systems. It allows you to:

- **Receive Comprehensive Feedback:** Get messages, events, and debug information all in one stream.
- **Improve Monitoring and Debugging:** See real-time details about every step of your graph's execution.
- **Enhance Real-World Applications:** Whether it's for a customer support chatbot, a real-time data processing pipeline, or any other interactive system, multiple streaming modes ensure you have all the information you need to diagnose and optimize performance.

This approach makes it easier to monitor, troubleshoot, and fine-tune your applications for better efficiency and user satisfaction. Happy streaming! 🚀