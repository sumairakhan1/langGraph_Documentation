# 1. How to call tools using ToolNode

# 🔥 **How to Call Tools Using ToolNode in LangGraph**  

LangGraph provides a powerful feature called **ToolNode** that allows calling tools efficiently within a state-based system. This guide will take you step-by-step through understanding **ToolNode**, how to set it up, and how to manually call tools. We'll break down each concept in an easy-to-understand way with **real-world use cases, code examples, and explanations**.

---

## 📌 **What is ToolNode?**  

**ToolNode** is a prebuilt **LangChain Runnable** that takes a **graph state** (which includes a list of messages) as input and outputs a state update with the result of tool calls.  

✅ It works **out of the box** with LangGraph’s **prebuilt ReAct agent**.  
✅ It can also work with **any StateGraph** as long as its state contains a `messages` key with an appropriate reducer.  

---

## 🌍 **Real-World Use Case of ToolNode**  

Imagine you're building an **AI-powered travel assistant**. Your assistant needs to:  

🔹 **Fetch weather updates** for a city.  
🔹 **Provide a list of the coolest cities** based on user preferences.  

Instead of handling this logic manually, **ToolNode** simplifies the process by calling these tools automatically when needed.

---

# 🚀 **Step-by-Step Guide to Calling Tools with ToolNode**  

## 🛠 **1. Setup and Install Required Packages**  

Before using **ToolNode**, you need to install the required Python packages:  

```python
!pip install --quiet -U langgraph langchain_anthropic
```

Now, import required modules and set up API keys:  

```python
import os
import getpass

# Function to set API keys
def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

# Set the Anthropic API Key (Used for AI Models)
_set_env("ANTHROPIC_API_KEY")
```

💡 **Explanation:**  
- We install `langgraph` and `langchain_anthropic` (needed for LangChain-based workflows).  
- `_set_env(var: str)` ensures that the API key is securely set before making requests.  

---

## 🏗 **2. Define Tools for ToolNode**  

Let's define two tools:  

1️⃣ **get_weather** → Returns the weather for a given location.  
2️⃣ **get_coolest_cities** → Returns a list of cool cities.  

```python
from langchain_core.messages import AIMessage
from langchain_core.tools import tool
from langgraph.prebuilt import ToolNode

@tool
def get_weather(location: str):
    """Call to get the current weather."""
    if location.lower() in ["sf", "san francisco"]:
        return "It's 60 degrees and foggy."
    else:
        return "It's 90 degrees and sunny."

@tool
def get_coolest_cities():
    """Get a list of coolest cities"""
    return "nyc, sf"

# List of available tools
tools = [get_weather, get_coolest_cities]

# Initialize ToolNode with defined tools
tool_node = ToolNode(tools)
```

💡 **Explanation:**  
✅ We use `@tool` decorator to define functions as **callable tools**.  
✅ `get_weather(location: str)` checks if the city is "San Francisco" (SF) and returns weather info.  
✅ `get_coolest_cities()` simply returns `"nyc, sf"`.  
✅ We **initialize `ToolNode`** with the list of available tools.

---

## 🖐 **3. Manually Call ToolNode with a Single Tool Call**  

ToolNode operates on **graph state** with a list of messages.  
The **last message** in the list must be an `AIMessage` containing **tool calls**.

### 🔹 Example: Fetch Weather for San Francisco  

```python
# Create an AIMessage with a tool call request
message_with_single_tool_call = AIMessage(
    content="",
    tool_calls=[
        {
            "name": "get_weather",
            "args": {"location": "sf"},
            "id": "tool_call_id",
            "type": "tool_call",
        }
    ],
)

# Invoke ToolNode with the message
response = tool_node.invoke({"messages": [message_with_single_tool_call]})

print(response)
```

🔹 **Output:**  
```json
{
  'messages': [
    ToolMessage(content="It's 60 degrees and foggy.", name='get_weather', tool_call_id='tool_call_id')
  ]
}
```

💡 **Explanation:**  
✅ We create an **AIMessage** with a **tool call** to `get_weather(location="sf")`.  
✅ The **ToolNode** processes the request and **returns the weather info**.  

---

## ⚡ **4. Parallel Tool Calls with ToolNode**  

**ToolNode** allows calling **multiple tools in parallel**, improving efficiency.

### 🔹 Example: Fetch Weather + Get Coolest Cities Together  

```python
# Create an AIMessage with multiple tool call requests
message_with_multiple_tool_calls = AIMessage(
    content="",
    tool_calls=[
        {
            "name": "get_coolest_cities",
            "args": {},
            "id": "tool_call_id_1",
            "type": "tool_call",
        },
        {
            "name": "get_weather",
            "args": {"location": "sf"},
            "id": "tool_call_id_2",
            "type": "tool_call",
        },
    ],
)

# Invoke ToolNode with multiple tool calls
response = tool_node.invoke({"messages": [message_with_multiple_tool_calls]})

print(response)
```

🔹 **Output:**  
```json
{
  'messages': [
    ToolMessage(content='nyc, sf', name='get_coolest_cities', tool_call_id='tool_call_id_1'),
    ToolMessage(content="It's 60 degrees and foggy.", name='get_weather', tool_call_id='tool_call_id_2')
  ]
}
```

💡 **Explanation:**  
✅ We create an **AIMessage** that contains **two tool calls**:  
   - One for `get_coolest_cities()`.  
   - One for `get_weather(location="sf")`.  
✅ **ToolNode** handles both requests **simultaneously**, improving performance.  
✅ We get responses for **both** tool calls in a **single execution**.  

---

# 🎯 **Key Takeaways**  

🔹 **ToolNode** allows efficient **tool execution** within LangGraph.  
🔹 It processes tool calls **automatically** when used with **LangChain chat models**.  
🔹 You can manually invoke **single or multiple** tools using `AIMessage`.  
🔹 **Parallel tool execution** improves efficiency for multiple requests.  

---

# 🎓 **Final Thoughts**  

ToolNode is a **powerful feature** for building AI applications that need **dynamic tool calling**.  
With it, you can efficiently **fetch data, call APIs, and automate actions** with minimal setup.  

🚀 **Next Steps:**  
🔹 Try integrating **more tools** into your own AI assistant.  
🔹 Explore **how LangGraph can be used in complex workflows**.  

Would you like to see a **full AI assistant project using ToolNode**? Let me know! 😊

---

# 🌟 **Using Chat Models with Tool Calling in LangChain**  

## 📝 **Introduction**  
In this guide, we'll explore **how to use chat models with tool calling** using **LangChain and Anthropic's Claude model**. We'll set up a **ReAct agent**, a tool-driven AI that keeps calling external tools until it gathers enough information to answer a query.  

We'll break down:  
✅ How tool calling works  
✅ Setting up a chat model with tools  
✅ Implementing a ReAct agent  
✅ Running real-world examples  

Let's get started! 🚀  

---

## 🔍 **What is Tool Calling?**  
**Tool calling** allows AI models to interact with external tools (like APIs) to fetch real-time data. Instead of just responding with pre-trained knowledge, the model can:  
✅ Call a **weather API** to check live weather updates  
✅ Query a **database** for information  
✅ Fetch **stock prices** or other real-time data  

🔹 **Real-world Example:** Imagine an AI assistant that helps you plan a trip. It can check flights, hotel availability, and weather—all in real-time using tool calls.  

---

## 🛠 **Step 1: Setting Up a Chat Model with Tools**  

### 📌 **Code: Binding Tools to the Model**  

```python
from langchain_anthropic import ChatAnthropic
from langgraph.graph import StateGraph, MessagesState
from langgraph.prebuilt import ToolNode

# Define a chat model with tool support
model_with_tools = ChatAnthropic(
    model="claude-3-haiku-20240307", temperature=0
).bind_tools(tools)

# Invoke the model to check the weather
response = model_with_tools.invoke("what's the weather in SF?")
print(response.tool_calls)
```

### 📝 **Explanation of Code:**  
🔹 **`ChatAnthropic(model="claude-3-haiku-20240307", temperature=0)`**  
- This initializes the Claude model.  
- `temperature=0` makes responses more **deterministic** (consistent).  

🔹 **`.bind_tools(tools)`**  
- This links the model to external tools so it can make API calls.  

🔹 **`model_with_tools.invoke("what's the weather in SF?")`**  
- The AI calls a weather API tool to fetch real-time data.  

---

## ⚙️ **Step 2: Implementing the ReAct Agent**  

A **ReAct agent** is an AI that repeatedly calls tools **until it has enough data** to answer a question.  

### 📌 **Code: Implementing the ReAct Agent**  

```python
from langgraph.graph import StateGraph, MessagesState, START, END

# Function to check if tools are needed
def should_continue(state: MessagesState):
    messages = state["messages"]
    last_message = messages[-1]
    if last_message.tool_calls:
        return "tools"
    return END

# Function to call the model
def call_model(state: MessagesState):
    messages = state["messages"]
    response = model_with_tools.invoke(messages)
    return {"messages": [response]}

# Create the workflow graph
workflow = StateGraph(MessagesState)

# Add agent and tool nodes
workflow.add_node("agent", call_model)
workflow.add_node("tools", tool_node)

# Define execution flow
workflow.add_edge(START, "agent")
workflow.add_conditional_edges("agent", should_continue, ["tools", END])
workflow.add_edge("tools", "agent")

# Compile the workflow
app = workflow.compile()
```

### 📝 **Explanation of Code:**  
🔹 **`should_continue(state: MessagesState)`**  
- Checks if the AI's last response includes a tool call.  
- If **yes**, it moves to the "tools" step.  
- If **no**, it stops processing.  

🔹 **`call_model(state: MessagesState)`**  
- Calls the AI model to generate a response.  

🔹 **`StateGraph(MessagesState)`**  
- Creates a **workflow** that manages the AI's interactions.  

🔹 **`.add_node("agent", call_model)`**  
- Defines the **AI agent** as a node.  

🔹 **`.add_node("tools", tool_node)`**  
- Adds **ToolNode**, which handles external API calls.  

🔹 **`.add_conditional_edges("agent", should_continue, ["tools", END])`**  
- If the AI needs more info, it **calls a tool**.  
- Otherwise, it **ends the process**.  

---

## 🎯 **Step 3: Running the ReAct Agent**  

### 📌 **Code: Executing the Workflow**  

```python
# Example: Asking for weather in a single city
for chunk in app.stream(
    {"messages": [("human", "what's the weather in SF?")]}, stream_mode="values"
):
    chunk["messages"][-1].pretty_print()
```

### 📝 **Expected Output:**  

```plaintext
Human: what's the weather in SF?
AI: Okay, let's check the weather in San Francisco.
Tool Calls:
  get_weather (ID: tool_123)
Args:
  location: San Francisco
Tool Response: 
  It's 60 degrees and foggy.
AI: The weather in San Francisco is currently 60 degrees with foggy conditions.
```

🔹 The **AI understands the query**.  
🔹 It **calls the tool** to get real-time weather.  
🔹 The tool returns **"60 degrees and foggy"**.  
🔹 The AI **summarizes the result**.  

---

## 🌍 **Real-World Use Cases**  

✅ **Smart Assistants**: AI-powered assistants like Siri or Google Assistant use tool calls to fetch weather, book flights, or get live sports scores.  

✅ **Customer Support Bots**: AI chatbots for businesses can check **order status**, **pricing**, or **stock availability** in real time.  

✅ **Finance & Stock Trading**: AI agents can retrieve **live stock prices**, **cryptocurrency updates**, and **financial reports** using API calls.  

✅ **Healthcare & Medical Assistance**: AI chatbots can check **appointment schedules** or provide **real-time symptom analysis** with medical databases.  

---

## 🔄 **Handling Multiple Tool Calls**  

We can also call **multiple tools** in sequence.  

### 📌 **Code: Getting Weather for Multiple Cities**  

```python
for chunk in app.stream(
    {"messages": [("human", "what's the weather in the coolest cities?")]},
    stream_mode="values",
):
    chunk["messages"][-1].pretty_print()
```

### 📝 **Expected Output:**  

```plaintext
Human: what's the weather in the coolest cities?
AI: Okay, let's find out the weather in the coolest cities.
Tool Calls:
  get_coolest_cities (ID: tool_456)
Tool Response:
  NYC, SF
AI: Now let's get the weather for those cities.
Tool Calls:
  get_weather (NYC) (ID: tool_789)
  get_weather (SF) (ID: tool_101)
Tool Responses:
  NYC: 90 degrees and sunny.
  SF: 60 degrees and foggy.
AI: The weather in NYC is 90 degrees and sunny. In SF, it's 60 degrees and foggy.
```

---

## ❌ **Handling Errors in ToolNode**  

Errors might occur if a tool fails. **ToolNode** automatically handles errors by default.  

You can enable or disable error handling with:  

```python
ToolNode(handle_tool_errors=True)  # Enabled (default)
ToolNode(handle_tool_errors=False) # Disabled
```

🔹 When enabled, the AI will **gracefully handle errors**.  
🔹 If disabled, it will **return raw error messages**.  

---

## 🎯 **Conclusion**  

✅ **Tool calling** enhances AI capabilities by allowing real-time information retrieval.  
✅ **ReAct agents** automate tool calls until they have enough data.  
✅ **LangChain & LangGraph** provide a powerful way to structure AI workflows.  
✅ **Real-world use cases** include **smart assistants, finance, healthcare, and customer service**.  

🚀 Now you can integrate **tool calling AI agents** into your projects! 🎉