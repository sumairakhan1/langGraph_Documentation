# 4. How to pass config to tools

Sure! Here’s a detailed and beginner-friendly explanation of **how to pass config to tools in LangChain**, including real-world use cases, step-by-step breakdowns, and code explanations.

---

# 🛠️ How to Pass Config to Tools in LangChain

When working with **LangChain tools**, you might need to pass **runtime values** (such as user ID, API keys, or session data). This should be controlled by the **application logic**, not the LLM, to ensure **security and consistency**.

LangChain tools use the **Runnable interface**, where the `invoke` method allows runtime information to be passed through the `config` argument using **RunnableConfig**.

In this guide, we will:
✅ Set up an agent to manage a **user’s favorite pets**  
✅ Use `RunnableConfig` to ensure the user ID is fixed by application logic  
✅ Let the LLM control the other parameters  

---

## 📌 **Real-World Use Case**

Imagine you're building a **customer support chatbot** that handles **personalized user settings**. You wouldn't want the AI to decide which user’s settings to modify—it should always come from **application logic**.  

Example:  
- A **shopping assistant** that saves a user's preferred brands and categories.  
- A **music recommendation bot** that remembers a user’s liked songs.  
- A **home automation assistant** that controls a specific user's devices.  

By using `RunnableConfig`, we ensure that **only the authenticated user’s data is modified**.

---

## 🔧 **Step 1: Install Required Packages**
Before we start coding, let's install the necessary libraries:

```python
%pip install --quiet -U langgraph langchain_anthropic
```

This installs:
- **LangGraph** → For building AI workflows  
- **LangChain Anthropic** → To use Claude models  

---

## 🔑 **Step 2: Set API Keys**
Since API keys should never be hardcoded, we use environment variables:

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("ANTHROPIC_API_KEY")
```

### 🔍 **Code Explanation:**
1️⃣ `getpass.getpass()` → Securely asks for API key input  
2️⃣ `os.environ.get(var)` → Checks if the key is already set  
3️⃣ If not set, the key is stored in `os.environ[var]`  

---

## ⚙️ **Step 3: Define Tools with Config Support**
Now, let's define **three tools** that will manage a user’s favorite pets.

### **📌 1. Tool to Update Favorite Pets**
```python
from typing import List
from langchain_core.tools import tool
from langchain_core.runnables.config import RunnableConfig

user_to_pets = {}  # Dictionary to store user data

@tool(parse_docstring=True)
def update_favorite_pets(pets: List[str], config: RunnableConfig) -> None:
    """Add the list of favorite pets.

    Args:
        pets: List of favorite pets to set.
    """
    user_id = config.get("configurable", {}).get("user_id")
    user_to_pets[user_id] = pets
```

### 🔍 **Code Explanation:**
✅ `@tool(parse_docstring=True)` → Registers this function as a LangChain tool  
✅ `pets: List[str]` → Accepts a list of pet names  
✅ `config: RunnableConfig` → Provides user ID at runtime  
✅ `user_to_pets[user_id] = pets` → Stores the user's pets in a dictionary  

---

### **📌 2. Tool to Delete Favorite Pets**
```python
@tool
def delete_favorite_pets(config: RunnableConfig) -> None:
    """Delete the list of favorite pets."""
    user_id = config.get("configurable", {}).get("user_id")
    if user_id in user_to_pets:
        del user_to_pets[user_id]
```

### 🔍 **Code Explanation:**
✅ Retrieves `user_id` from `config`  
✅ Deletes the pet list for that user if it exists  

---

### **📌 3. Tool to List Favorite Pets**
```python
@tool
def list_favorite_pets(config: RunnableConfig) -> None:
    """List favorite pets if asked to."""
    user_id = config.get("configurable", {}).get("user_id")
    return ", ".join(user_to_pets.get(user_id, []))
```

### 🔍 **Code Explanation:**
✅ Retrieves `user_id`  
✅ Returns the list of pets in a comma-separated string  

---

## 🤖 **Step 4: Set Up the Chat Model**
Now, we define the **Anthropic chat model** (Claude):

```python
from langchain_anthropic import ChatAnthropic

model = ChatAnthropic(model="claude-3-5-haiku-latest")
```

---

## 🕵️‍♂️ **Step 5: Create a ReAct Agent**
A **ReAct agent** repeatedly calls tools until it gathers enough information. We will use **LangGraph** to create it.

```python
from langgraph.prebuilt import create_react_agent
from langgraph.graph import StateGraph
from langgraph.prebuilt import ToolNode

tools = [update_favorite_pets, delete_favorite_pets, list_favorite_pets]
graph = create_react_agent(model, tools)
```

### 🔍 **Code Explanation:**
✅ `create_react_agent(model, tools)` → Creates an agent that can call tools  
✅ The agent **binds tools automatically**, so we don’t need to pass them manually  

---

## 🚀 **Step 6: Using the Agent**
Now, let's test the agent by storing, retrieving, and deleting favorite pets.

### **✅ Storing Favorite Pets**
```python
from langchain_core.messages import HumanMessage

user_to_pets.clear()  # Clear previous data
print(f"User information prior to run: {user_to_pets}")

inputs = {"messages": [HumanMessage(content="my favorite pets are cats and dogs")]}

for chunk in graph.stream(inputs, {"configurable": {"user_id": "123"}}, stream_mode="values"):
    chunk["messages"][-1].pretty_print()

print(f"User information after the run: {user_to_pets}")
```

### 🔍 **What Happens Here?**
1️⃣ Clears previous user data  
2️⃣ Sends a message: *"my favorite pets are cats and dogs"*  
3️⃣ Calls `update_favorite_pets` with `user_id="123"`  
4️⃣ Stores `{'123': ['cats', 'dogs']}` in the dictionary  

---

### **✅ Retrieving Favorite Pets**
```python
inputs = {"messages": [HumanMessage(content="what are my favorite pets")]}

for chunk in graph.stream(inputs, {"configurable": {"user_id": "123"}}, stream_mode="values"):
    chunk["messages"][-1].pretty_print()
```

### 🔍 **What Happens Here?**
1️⃣ Calls `list_favorite_pets`  
2️⃣ Returns: `"cats, dogs"`

---

### **✅ Deleting Favorite Pets**
```python
inputs = {"messages": [HumanMessage(content="please forget what i told you about my favorite animals")]}

for chunk in graph.stream(inputs, {"configurable": {"user_id": "123"}}, stream_mode="values"):
    chunk["messages"][-1].pretty_print()

print(f"User information after deletion: {user_to_pets}")
```

### 🔍 **What Happens Here?**
1️⃣ Calls `delete_favorite_pets`  
2️⃣ Removes `user_id="123"` from the dictionary  

---

# 🎯 **Conclusion**
✅ **LangChain’s `RunnableConfig` ensures user-specific data is managed securely**  
✅ **Application logic, not the LLM, controls user IDs**  
✅ **This approach is useful in AI assistants, chatbots, and personalized services**  

Would you like me to explain anything further? 😊