# 5. How to update graph state from tools

Here's a detailed explanation of how to update graph state from tools in LangGraph, structured in a way that's easy for beginners to understand, with real-world examples, icons, and code explanations.  

---

# 🛠️ **How to Update Graph State from Tools in LangGraph**

### 📌 **Introduction**
In LangGraph, updating the graph state from tools is useful in cases where we need to modify or store information dynamically during a conversation. A common example is in customer support applications, where the system may need to fetch a user's account details at the beginning of a conversation.

With LangGraph, we can achieve this by returning a `Command` object with an `update` field, which allows us to update specific state variables.

---

# 🏛️ **Real-World Use Case**
Imagine you’re building an AI chatbot for a **customer support system**. When a user enters their query, the chatbot should:
1. Look up the user’s details (e.g., name, location).
2. Store that information in the conversation state.
3. Use it to personalize responses.

For example:
- **User:** "What are my subscription details?"
- **Bot:** "Hello, John! You are on the Gold Plan, and your next payment is due on June 15."

---

# 🏗️ **Understanding the Code Step by Step**
Let's break down how we implement this in LangGraph.

## 🛠️ **1. Defining the Tool to Look Up User Information**
We need to define a **tool** that fetches user details from a database (simulated here with a dictionary).

### ✅ **Code Implementation**
```python
from langchain_core.tools import tool
from langchain_core.tools.base import InjectedToolCallId
from langchain_core.messages import ToolMessage
from langchain_core.runnables import RunnableConfig
from langgraph.types import Command

from typing_extensions import Annotated

# Sample database (a dictionary of user info)
USER_INFO = [
    {"user_id": "1", "name": "Bob Dylan", "location": "New York, NY"},
    {"user_id": "2", "name": "Taylor Swift", "location": "Beverly Hills, CA"},
]

USER_ID_TO_USER_INFO = {info["user_id"]: info for info in USER_INFO}

@tool
def lookup_user_info(tool_call_id: Annotated[str, InjectedToolCallId], config: RunnableConfig):
    """Fetch user details based on user ID."""
    user_id = config.get("configurable", {}).get("user_id")  # Extract user ID from config
    
    if user_id is None:
        raise ValueError("Please provide user ID")  # Handle missing user ID
    
    if user_id not in USER_ID_TO_USER_INFO:
        raise ValueError(f"User '{user_id}' not found")  # Handle case where user is not in database

    user_info = USER_ID_TO_USER_INFO[user_id]  # Fetch user details

    # Return a Command object that updates the graph state
    return Command(
        update={
            "user_info": user_info,  # Store user info in the state
            "messages": [ToolMessage("Successfully looked up user information", tool_call_id=tool_call_id)]
        }
    )
```
---

### 🔍 **Breaking Down the Code**
1. **Defining a tool (`@tool`)**  
   - This function is marked as a tool, meaning it can be used in LangGraph workflows.

2. **Extracting `user_id` from the configuration (`config`)**  
   - The function retrieves the user ID from the config object.

3. **Validating the input**  
   - If no user ID is provided, it raises an error.
   - If the user ID is not found in our dictionary, it raises an error.

4. **Fetching the user information**  
   - It retrieves the user’s details from a pre-defined dictionary.

5. **Returning a `Command` to update the state**  
   - The returned `Command` updates:
     - `"user_info"`: Stores the retrieved user details.
     - `"messages"`: Adds a confirmation message to the message history.

---

## 📜 **2. Defining the Prompt Function**
Once the user’s details are fetched, we need to **personalize responses**. We do this by defining a function that modifies the system prompt based on the updated state.

### ✅ **Code Implementation**
```python
from langgraph.prebuilt.chat_agent_executor import AgentState

class State(AgentState):
    user_info: dict  # State variable to store user info

def prompt(state: State):
    """Generate a system prompt using updated user info."""
    user_info = state.get("user_info")

    if user_info is None:
        return state["messages"]  # If no user info, return default messages

    # Create a system message with personalized details
    system_msg = f"User name is {user_info['name']}. User lives in {user_info['location']}."
    
    return [{"role": "system", "content": system_msg}] + state["messages"]
```
---

### 🔍 **Breaking Down the Code**
1. **Defines a state class (`State`)**  
   - The `user_info` dictionary is added to store user details.

2. **Modifies the system prompt**  
   - If user info exists, it adds their **name and location** to the system message.

3. **Ensures personalized responses**  
   - Instead of a generic response, the AI now responds using the user’s details.

---

## 🔗 **3. Connecting Everything in a Graph**
Now, we combine everything into a **LangGraph agent**.

### ✅ **Code Implementation**
```python
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")  # Load an AI model

agent = create_react_agent(
    model,
    [lookup_user_info],  # Pass the tool
    state_schema=State,  # Define the state
    prompt=prompt,  # Use the personalized prompt function
)
```
---

### 🔍 **Breaking Down the Code**
1. **Loads an AI model (`ChatOpenAI`)**  
   - Uses OpenAI's GPT-4o model for text generation.

2. **Creates an AI agent (`create_react_agent`)**  
   - Connects the **lookup tool**, **state schema**, and **prompt function**.

---

## 🚀 **4. Running the Agent**
Let's test our agent by providing a user ID.

### ✅ **Code Implementation**
```python
for chunk in agent.stream(
    {"messages": [("user", "hi, what should I do this weekend?")]}, 
    {"configurable": {"user_id": "1"}}  # Provide user ID
):
    print(chunk)
```
---

### 🔍 **Expected Output**
```
Hi Bob! Since you're in New York, NY, here are some things you can do:
1. Visit Central Park
2. Check out a Broadway show
3. Explore a new restaurant
...
```
---

# 🎯 **Key Takeaways**
✔ **Graph state updates allow tools to store and modify information dynamically.**  
✔ **Personalization improves user experience by making responses context-aware.**  
✔ **Using `Command(update={})`, we can modify state variables inside a tool.**  
✔ **LangGraph’s `create_react_agent` makes it easy to integrate tools and state updates.**  

---

# 🎬 **Conclusion**
Updating graph state from tools is a powerful feature in LangGraph that allows AI applications to **store and recall user-specific details** for **better contextual conversations**. Whether you're building a **customer support chatbot, AI assistant, or recommendation system**, this technique ensures a more **engaging and intelligent** experience for users.

Would you like me to expand on any specific part? 😊