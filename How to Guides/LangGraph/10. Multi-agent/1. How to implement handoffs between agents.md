# 1. How to implement handoffs between agents


# 🚀 Implementing Handoffs Between Agents in Multi-Agent Systems

Handoffs between agents are a crucial aspect of multi-agent systems, allowing smooth transitions of tasks from one agent to another. In this guide, we'll deeply explore how to implement handoffs using **LangGraph**. 

We'll cover:
✅ Understanding handoffs in multi-agent architectures  
✅ Real-world applications of agent handoffs  
✅ Implementing handoffs using **Command** objects  
✅ Using tools for agent handoffs  
✅ A step-by-step breakdown of the **code implementation**  

---

## 🧠 Understanding Handoffs in Multi-Agent Systems

In multi-agent systems, agents **work together** by exchanging information and responsibilities. Each agent is represented as a **graph node**, and interactions between agents follow a structured **workflow**.

### 🔹 What is a Handoff?
A **handoff** occurs when:
- One agent **passes control** to another agent.
- The agent **transfers data** (state) along with control.

### 🔹 Key Components of Handoffs
- **Destination** 🏁: The next agent to take over  
- **Payload** 📦: The data passed to the next agent  

### 🔹 How Does it Work in LangGraph?
In **LangGraph**, an agent node can return a **Command** object, which:
- **Decides** which agent should handle the next step.
- **Updates** the state of the graph.

---

## 🌍 Real-World Example: Customer Support Automation

Imagine an **AI-powered customer support system** where:
- **Agent 1:** Handles general inquiries 📩  
- **Agent 2:** Handles billing issues 💰  
- **Agent 3:** Handles technical support 🖥️  

A handoff occurs when:
- The **general inquiry agent** determines that the issue is **billing-related** → hands off to the **billing agent**.
- The **billing agent** finds a technical issue → hands off to the **technical support agent**.

This ensures that **customers receive expert help efficiently** without repeating their queries.

---

## 🛠️ Implementing Handoffs in LangGraph

### 🔹 1️⃣ Basic Handoff Using `Command`

Agents can decide when to **stop or hand off** using `Command`. Below is a **simple implementation**:

```python
from langgraph.types import Command
from typing_extensions import Literal

def agent(state) -> Command[Literal["agent", "another_agent"]]:
    # Determine the next agent dynamically (e.g., based on user query)
    goto = get_next_agent()  # Returns either 'agent' or 'another_agent'
    
    return Command(
        goto=goto,  # Specifies the next agent
        update={"my_state_key": "my_state_value"}  # Updates the graph state
    )
```

🔍 **Explanation:**
- **`get_next_agent()`** determines the next agent based on logic.
- **`goto`** defines the next agent to execute.
- **`update`** modifies the state to carry forward information.

---

### 🔹 2️⃣ Using Tools to Trigger a Handoff

Some agents use **tool calls** to signal a handoff.  
We define tools that allow **agents to transfer control**.

```python
from langchain_core.tools import tool

@tool
def transfer_to_bob(state):
    """Transfers control to Bob (another agent)."""
    return Command(
        goto="bob",  # Transfers control to Bob
        update={"my_state_key": "my_state_value"},
        graph=Command.PARENT  # Ensures correct navigation
    )
```

🔍 **Explanation:**
- The **`@tool` decorator** registers the function as a tool.
- **Returns a `Command`** object, specifying:
  - **Next agent**: `goto="bob"`
  - **State update**: Transfers data to the next agent.
  - **`graph=Command.PARENT`**: Ensures correct routing in a multi-agent structure.

---

## 🔢 Example: Math Experts Collaborating (Addition & Multiplication)

We will create a **multi-agent system** where:
1. An **Addition Expert** handles addition but needs help with multiplication.  
2. A **Multiplication Expert** handles multiplication but needs help with addition.  
3. Agents **handoff tasks** when needed.

### **🔹 Step 1: Install Dependencies**
Install **LangGraph** and necessary libraries.

```sh
pip install -U langgraph langchain-anthropic
```

Set up API key for **Anthropic Claude**:
```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("ANTHROPIC_API_KEY")
```

---

### **🔹 Step 2: Define Tool Calls for Handoff**

Each agent uses **tool calls** to **request help from the other agent**.

```python
from langchain_core.tools import tool

@tool
def transfer_to_multiplication_expert():
    """Request help from the multiplication expert."""
    return  # No return needed, just a signal.

@tool
def transfer_to_addition_expert():
    """Request help from the addition expert."""
    return
```

🔍 **Explanation:**
- These tools act as **signals** for the AI.
- They **don’t return** values but indicate the need for a handoff.

---

### **🔹 Step 3: Implement the Addition Expert**
The **addition expert** solves **addition problems** but can request help for **multiplication**.

```python
from langgraph.types import Command
from langchain_anthropic import ChatAnthropic
from langgraph.graph import MessagesState

model = ChatAnthropic(model="claude-3-5-sonnet-latest")

def addition_expert(
    state: MessagesState,
) -> Command[Literal["multiplication_expert", "__end__"]]:
    system_prompt = (
        "You are an addition expert. Ask the multiplication expert for help if needed."
    )

    messages = [{"role": "system", "content": system_prompt}] + state["messages"]
    ai_msg = model.bind_tools([transfer_to_multiplication_expert]).invoke(messages)

    # If AI asks for a handoff, trigger it
    if len(ai_msg.tool_calls) > 0:
        tool_call_id = ai_msg.tool_calls[-1]["id"]
        tool_msg = {"role": "tool", "content": "Transferred", "tool_call_id": tool_call_id}
        return Command(goto="multiplication_expert", update={"messages": [ai_msg, tool_msg]})

    return {"messages": [ai_msg]}
```

🔍 **Explanation:**
1. **Defines system prompt** → Instructs AI on behavior.
2. **Uses AI model (`Claude`)** to process requests.
3. **Checks for tool calls**:
   - If the AI calls **`transfer_to_multiplication_expert`**, it means a handoff is needed.
   - The **Command object** transfers control to the **multiplication expert**.

---

### **🔹 Step 4: Implement the Multiplication Expert**
Similarly, the **multiplication expert** solves multiplication but requests help for addition.

```python
def multiplication_expert(
    state: MessagesState,
) -> Command[Literal["addition_expert", "__end__"]]:
    system_prompt = (
        "You are a multiplication expert. Ask the addition expert for help if needed."
    )

    messages = [{"role": "system", "content": system_prompt}] + state["messages"]
    ai_msg = model.bind_tools([transfer_to_addition_expert]).invoke(messages)

    if len(ai_msg.tool_calls) > 0:
        tool_call_id = ai_msg.tool_calls[-1]["id"]
        tool_msg = {"role": "tool", "content": "Transferred", "tool_call_id": tool_call_id}
        return Command(goto="addition_expert", update={"messages": [ai_msg, tool_msg]})

    return {"messages": [ai_msg]}
```

🔍 **Explanation:**
- Works the **same way** as the addition expert.
- Routes to **addition expert** if needed.

---

## 🎯 Summary
✅ **Handoffs** allow agents to delegate tasks dynamically.  
✅ Implemented **handoffs using `Command`** for routing.  
✅ Used **tools for LLM-based decision-making**.  
✅ Built a **multi-agent system** with **addition & multiplication experts**.

🚀 **Now you can build scalable multi-agent systems using LangGraph!** 🎯

---
# 🧠 **Understanding State Graphs for Expert Routing in AI Systems**  

In this detailed explanation, we'll explore **State Graphs** and how they help in **routing expert agents** for solving specific problems. We'll break down each concept in a beginner-friendly way, provide **real-world use cases**, and go through a **line-by-line code explanation** to solidify your understanding.  

---

## 🔹 **What is a State Graph?**
A **State Graph** is a structure used in AI systems to manage decision-making and workflows dynamically. It defines:
- **Nodes** (representing agents or experts)
- **Edges** (representing connections or transitions between experts)
- **State changes** based on conditions  

📌 **Example in Real World:**  
Imagine a **customer support system** where different agents handle **billing, technical support, and product inquiries**. Instead of randomly assigning queries, a **State Graph** routes a question to the **right expert** dynamically.

---

## 🔹 **How Does the State Graph Work in This Code?**
We are implementing a **math expert system** where:
1. An **addition expert** solves addition problems.
2. A **multiplication expert** handles multiplication.
3. If one expert cannot solve a problem, they **pass it** to the correct expert.

---

## 📝 **Code Implementation and Explanation**  
Let’s break down the provided code in detail.

### ✅ **1. Creating the State Graph**
```python
builder = StateGraph(MessagesState)
builder.add_node("addition_expert", addition_expert)
builder.add_node("multiplication_expert", multiplication_expert)
# We'll always start with the addition expert
builder.add_edge(START, "addition_expert")
graph = builder.compile()
```
### 🛠️ **Code Breakdown:**
- `StateGraph(MessagesState)`: Initializes a **state graph** that manages **messages** between different agents.
- `add_node("addition_expert", addition_expert)`: Adds a **node** for an expert who handles **addition problems**.
- `add_node("multiplication_expert", multiplication_expert)`: Adds another **node** for an expert who handles **multiplication**.
- `add_edge(START, "addition_expert")`: Defines that **the process starts** with the **addition expert**.
- `graph = builder.compile()`: Compiles the graph so it can execute tasks.

📌 **Why Start with Addition Expert?**  
Since multiplication often involves **parentheses**, we **first resolve** additions inside parentheses before multiplying.

---

### ✅ **2. Defining a Helper Function to Display Outputs Nicely**
```python
from langchain_core.messages import convert_to_messages

def pretty_print_messages(update):
    if isinstance(update, tuple):
        ns, update = update
        if len(ns) == 0:  # Ignore empty updates
            return

        graph_id = ns[-1].split(":")[0]
        print(f"Update from subgraph {graph_id}:\n")

    for node_name, node_update in update.items():
        print(f"Update from node {node_name}:\n")

        for m in convert_to_messages(node_update["messages"]):
            m.pretty_print()
        print("\n")
```
### 🛠️ **Code Breakdown:**
- `convert_to_messages(update)`: Converts system updates into a **readable message format**.
- `if isinstance(update, tuple)`: Checks if the update is a **tuple** (used for tracking states).
- `if len(ns) == 0`: Skips **empty updates** that do not contribute to results.
- `graph_id = ns[-1].split(":")[0]`: Extracts the **subgraph ID** where the update is happening.
- `for node_name, node_update in update.items()`: Loops through all **active expert nodes** and displays their updates.
- `m.pretty_print()`: **Formats** and prints AI-generated messages clearly.

📌 **Why Do We Need This?**  
This function helps **track updates** from different experts in an organized way.

---

### ✅ **3. Running the Graph with a Math Expression**
```python
for chunk in graph.stream(
    {"messages": [("user", "what's (3 + 5) * 12")]},
):
    pretty_print_messages(chunk)
```
### 🛠️ **Code Breakdown:**
- `graph.stream({"messages": [("user", "what's (3 + 5) * 12")]})`:  
  - The **user** asks a math question.  
  - The **graph processes it step by step**, first resolving **(3 + 5) → 8**, then handling **8 × 12 → 96**.
- `pretty_print_messages(chunk)`: Displays **updates** from both **addition and multiplication experts**.

---

## 🎯 **Expected Output**
```plaintext
Update from node addition_expert:

AI Message:
"Let me help break this down:
First, I'll handle the addition part:  
3 + 5 = 8  
Now, for multiplication 8 * 12, I'll ask the multiplication expert for help."

Update from node multiplication_expert:

AI Message:
"Multiplying 8 * 12 = 96"

Final Answer: (3 + 5) * 12 = 96
```
**📌 How It Works:**
1. **Addition Expert:** Solves `3 + 5 = 8` and **passes the result** to the **Multiplication Expert**.
2. **Multiplication Expert:** Solves `8 * 12 = 96` and **returns the final answer**.

---

## 🌍 **Real-World Applications**
### ✅ **1. Automated Customer Support**
- Users ask **billing, technical, or general** queries.
- The **State Graph routes** the question to the **right expert** dynamically.

### ✅ **2. AI-Powered Medical Diagnosis**
- **Primary Expert** (General Doctor) checks basic symptoms.
- If needed, **routes the patient** to a **specialist** (Cardiologist, Neurologist, etc.).

### ✅ **3. Multi-Agent AI Systems**
- In **AI assistants** (e.g., Siri, Google Assistant), different **agents** handle:
  - **Weather queries**
  - **Math problems**
  - **Calendar scheduling**
  - **Music recommendations**

---

## 💡 **Key Takeaways**
✔️ **State Graphs** efficiently manage **task delegation** between multiple experts.  
✔️ Each **expert node** specializes in a **specific function** and communicates dynamically.  
✔️ Useful in **customer support, AI assistants, medical diagnosis, and automation.**  
✔️ The **graph execution** ensures that **complex queries** are **broken down and solved step-by-step.**  

---

🚀 **Now, Let’s Take It Further!**  
You can extend this system by adding **more experts** for division, subtraction, or even **advanced mathematical functions!**  

🔹 **What else would you like to add to this AI expert system?** Let’s discuss! 😊

---

# 🔄 Implementing Handoffs in Multi-Agent Systems  

In multi-agent systems, **handoffs** allow different agents to collaborate by passing tasks between them. Instead of defining explicit transitions within each agent, we can use **handoff tools** that automate this process.  

This approach ensures that control is transferred smoothly between different experts (agents) while maintaining chat history. Let's dive deep into the concept and see how it works with **LangGraph**.  

---

## 🔹 **Why Use Handoff Tools?**  

Handoff tools are beneficial in multi-agent architectures where:  
✅ Tasks are distributed among multiple agents (e.g., addition and multiplication experts).  
✅ Some agents may not have the required information to complete a task and need to ask another agent for help.  
✅ The system should maintain message history and provide seamless interactions between agents.  

### 🏢 **Real-World Example**  

Imagine a **customer support chatbot** for an e-commerce website:  
- The **Order Inquiry Agent** handles order tracking.  
- The **Refund Agent** handles refund requests.  
- The **Technical Support Agent** resolves issues with a product.  

If a customer asks about a refund while talking to the Order Inquiry Agent, a **handoff tool** will smoothly transfer the conversation to the Refund Agent while maintaining chat history.  

---

## 🔹 **Key Considerations for Handoff Tools**  

When implementing handoff tools, we need to handle the following aspects:  

1️⃣ **Navigating Between Agents**  
   - Each agent functions as a **subgraph node** within a larger multi-agent system.  
   - When a handoff occurs, the control should transfer to the parent graph using `Command.PARENT`.  

2️⃣ **Updating State for the Next Agent**  
   - The system needs to **pass the current conversation history** to the next agent.  
   - This ensures the new agent understands the context without losing past interactions.  

3️⃣ **Providing Additional Data**  
   - Injecting relevant information like:  
     🔹 Graph state (`InjectedState`)  
     🔹 Memory storage (`InjectedStore`)  
     🔹 Tool call ID (`InjectedToolCallId`)  

---

## 📝 **Code Implementation of Handoff Tools**  

Below is an implementation of a **handoff tool** using LangGraph.  

### 🔹 **Step 1: Define the Handoff Tool Function**  

```python
from typing import Annotated
from langchain_core.tools import tool
from langchain_core.tools.base import InjectedToolCallId
from langgraph.prebuilt import InjectedState

def make_handoff_tool(*, agent_name: str):
    """Create a tool that allows handing off control to another agent."""
    
    # Tool name dynamically generated based on the target agent
    tool_name = f"transfer_to_{agent_name}"

    @tool(tool_name)
    def handoff_to_agent(
        state: Annotated[dict, InjectedState],  # Inject current graph state
        tool_call_id: Annotated[str, InjectedToolCallId],  # Inject current tool call ID
    ):
        """Transfers control to another agent for assistance."""

        # Tool message indicating successful transfer
        tool_message = {
            "role": "tool",
            "content": f"Successfully transferred to {agent_name}",
            "name": tool_name,
            "tool_call_id": tool_call_id,
        }

        return Command(
            goto=agent_name,         # Move execution to the specified agent
            graph=Command.PARENT,    # Ensure control is transferred in the parent graph
            update={                 # Update the graph state
                "messages": state["messages"] + [tool_message]
            },
        )

    return handoff_to_agent
```

---

## 🔎 **Breaking Down the Code**  

### ✅ **1. Function Definition**
```python
def make_handoff_tool(*, agent_name: str):
```
- The function `make_handoff_tool` creates a tool for transferring tasks to another agent.
- `agent_name` is the target agent that will receive the task.

### ✅ **2. Generating a Dynamic Tool Name**
```python
tool_name = f"transfer_to_{agent_name}"
```
- This dynamically assigns a tool name based on the agent it transfers to.
- Example: If we call `make_handoff_tool(agent_name="math_expert")`, the tool will be named `transfer_to_math_expert`.

### ✅ **3. Defining the Handoff Tool**
```python
@tool(tool_name)
def handoff_to_agent(
    state: Annotated[dict, InjectedState],  
    tool_call_id: Annotated[str, InjectedToolCallId],  
):
```
- The function `handoff_to_agent` represents the handoff mechanism.
- `state`: Injects the **current graph state**, which includes message history.
- `tool_call_id`: Injects the **tool call ID**, helping track the request.

### ✅ **4. Creating a Transfer Message**
```python
tool_message = {
    "role": "tool",
    "content": f"Successfully transferred to {agent_name}",
    "name": tool_name,
    "tool_call_id": tool_call_id,
}
```
- Generates a message confirming that the request has been transferred.
- This message is added to the conversation history.

### ✅ **5. Returning the Handoff Command**
```python
return Command(
    goto=agent_name,        
    graph=Command.PARENT,   
    update={"messages": state["messages"] + [tool_message]},
)
```
- `goto=agent_name`: Transfers execution to the target agent.  
- `graph=Command.PARENT`: Ensures the transition happens within the **parent graph**.  
- `update={"messages": state["messages"] + [tool_message]}`: Maintains the chat history with the latest transfer message.  

---

## 🚀 **How the Handoff Works in Practice**  

### 🔹 **Scenario: Solving a Math Problem**  

Suppose we have two agents:  
1️⃣ **Addition Expert**: Handles addition problems.  
2️⃣ **Multiplication Expert**: Handles multiplication problems.  

#### **Running the Graph with a Math Expression**
```python
for chunk in graph.stream(
    {"messages": [("user", "what's (3 + 5) * 12")]},
):
    pretty_print_messages(chunk)
```

### 🔹 **Expected Output**  

1️⃣ **Addition Expert Processes the Request**  
```
Update from node addition_expert:
AI Message:
Let me help break this down:
First, I'll handle the addition part: 
3 + 5 = 8
Now, I'll transfer the multiplication to the multiplication expert.
```

2️⃣ **Multiplication Expert Receives the Handoff**  
```
Update from node multiplication_expert:
AI Message:
Now that I have the result of 3 + 5 = 8, I can multiply:
8 * 12 = 96
```

### ✅ **Final Answer**  
```
(3 + 5) * 12 = 96
```
This demonstrates how handoff tools allow different agents to collaborate in solving a problem!

---

## 🏆 **Key Takeaways**  

✅ **Handoff tools** allow smooth task transfers between agents.  
✅ They help in **multi-agent collaboration**, ensuring that the right agent handles the right task.  
✅ Using **LangGraph**, we can structure a parent-child graph where different agents communicate effectively.  
✅ The system **maintains chat history**, making interactions seamless.  
✅ Handoffs are widely used in **customer support, AI-powered tutoring, and multi-step problem-solving systems**.  

---

## 🎯 **Next Steps**  

Now that we've learned how to implement handoffs, we can:  
📌 Improve the system by **storing previous answers** to avoid redundant calculations.  
📌 Use **AI-powered decision-making** to determine which agent should handle a request dynamically.  
📌 Extend this concept to **real-world applications**, such as AI chatbots and virtual assistants.  

Would you like to see an advanced example where agents communicate based on probabilities or external API calls? 🚀

---


Here's a detailed, beginner-friendly explanation of **Using a Custom Agent with Handoff Tools in LangChain** with real-world use cases, a breakdown of the code, and explanations for each part.  

---

# 🔹 **Using a Custom Agent with Handoff Tools in LangChain**  

## 📌 **Introduction**  
LangChain is a powerful framework for building AI applications that interact with tools. In this tutorial, we'll implement a **custom agent** that can perform tool-based operations and demonstrate **handoff tools**, which allow one agent to transfer tasks to another.  

By the end of this guide, you'll understand:  
✅ What LangChain agents are.  
✅ How to create a custom agent that calls tools.  
✅ How agents can collaborate using handoff tools.  

---

# 🏗 **Understanding the Concept of Agents and Tools**  

### 🔹 **What is an Agent in LangChain?**  
An **agent** is an AI model that can take in user queries, reason about them, and interact with tools to generate responses.  

### 🔹 **What are Tools in LangChain?**  
A **tool** is a function that performs a specific task, such as solving a math problem, retrieving data, or interacting with an API.  

### 🔹 **What is a Handoff Tool?**  
A **handoff tool** allows one agent to delegate part of a task to another specialized agent. This is useful when breaking down complex queries into smaller tasks handled by different agents.

---

# 🌍 **Real-World Use Case: AI Assistants in a Helpdesk System**  
Imagine an AI-powered customer support chatbot. Instead of one agent handling everything, we can split tasks:  
🔹 **Billing Agent** for payment-related queries.  
🔹 **Technical Support Agent** for troubleshooting.  
🔹 **General Inquiry Agent** for FAQs.  

With **handoff tools**, the chatbot can transfer customer queries to the right specialist agent, improving efficiency.

---

# 🛠 **Building a Custom Agent in LangChain**  

### 🔹 **Step 1: Import Required Modules**
We need various modules to define our agents and tools.

```python
from typing_extensions import Literal  # For type hinting
from langchain_core.messages import ToolMessage  # Handles tool responses
from langchain_core.tools import tool  # Defines tools
from langgraph.graph import MessagesState, StateGraph, START  # Manages state in the conversation flow
from langgraph.types import Command  # Defines agent actions
```

---

### 🔹 **Step 2: Define the Custom Agent**
The `make_agent` function creates an agent that interacts with tools.

```python
def make_agent(model, tools, system_prompt=None):
    model_with_tools = model.bind_tools(tools)  # Bind model with tools
    tools_by_name = {tool.name: tool for tool in tools}  # Store tools in a dictionary

    def call_model(state: MessagesState) -> Command[Literal["call_tools", "__end__"]]:
        messages = state["messages"]
        if system_prompt:
            messages = [{"role": "system", "content": system_prompt}] + messages  # Add system instructions
        
        response = model_with_tools.invoke(messages)  # Get model's response
        if len(response.tool_calls) > 0:  # Check if model wants to call tools
            return Command(goto="call_tools", update={"messages": [response]})
        
        return {"messages": [response]}  # If no tools are needed, return response

    def call_tools(state: MessagesState) -> Command[Literal["call_model"]]:
        tool_calls = state["messages"][-1].tool_calls  # Get last tool calls
        results = []
        for tool_call in tool_calls:
            tool_ = tools_by_name[tool_call["name"]]  # Get tool from dictionary
            tool_response = tool_.invoke(tool_call)  # Call the tool
            
            if isinstance(tool_response, ToolMessage):  
                results.append(Command(update={"messages": [tool_response]}))  # Append tool response
            elif isinstance(tool_response, Command):
                results.append(tool_response)  # If response is another command, add it
        
        return results  # Return updated results

    # Define the state graph (workflow for the agent)
    graph = StateGraph(MessagesState)
    graph.add_node(call_model)
    graph.add_node(call_tools)
    graph.add_edge(START, "call_model")  # Start with call_model
    graph.add_edge("call_tools", "call_model")  # After calling tools, go back to model

    return graph.compile()  # Compile the agent workflow
```

📌 **Explanation:**  
✅ This function sets up an agent that can process messages and call appropriate tools.  
✅ If the AI model detects that a tool is required, it calls the relevant function.  
✅ It then returns either a tool response or proceeds with the conversation.  

---

### 🔹 **Step 3: Define Math Tools (Addition & Multiplication)**
We create tools for simple math operations.

```python
@tool
def add(a: int, b: int) -> int:
    """Adds two numbers."""
    return a + b

@tool
def multiply(a: int, b: int) -> int:
    """Multiplies two numbers."""
    return a * b
```

📌 **Explanation:**  
✅ The `@tool` decorator defines tools in LangChain.  
✅ These functions return the sum and product of two numbers, respectively.  

---

### 🔹 **Step 4: Test the Agent**
Now, we create an agent and test it with a query.

```python
agent = make_agent(model, [add, multiply])  # Create agent with math tools

for chunk in agent.stream({"messages": [("user", "what's (3 + 5) * 12")]}):
    pretty_print_messages(chunk)  # Display responses
```

📌 **Expected Output:**  
✅ The agent first calls the `add` tool to compute **3 + 5 = 8**.  
✅ It then calls the `multiply` tool to compute **8 * 12 = 96**.  
✅ Finally, it responds with **96** as the result.  

---

# 🔁 **Using Handoff Tools for Multi-Agent Collaboration**
Now, let's split the tasks between two agents:  
✅ **Addition Expert** handles addition.  
✅ **Multiplication Expert** handles multiplication.  

```python
addition_expert = make_agent(
    model,
    [add, make_handoff_tool(agent_name="multiplication_expert")],
    system_prompt="You are an addition expert, you can ask the multiplication expert for help with multiplication.",
)

multiplication_expert = make_agent(
    model,
    [multiply, make_handoff_tool(agent_name="addition_expert")],
    system_prompt="You are a multiplication expert, you can ask an addition expert for help with addition.",
)

builder = StateGraph(MessagesState)
builder.add_node("addition_expert", addition_expert)
builder.add_node("multiplication_expert", multiplication_expert)
builder.add_edge(START, "addition_expert")  # Start with addition expert
graph = builder.compile()
```

📌 **Explanation:**  
✅ The **addition expert** can handle addition but delegates multiplication.  
✅ The **multiplication expert** can handle multiplication but delegates addition.  
✅ **StateGraph** connects the two agents.  

---

### 🔹 **Step 6: Run Multi-Agent Collaboration**
```python
for chunk in graph.stream({"messages": [("user", "what's (3 + 5) * 12")]}, subgraphs=True):
    pretty_print_messages(chunk)
```

📌 **Expected Behavior:**  
🔹 The **addition expert** calculates **3 + 5 = 8** and hands off multiplication.  
🔹 The **multiplication expert** calculates **8 * 12 = 96** and returns the final answer.  

---

# 🎯 **Conclusion**
✅ **Agents** can process user queries and interact with tools.  
✅ **Handoff tools** enable **multi-agent collaboration**, improving efficiency.  
✅ This approach is useful in **AI-powered customer support, financial advisors, and automated workflow management**.  

Would you like to extend this example with **more advanced tools**, such as API integrations or database queries? 🚀

# 🚀 Understanding Prebuilt ReAct Agent in LangGraph  

ReAct (Reasoning + Acting) is a framework that allows AI models to reason about problems and act accordingly by using tools. In this guide, we will break down how to use a **prebuilt ReAct agent** in LangGraph to handle mathematical operations like **addition** and **multiplication**, step by step.  

---

## 📌 **What is a Prebuilt ReAct Agent?**  
A **prebuilt ReAct agent** is a ready-made agent that uses **ToolNode** to perform specific tasks. If you don’t need deep customization, you can use `create_react_agent`, which simplifies the process of defining and managing agents that interact with each other.

### **🔹 Real-World Use Case**  
This concept can be applied in **modular AI assistants** that need specialized agents for different tasks. For example:
- **Customer Support Bots**: One agent handles billing inquiries, while another handles technical support.
- **AI Tutors**: One agent can specialize in **math**, another in **science**, and they collaborate to answer complex queries.

---

## 🛠 **Code Implementation of Prebuilt ReAct Agent**  

Let's break down the code for creating and using a **prebuilt ReAct agent** that can handle addition and multiplication.

### **📌 Step 1: Import Necessary Modules**
```python
from langgraph.prebuilt import create_react_agent
```
🔍 **Explanation**:  
- `create_react_agent` is a function from **LangGraph** that allows us to quickly create a **ReAct agent** with built-in tool support.

---

### **📌 Step 2: Define Addition and Multiplication Experts**
```python
addition_expert = create_react_agent(
    model,
    [add, make_handoff_tool(agent_name="multiplication_expert")],
    prompt="You are an addition expert, you can ask the multiplication expert for help with multiplication.",
)
```
🔍 **Explanation**:  
- `create_react_agent(model, tools, prompt)` creates an agent that:
  - Uses a given **model**.
  - Can execute **addition (`add`)**.
  - Can **handoff** multiplication tasks to the `multiplication_expert`.
  - **Prompt defines** its role as an "addition expert".

---

```python
multiplication_expert = create_react_agent(
    model,
    [multiply, make_handoff_tool(agent_name="addition_expert")],
    prompt="You are a multiplication expert, you can ask an addition expert for help with addition.",
)
```
🔍 **Explanation**:  
- This creates a **multiplication expert** that:
  - Performs **multiplication (`multiply`)**.
  - Can **handoff addition tasks** to the `addition_expert`.

**🤖 How They Work Together:**  
- If a problem involves **both addition and multiplication**, the **addition expert** solves the addition part and then **passes the result** to the multiplication expert.

---

### **📌 Step 3: Define the State Graph**
```python
builder = StateGraph(MessagesState)
builder.add_node("addition_expert", addition_expert)
builder.add_node("multiplication_expert", multiplication_expert)
builder.add_edge(START, "addition_expert")
graph = builder.compile()
```
🔍 **Explanation**:  
- `StateGraph(MessagesState)`: Creates a **graph-based structure** where each agent acts as a **node**.
- `add_node("addition_expert", addition_expert)`: Adds the **addition expert** to the graph.
- `add_node("multiplication_expert", multiplication_expert)`: Adds the **multiplication expert**.
- `add_edge(START, "addition_expert")`: Defines that the **starting point** of our system is the **addition expert**.
- `graph = builder.compile()`: Compiles the **graph** so that agents can interact.

---

## 🎯 **Running the ReAct Agent**
```python
for chunk in graph.stream(
    {"messages": [("user", "what's (3 + 5) * 12")]}, subgraphs=True
):
    pretty_print_messages(chunk)
```
🔍 **Explanation**:  
- `graph.stream({"messages": [...]})`: Passes a **user query** to the agent.
- The query **"what's (3 + 5) * 12"** is processed step-by-step:
  1. **Addition expert** solves `3 + 5 = 8`.
  2. **Multiplication expert** receives `8` and computes `8 * 12 = 96`.

---

## 🏆 **Final Output Breakdown**
```plaintext
User: what's (3 + 5) * 12?
Addition Expert: I will calculate 3 + 5.
Addition Tool: The result is 8.
Multiplication Expert: Now, I will multiply 8 by 12.
Multiplication Tool: The final result is 96.
```
🔍 **Explanation**:  
- The system **delegates tasks** to the right expert.
- **Each agent solves only what it is trained for**.
- The final answer is **96**.

---

## 🎯 **Why Use Prebuilt ReAct Agents?**
✅ **Modular AI Systems**: Different agents specialize in different tasks.  
✅ **Scalability**: More experts can be added (e.g., **division, subtraction**).  
✅ **Flexibility**: You can switch experts or enhance their logic easily.  

---

## 📌 **Real-World Applications**
🔹 **AI-powered Customer Support** (Agents for billing, tech support, product info).  
🔹 **AI Tutors** (Math, Science, History experts collaborating).  
🔹 **Automated Financial Calculators** (Handling different types of computations).  

---

## 🏁 **Conclusion**  
With **LangGraph's prebuilt ReAct agent**, you can **quickly build AI systems** that **reason and act collaboratively**. By using **specialized experts**, you can create **intelligent, modular AI assistants** capable of **solving complex tasks step by step**. 🚀