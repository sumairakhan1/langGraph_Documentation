# 3. How to add multi-turn conversation in a multi-agent application

That’s a detailed topic, and I’ll make sure to explain it in a structured way with beginner-friendly explanations, real-world applications, code breakdowns, and step-by-step explanations. I’ll organize it using clear headings and icons to make it visually appealing.  

Give me a moment to draft this for you.

Here's a detailed and beginner-friendly guide on **How to Add Multi-Turn Conversation in a Multi-Agent Application**, including explanations, real-world applications, code breakdown, and visual enhancements.  

---

# 🔹 How to Add Multi-Turn Conversation in a Multi-Agent Application

## 🏆 **Introduction**
Multi-turn conversation in a multi-agent system allows users to interact with multiple agents that handle different tasks. Each agent has specialized knowledge and can route queries to another agent when needed.

This guide will help you build an AI-powered chatbot system where:
✅ **Users can engage in a multi-turn conversation.**  
✅ **Agents communicate with each other based on user input.**  
✅ **Agents transfer conversations when necessary.**  

We'll be using **LangGraph** (a framework for conversational AI workflows) and **LangChain** to integrate AI models.

---

## 🌎 **Real-World Applications**
Multi-turn conversations with multiple agents are used in:  
💼 **Customer Support Bots** – Handling queries across different departments (billing, tech support).  
🧳 **Travel Assistants** – One agent helps with destinations, another with hotels.  
📞 **AI-powered Call Centers** – Routing customer calls to the right support agent.  
🏥 **Healthcare Chatbots** – One agent checks symptoms, another schedules appointments.  

---

# 🛠 **1. Setting Up the Environment**
### 📌 Install Required Packages
We need to install the necessary dependencies:  
```python
%pip install -U langgraph langchain-anthropic
```

### 📌 Set API Key for Anthropic AI (Claude Model)
We use **Anthropic's Claude** as the AI model.  
```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("ANTHROPIC_API_KEY")
```
This secures our API key input.

---

# 🏗 **2. Defining Multi-Agent Roles**
We'll create **two AI agents** that work together:

1️⃣ **Travel Advisor** – Suggests travel destinations.  
2️⃣ **Hotel Advisor** – Recommends hotels for a selected destination.  

Each agent can **handoff** the conversation to the other if required.

## 📌 Define Tools for Agents
### ✈️ Travel Recommendations  
```python
import random
from typing import Literal
from langchain_core.tools import tool

@tool
def get_travel_recommendations():
    """Get recommendations for travel destinations"""
    return random.choice(["Aruba", "Turks and Caicos"])
```
✅ **Explanation:**  
- This function picks a random travel destination when called.  
- `@tool` makes it a callable tool within the agent.

---

### 🏨 Hotel Recommendations  
```python
@tool
def get_hotel_recommendations(location: Literal["Aruba", "Turks and Caicos"]):
    """Get hotel recommendations for a given destination."""
    return {
        "Aruba": ["The Ritz-Carlton, Aruba", "Bucuti & Tara Beach Resort"],
        "Turks and Caicos": ["Grace Bay Club", "COMO Parrot Cay"],
    }[location]
```
✅ **Explanation:**  
- The function provides **hotels based on a selected destination**.  
- It checks if the location is **Aruba or Turks and Caicos** and returns relevant hotels.  

---

## 📌 **Handoff Mechanism Between Agents**
When an agent **needs help** from another, it calls a special tool:

```python
from langgraph.prebuilt import InjectedState
from langchain_core.tools.base import InjectedToolCallId

def make_handoff_tool(agent_name: str):
    """Create a tool for transferring conversation to another agent."""
    tool_name = f"transfer_to_{agent_name}"

    @tool(tool_name)
    def handoff_to_agent(
        state: dict,
        tool_call_id: InjectedToolCallId,
    ):
        """Transfers the conversation to another agent."""
        tool_message = {
            "role": "tool",
            "content": f"Successfully transferred to {agent_name}",
            "name": tool_name,
            "tool_call_id": tool_call_id,
        }
        return Command(goto=agent_name, update={"messages": state["messages"] + [tool_message]})
    
    return handoff_to_agent
```
✅ **Explanation:**  
- This function creates a **handoff tool** that transfers the conversation.  
- It **stores messages** and **routes the user to the correct agent**.  

---

# 🤖 **3. Creating AI Agents**
We now define **travel_advisor** and **hotel_advisor** agents.

## 📌 **Travel Advisor Agent**
```python
from langchain_anthropic import ChatAnthropic
from langgraph.prebuilt import create_react_agent

model = ChatAnthropic(model="claude-3-5-sonnet-latest")

travel_advisor_tools = [
    get_travel_recommendations,
    make_handoff_tool(agent_name="hotel_advisor"),
]

travel_advisor = create_react_agent(
    model,
    travel_advisor_tools,
    prompt=(
        "You are a travel expert who suggests destinations."
        "If asked about hotels, transfer to 'hotel_advisor'."
    ),
)
```
✅ **Explanation:**  
- Uses **Claude AI** as the model.  
- Calls **get_travel_recommendations** to suggest destinations.  
- Calls **handoff_tool** if hotels are needed.  

---

## 📌 **Hotel Advisor Agent**
```python
hotel_advisor_tools = [
    get_hotel_recommendations,
    make_handoff_tool(agent_name="travel_advisor"),
]

hotel_advisor = create_react_agent(
    model,
    hotel_advisor_tools,
    prompt=(
        "You are a hotel expert. Provide hotel recommendations."
        "If asked about travel destinations, transfer to 'travel_advisor'."
    ),
)
```
✅ **Explanation:**  
- Calls **get_hotel_recommendations** when asked about hotels.  
- Transfers to `travel_advisor` if asked about destinations.  

---

# 🔄 **4. Managing User Input**
We create a **human node** to collect user input.

```python
from langgraph.types import Command, interrupt
from langgraph.graph import MessagesState

def human_node(state: MessagesState, config) -> Command:
    """Handles user input and routes to active agent."""
    user_input = interrupt(value="Ready for user input.")

    # Identify last active agent
    active_agent = config["metadata"]["langgraph_triggers"][0].split(":")[1]

    return Command(
        update={"messages": [{"role": "human", "content": user_input}]},
        goto=active_agent,
    )
```
✅ **Explanation:**  
- Waits for **user input**.  
- **Identifies last active agent** to resume conversation.  

---

# 📌 **5. Building the Conversation Graph**
Now we **connect** everything in a **state graph**.

```python
from langgraph.graph import StateGraph, START
from langgraph.checkpoint.memory import MemorySaver

builder = StateGraph(MessagesState)
builder.add_node("travel_advisor", call_travel_advisor)
builder.add_node("hotel_advisor", call_hotel_advisor)
builder.add_node("human", human_node)

builder.add_edge(START, "travel_advisor")

checkpointer = MemorySaver()
graph = builder.compile(checkpointer=checkpointer)
```
✅ **Explanation:**  
- **Defines the conversation flow.**  
- **Starts with** `travel_advisor`.  
- **Adds human interaction and handoff between agents.**  

---

# 🏁 **6. Testing the Multi-Turn Conversation**
Let's simulate a **real conversation**.

```python
import uuid

thread_config = {"configurable": {"thread_id": uuid.uuid4()}}

inputs = [
    {"messages": [{"role": "user", "content": "I want to visit a warm place"}]},
    Command(resume="Can you recommend a hotel?"),
    Command(resume="What activities are available nearby?"),
]

for idx, user_input in enumerate(inputs):
    print(f"--- Conversation Turn {idx + 1} ---")
    for update in graph.stream(user_input, config=thread_config, stream_mode="updates"):
        for node_id, value in update.items():
            if isinstance(value, dict) and "messages" in value:
                print(f"{node_id}: {value['messages'][-1]}")
```
✅ **Explanation:**  
- Simulates **multi-turn user interaction**.  
- Transfers between **travel advisor** and **hotel advisor** as needed.  

---

# 🎯 **Conclusion**
✅ We created a **multi-turn chatbot** using LangGraph.  
✅ Implemented **handoff between AI agents** for different tasks.  
✅ Built a **stateful conversation** flow.  

This approach can be **extended** for customer service, travel assistance, and more!

🚀 **Next Steps:** Try adding **more agents** like **Restaurant Advisor**! 🎉

### 📌 **Where is Multi-Turn Conversation Implemented in the Multi-Agent System?**  

In the multi-agent chatbot system we built, **multi-turn conversation is implemented through state management, agent handoff, and user interaction handling**. The following components enable multi-turn conversation:  

---

### **1️⃣ Human Node – Capturing User Input Across Multiple Turns**  
The **human node** ensures that the system waits for user input before continuing the conversation. This allows the conversation to be multi-turn, where the user can interact with different agents dynamically.  

#### **Code Implementation:**
```python
def human_node(state: MessagesState, config) -> Command:
    """Handles user input and routes to active agent."""
    user_input = interrupt(value="Ready for user input.")

    # Identify last active agent
    active_agent = config["metadata"]["langgraph_triggers"][0].split(":")[1]

    return Command(
        update={"messages": [{"role": "human", "content": user_input}]},
        goto=active_agent,
    )
```
✅ **How This Enables Multi-Turn Conversations:**  
- The function **waits for the user to respond** before proceeding.  
- It keeps track of the **active agent** handling the conversation.  
- It **routes the user back to the correct agent** instead of restarting.  

---

### **2️⃣ Agent Handoff – Switching Between Agents Mid-Conversation**  
Each agent has a built-in **handoff mechanism** that allows it to transfer the conversation when necessary. This is crucial for multi-turn interactions because different agents might be needed as the conversation evolves.  

#### **Code Implementation:**
```python
def make_handoff_tool(agent_name: str):
    """Create a tool for transferring conversation to another agent."""
    tool_name = f"transfer_to_{agent_name}"

    @tool(tool_name)
    def handoff_to_agent(
        state: dict,
        tool_call_id: InjectedToolCallId,
    ):
        """Transfers the conversation to another agent."""
        tool_message = {
            "role": "tool",
            "content": f"Successfully transferred to {agent_name}",
            "name": tool_name,
            "tool_call_id": tool_call_id,
        }
        return Command(goto=agent_name, update={"messages": state["messages"] + [tool_message]})

    return handoff_to_agent
```
✅ **How This Enables Multi-Turn Conversations:**  
- When a user **asks a question that another agent should handle**, the handoff function **transfers control to the right agent**.  
- It **preserves past messages** to maintain conversation history.  
- Users can **switch between agents** without restarting the conversation.  

Example scenario:
1. **User:** "I want to travel somewhere warm."  
   - **Travel Agent:** "I recommend Aruba or Turks and Caicos."  
2. **User:** "Can you recommend a hotel?"  
   - **Travel Agent → Handoff to Hotel Agent**  
   - **Hotel Agent:** "I recommend The Ritz-Carlton, Aruba or Bucuti & Tara Beach Resort."  

This **seamless agent transition** makes multi-turn conversation possible.

---

### **3️⃣ Conversation State Graph – Managing Dialogue Flow**
A **state graph** is used to define how the conversation progresses between agents and how user input is handled. The system remembers where the conversation left off and picks up from there instead of restarting.  

#### **Code Implementation:**
```python
from langgraph.graph import StateGraph, START
from langgraph.checkpoint.memory import MemorySaver

builder = StateGraph(MessagesState)

# Adding nodes for each agent and human interaction
builder.add_node("travel_advisor", call_travel_advisor)
builder.add_node("hotel_advisor", call_hotel_advisor)
builder.add_node("human", human_node)

# Starting point of the conversation
builder.add_edge(START, "travel_advisor")

# Enables stateful conversation storage
checkpointer = MemorySaver()
graph = builder.compile(checkpointer=checkpointer)
```
✅ **How This Enables Multi-Turn Conversations:**  
- The system **tracks the user’s conversation state** to avoid repetition.  
- Users can **return to the previous topic** or **continue with a different agent**.  
- **Edges define the possible transitions** (e.g., start with Travel Advisor, then go to Hotel Advisor).  

---

### **4️⃣ Testing Multi-Turn Conversation**
To verify that the multi-turn interaction works correctly, we simulate multiple user inputs:  

#### **Code Implementation:**
```python
import uuid

thread_config = {"configurable": {"thread_id": uuid.uuid4()}}

inputs = [
    {"messages": [{"role": "user", "content": "I want to visit a warm place"}]},
    Command(resume="Can you recommend a hotel?"),
    Command(resume="What activities are available nearby?"),
]

for idx, user_input in enumerate(inputs):
    print(f"--- Conversation Turn {idx + 1} ---")
    for update in graph.stream(user_input, config=thread_config, stream_mode="updates"):
        for node_id, value in update.items():
            if isinstance(value, dict) and "messages" in value:
                print(f"{node_id}: {value['messages'][-1]}")
```
✅ **How This Enables Multi-Turn Conversations:**  
- **Each input builds on the previous one**, creating a natural dialogue flow.  
- **The system remembers past inputs and responses**, so users don’t have to repeat themselves.  
- The agent switches between **travel recommendations → hotel recommendations → additional questions** without breaking context.  

---

### **📌 Summary – Where Multi-Turn Conversation is Implemented**
| **Component** | **Purpose in Multi-Turn Conversation** |
|--------------|--------------------------------|
| **Human Node** | Captures user input across multiple turns, ensuring continuous conversation. |
| **Agent Handoff** | Allows seamless switching between different agents based on user queries. |
| **State Graph** | Maintains conversation history and directs user input to the correct agent. |
| **Thread-Based Testing** | Simulates multi-turn interactions to validate the system's statefulness. |

---

### **🚀 Final Thoughts**
✅ **Multi-turn conversation is implemented** using state tracking, agent handoff, and dynamic user input handling.  
✅ The **conversation feels natural**, as users can move between topics and agents without restarting.  
✅ This approach **can be extended** to multiple domains, such as customer support, AI chatbots, and automated virtual assistants.

Would you like to add **more advanced features** like **memory persistence** (so the bot remembers the conversation even after a session ends)? 🚀

# o3 mini:

# 🔄 Multi-Turn Conversations in a Multi-Agent Application

In this guide, we'll build an application that lets an end-user engage in a **multi-turn conversation** with one or more agents. Our system uses a special **human node** that waits for user input (an **interrupt**) and then routes the conversation back to the active agent. This approach enables a back-and-forth dialogue between the user and various specialized agents.

> **Real-World Example:**  
> Imagine a travel assistant chatbot on a travel website.  
> - **Travel Advisor Agent:** Recommends travel destinations.  
> - **Hotel Advisor Agent:** Provides hotel recommendations.  
>  
> In a real scenario, a user might start with a general query like, "I want to go somewhere warm." The Travel Advisor answers, then—if the user asks for hotel details—the conversation is handed over to the Hotel Advisor. Later, if the user asks follow-up questions, the system collects the input and routes it back to the appropriate agent. This back-and-forth is known as a **multi-turn conversation**.

---

## 🛠️ System Overview

Our system consists of:
- **Agent Nodes:** Nodes representing specialized agents (e.g., travel_advisor, hotel_advisor).  
- **Human Node:** A node that waits for user input (using an interrupt) and routes the conversation back to the active agent.
- **Handoffs:** Mechanism for switching control from one agent to another.

Below is a detailed explanation with code examples and step-by-step comments.

---

## 📖 Code Example & Explanation

### 1. **Define the Human Node**

This node collects user input during a conversation turn and routes control back to the active agent.

```python
def human(state: MessagesState) -> Command[Literal["agent", "another_agent"]]:
    """A node for collecting user input."""
    # Wait for user input. This simulates an interrupt where the system stops to get input.
    user_input = interrupt(value="Ready for user input.")

    # Determine the active agent based on the configuration metadata.
    # Here, we extract the last active agent from a metadata field.
    langgraph_triggers = config["metadata"]["langgraph_triggers"]
    if len(langgraph_triggers) != 1:
        raise AssertionError("Expected exactly 1 trigger in human node")

    # Extract the active agent from the trigger string (format: "<something>:<active_agent>")
    active_agent = langgraph_triggers[0].split(":")[1]

    # Return a Command that updates the conversation state with the human's input,
    # then routes the conversation back to the active agent.
    return Command(
        update={
            "messages": [{
                "role": "human",
                "content": user_input,
            }]
        },
        goto=active_agent
    )
```

**Explanation of Each Line:**
- **Function Definition:**  
  `def human(state: MessagesState) -> Command[Literal["agent", "another_agent"]]:`  
  - Defines a node called **human** that accepts the current state and returns a Command object indicating which agent to route to next.
  
- **Interrupt for User Input:**  
  `user_input = interrupt(value="Ready for user input.")`  
  - The `interrupt` function pauses execution to collect input from the user.
  
- **Determine Active Agent:**  
  ```python
  langgraph_triggers = config["metadata"]["langgraph_triggers"]
  if len(langgraph_triggers) != 1:
      raise AssertionError("Expected exactly 1 trigger in human node")
  active_agent = langgraph_triggers[0].split(":")[1]
  ```  
  - **`config["metadata"]["langgraph_triggers"]`**: Retrieves metadata that tracks which agent was last active.
  - **Validation:** Ensures there is exactly one active trigger.
  - **Extract Active Agent:** Parses the trigger string to determine the active agent.
  
- **Return Command Object:**  
  ```python
  return Command(
      update={"messages": [{"role": "human", "content": user_input}]},
      goto=active_agent
  )
  ```  
  - **`update`:** Adds the human's input to the conversation history.
  - **`goto`:** Routes control back to the active agent for the next conversation turn.

---

### 2. **Define an Agent Node**

This is an example agent node. It processes the conversation and either continues its dialogue or hands off to another agent.

```python
def agent(state) -> Command[Literal["agent", "another_agent", "human"]]:
    # Determine which agent to call next. This decision can be based on any logic,
    # such as LLM tool calls or structured output.
    goto = get_next_agent(...)  # For example, this returns 'agent' or 'another_agent'
    
    # If a specific agent is determined, return a Command to route there,
    # while updating the state with new information.
    if goto:
        return Command(goto=goto, update={"my_state_key": "my_state_value"})
    else:
        # If no specific agent is chosen, route to the human node to collect more input.
        return Command(goto="human")
```

**Explanation of Each Line:**
- **Function Definition:**  
  `def agent(state) -> Command[Literal["agent", "another_agent", "human"]]:`  
  - Defines an agent node that processes the conversation state and returns a Command object.
  
- **Determine Next Agent:**  
  `goto = get_next_agent(...)`  
  - Placeholder function that decides which agent should handle the next turn.
  
- **Return Command Based on Decision:**  
  ```python
  if goto:
      return Command(goto=goto, update={"my_state_key": "my_state_value"})
  else:
      return Command(goto="human")
  ```  
  - If an agent is chosen (e.g., another specialized agent), the system updates the state and routes control there.
  - If not, it falls back to the human node to get more user input.

---

### 3. **Setting Up the Multi-Agent Graph**

Now we combine the human and agent nodes into a multi-agent network using a **StateGraph**.

```python
from langgraph.graph import MessagesState, StateGraph, START
from langgraph.types import Command, interrupt

builder = StateGraph(MessagesState)

# Add our agent node that processes conversation turns.
builder.add_node("agent", agent)

# Add our human node to collect user input.
builder.add_node("human", human)

# Set the starting point of our conversation to the agent node.
builder.add_edge(START, "agent")

# Compile the graph to create our multi-agent conversation system.
graph = builder.compile()
```

**Explanation of Each Line:**
- **StateGraph Initialization:**  
  `builder = StateGraph(MessagesState)`  
  - Creates a graph that manages conversation state using messages.
  
- **Add Nodes:**  
  ```python
  builder.add_node("agent", agent)
  builder.add_node("human", human)
  ```  
  - Adds the **agent** node and **human** node to the graph.
  
- **Define Starting Point:**  
  `builder.add_edge(START, "agent")`  
  - Sets the conversation to start with the **agent** node.
  
- **Compile the Graph:**  
  `graph = builder.compile()`  
  - Finalizes the graph so it can execute the multi-turn conversation.

---

## 💬 Running a Multi-Turn Conversation

With our multi-agent graph set up, we can simulate a conversation that involves multiple turns. The conversation flow works as follows:
1. **Agent Node:** Processes the conversation and provides an answer.
2. **Human Node:** Waits for further user input via an interrupt.
3. **Routing:** Depending on the response, the conversation is routed back to the active agent for another turn.

### **Example: Simulated Conversation**

```python
import uuid

# Thread configuration to uniquely identify the conversation thread.
thread_config = {"configurable": {"thread_id": uuid.uuid4()}}

# Define conversation turns. In a real scenario, these would be provided by the user.
inputs = [
    # Turn 1: Initial conversation input.
    {
        "messages": [
            {"role": "user", "content": "I wanna go somewhere warm in the Caribbean."}
        ]
    },
    # Turn 2: System resumes with user input after interrupt.
    Command(resume="Could you recommend a nice hotel in that area and tell me which area it is?"),
    # Turn 3: Follow-up user input.
    Command(resume="I like the first option. What fun activities are available near the hotel?")
]

# Execute each turn of the conversation.
for idx, user_input in enumerate(inputs):
    print(f"\n--- Conversation Turn {idx + 1} ---\n")
    print(f"User: {user_input}\n")
    for update in graph.stream(
        user_input,
        config=thread_config,
        stream_mode="updates",
    ):
        # Print the final AI message from the current active node.
        for node_id, value in update.items():
            if isinstance(value, dict) and value.get("messages", []):
                last_message = value["messages"][-1]
                # Skip non-AI messages (e.g., human inputs or tool messages)
                if isinstance(last_message, dict) and last_message.get("role") == "ai":
                    print(f"{node_id}: {last_message['content']}")
```

**Explanation of Each Section:**
- **Thread Configuration:**  
  ```python
  thread_config = {"configurable": {"thread_id": uuid.uuid4()}}
  ```  
  - Creates a unique thread identifier to manage conversation context.
  
- **Conversation Inputs:**  
  ```python
  inputs = [ ... ]
  ```  
  - Simulates a series of conversation turns:
    - The first input is a direct query from the user.
    - The next turns use `Command(resume=...)` to simulate resuming the conversation after an interrupt.
  
- **Graph Streaming:**  
  ```python
  for update in graph.stream(user_input, config=thread_config, stream_mode="updates"):
      ...
  ```  
  - Streams the conversation through the graph.
  - The system prints updates from the active node (either the agent or the human node).

---

## 🚀 Key Takeaways

- **Multi-Turn Conversations:**  
  This technique allows an application to handle back-and-forth dialogue, collecting user input as needed and routing it appropriately.

- **Agents & Human Node:**  
  - **Agent nodes** perform specialized tasks.
  - The **human node** collects new user input via interrupts.

- **Handoffs:**  
  Agents can hand off control to one another based on logic, ensuring a modular and flexible conversation system.

- **Real-World Application:**  
  Such a system is ideal for applications like customer support, travel planning, or any interactive service where ongoing dialogue is essential.

---

With these building blocks, you can now create robust multi-turn conversation systems in a multi-agent network. This architecture makes your application both interactive and highly modular, allowing specialized agents to collaborate seamlessly with human input. Happy coding!