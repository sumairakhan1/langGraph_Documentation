# 2. How to build a multi-agent network

Here‚Äôs a detailed and beginner-friendly guide on **how to build a multi-agent network**, including real-world applications, code explanations, and best practices.  

---

# üåê **How to Build a Multi-Agent Network**  

A **multi-agent network** is a system where multiple agents (programs or AI models) work together, communicating and collaborating to solve tasks. In this guide, we will create a **multi-agent network using Python** where agents can communicate **many-to-many** and decide which agent to call next.  

## üöÄ **Real-World Applications of Multi-Agent Networks**  

Multi-agent systems are widely used in various domains, such as:  

- **Customer Support Chatbots** ü§ñüìû ‚Äì One chatbot handles general queries, another handles technical issues, and another handles billing.  
- **Healthcare Systems** üè• ‚Äì One AI model collects patient symptoms, another suggests possible diagnoses, and another provides medication advice.  
- **Smart Traffic Systems** üö¶üöó ‚Äì Sensors communicate with each other to optimize traffic flow.  
- **Financial Fraud Detection** üí≥üö® ‚Äì Multiple AI agents analyze different aspects of transactions to detect fraud.  

---

## üîß **Step 1: Installing Required Packages**  

Before starting, install the required libraries:  

```bash
pip install -U langgraph langchain-anthropic
```

These libraries help build AI-powered conversational agents using **LangGraph** and **Anthropic's Claude model**.  

---

## üîë **Step 2: Setting Up Environment Variables**  

To use the **Anthropic API**, set up an API key:  

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("ANTHROPIC_API_KEY")  # Securely store API key
```

This ensures our API key is safely stored without hardcoding it in the script.  

---

## ü§ñ **Step 3: Defining Agent Functions**  

In this example, we will create two AI agents:  

1. **Travel Advisor** ‚Äì Recommends travel destinations.  
2. **Hotel Advisor** ‚Äì Suggests hotels based on a selected destination.  

Each agent will communicate and **transfer** tasks between each other using "handoffs."

---

### üèùÔ∏è **Travel Advisor Agent**  

This agent suggests travel destinations. If the user needs hotel recommendations, it **transfers** the query to the hotel advisor.  

```python
from typing_extensions import Literal
from langchain_anthropic import ChatAnthropic
from langgraph.types import Command

# Initialize LLM model
model = ChatAnthropic(model="claude-3-5-sonnet-latest")

def travel_advisor(state):
    system_prompt = (
        "You are a travel expert. Recommend destinations based on user input. "
        "If the user asks for hotel recommendations, transfer to 'hotel_advisor'."
    )

    messages = [{"role": "system", "content": system_prompt}] + state["messages"]
    ai_msg = model.invoke(messages)

    # Check if handoff is needed
    if "hotel" in ai_msg["content"].lower():
        return Command(goto="hotel_advisor", update={"messages": [ai_msg]})

    return {"messages": [ai_msg]}
```

### üîç **Explanation**  

- The **`travel_advisor`** function takes the user‚Äôs query.  
- It checks whether **hotel recommendations** are needed.  
- If required, it **transfers** the query to the **hotel advisor** using `Command(goto="hotel_advisor")`.  

---

### üè® **Hotel Advisor Agent**  

This agent provides hotel recommendations. If the user needs **travel advice**, it transfers the task back to the travel advisor.  

```python
def hotel_advisor(state):
    system_prompt = (
        "You are a hotel expert. Recommend hotels based on the given destination. "
        "If the user needs travel recommendations, transfer to 'travel_advisor'."
    )

    messages = [{"role": "system", "content": system_prompt}] + state["messages"]
    ai_msg = model.invoke(messages)

    # Check if travel recommendations are needed
    if "destination" in ai_msg["content"].lower():
        return Command(goto="travel_advisor", update={"messages": [ai_msg]})

    return {"messages": [ai_msg]}
```

### üîç **Explanation**  

- The **`hotel_advisor`** agent provides hotel recommendations.  
- If the user asks about a **new destination**, the query is handed back to the **travel advisor**.  

---

## üìå **Step 4: Building the Multi-Agent Network**  

Now, we will connect both agents into a **graph-based structure** using **LangGraph**.  

```python
from langgraph.graph import MessagesState, StateGraph, START

# Create a graph of agents
builder = StateGraph(MessagesState)
builder.add_node("travel_advisor", travel_advisor)
builder.add_node("hotel_advisor", hotel_advisor)

# Start the conversation with travel_advisor
builder.add_edge(START, "travel_advisor")

# Compile the graph
graph = builder.compile()
```

### üîç **Explanation**  

- **StateGraph()** creates a network of agents.  
- Each **agent is added as a node** (`add_node`).  
- The **travel advisor starts the conversation** (`add_edge(START, "travel_advisor")`).  
- The **graph is compiled** and ready to run.  

---

## üé≠ **Step 5: Running the Multi-Agent Network**  

Now, let's test our **multi-agent system** by asking a question.  

```python
for chunk in graph.stream(
    {"messages": [("user", "I want to travel to the Caribbean. Can you recommend a hotel?")]}
):
    print(chunk)
```

### üñ•Ô∏è **Example Output**  

```
Update from node travel_advisor:
"Sure! How about visiting the Bahamas? Let me find hotels for you."
Handing over to hotel_advisor...
Update from node hotel_advisor:
"Here are some great hotels in the Bahamas: Atlantis Resort, Baha Mar, and The Ocean Club."
```

### üîç **Explanation**  

1. The **user asks about travel**.  
2. The **travel advisor suggests a destination**.  
3. Since **the user also asked about hotels**, the query is transferred.  
4. The **hotel advisor provides hotel recommendations**.  

---

## üéØ **Final Thoughts**  

‚úîÔ∏è **Multi-agent networks** allow AI models to collaborate.  
‚úîÔ∏è We used **LangGraph** and **Claude AI** for communication.  
‚úîÔ∏è This method is useful for **chatbots, automation, and AI workflows**.  

Would you like to expand this by adding **more agents**, such as **flight advisors or restaurant finders**? Let me know! üöÄ

---
# o3 mini  response:

# üåê How to Build a Multi-Agent Network

In this guide, we‚Äôll explore how to create a **multi-agent network** where agents can communicate with one another using **handoffs**. This architecture lets agents decide dynamically which agent to call next. In our example, we‚Äôll build a team of travel assistant agents that collaborate to provide travel and hotel recommendations.

---

## üìñ Overview

**What are Multi-Agent Networks?**  
Multi-agent networks consist of multiple agents (or nodes) that can communicate with one another. Each agent specializes in a specific task and can transfer control (or ‚Äúhandoff‚Äù) to another agent when needed.  

**Real-World Example:**  
Imagine a travel booking system:  
- A **Travel Advisor** can recommend destinations.  
- A **Hotel Advisor** can provide hotel recommendations.  
These agents work together to give you a complete travel plan. For instance, if you ask for a destination and hotel details, the travel advisor can recommend a destination and then hand off the conversation to the hotel advisor for accommodation details.

---

## üõ†Ô∏è Setup

Before we start coding, install the necessary packages and set up your environment variables. Run the following in your notebook or terminal:

```python
%%capture --no-stderr
%pip install -U langgraph langchain-anthropic
```

Then, configure your API key:

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("ANTHROPIC_API_KEY")
```

> **Note:** This sets your `ANTHROPIC_API_KEY` which is needed to use the ChatAnthropic model.

---

## üîÑ Communication via Handoffs

In our network, agents use **handoffs** to transfer control when they need help from another agent. The following code snippet shows a simplified agent function that returns a **Command** to specify which agent should handle the next part:

```python
def agent(state) -> Command[Literal["agent", "another_agent"]]:
    # The condition for routing/halting can be anything (e.g., a tool call, structured output, etc.)
    goto = get_next_agent(...)  # Determine the next agent: returns 'agent' or 'another_agent'
    return Command(
        # Specify which agent to call next
        goto=goto,
        # Update the graph state with any necessary information
        update={"my_state_key": "my_state_value"}
    )
```

> **Explanation:**  
> - `goto`: Determines the next agent based on some logic (for example, analyzing a tool call response).  
> - `update`: Passes along state data (e.g., conversation history) for the next agent to use.

---

## üß≥ Building the Travel Assistant Agents

We‚Äôll create two agents:
- **travel_advisor**: Recommends travel destinations.
- **hotel_advisor**: Recommends hotels for a given destination.

### 1. Define Helper Tools for Handoffs

These tools are used by agents to signal that they need help from another agent.

```python
from langchain_core.tools import tool

@tool
def transfer_to_travel_advisor():
    """Ask travel advisor for help."""
    # No return needed; acts as a signal to hand off.
    return

@tool
def transfer_to_hotel_advisor():
    """Ask hotel advisor for help."""
    return
```

> **Explanation:**  
> - The `@tool` decorator marks these functions as tools.  
> - They don't perform any calculations but serve as signals for handoffs.

---

### 2. Create the Agent Node Functions

Each agent node is defined as a function that uses a language model (LLM) with a custom prompt. They invoke the LLM, and if a tool call is detected, they hand off to the other agent.

#### **Travel Advisor Agent**

```python
from typing_extensions import Literal
from langchain_anthropic import ChatAnthropic
from langgraph.graph import MessagesState, StateGraph, START
from langgraph.types import Command

# Initialize the model
model = ChatAnthropic(model="claude-3-5-sonnet-latest")

def travel_advisor(state: MessagesState) -> Command[Literal["hotel_advisor", "__end__"]]:
    system_prompt = (
        "You are a general travel expert that can recommend travel destinations (e.g., countries, cities). "
        "If you need hotel recommendations, ask 'hotel_advisor' for help."
    )
    # Prepare the messages with system instructions
    messages = [{"role": "system", "content": system_prompt}] + state["messages"]
    # Invoke the model and bind the handoff tool for hotel advisor
    ai_msg = model.bind_tools([transfer_to_hotel_advisor]).invoke(messages)
    
    # Check if the model called a tool (i.e., requesting a handoff)
    if len(ai_msg.tool_calls) > 0:
        tool_call_id = ai_msg.tool_calls[-1]["id"]
        # Create a tool message to follow the expected format for LLM providers
        tool_msg = {
            "role": "tool",
            "content": "Successfully transferred",
            "tool_call_id": tool_call_id,
        }
        # Return a Command to transfer control to the hotel_advisor
        return Command(goto="hotel_advisor", update={"messages": [ai_msg, tool_msg]})

    # If no handoff is needed, simply return the AI's message as the final output.
    return {"messages": [ai_msg]}
```

> **Line-by-Line Explanation:**  
> - **Lines 1-4:** Import required modules and initialize the ChatAnthropic model.
> - **Function `travel_advisor`:**  
>   - **`system_prompt`:** Provides instructions that the agent is a travel expert and may call the hotel advisor if needed.  
>   - **`messages`:** Combines the system prompt with existing conversation history.  
>   - **`ai_msg`:** The LLM processes the messages and may issue a tool call if it needs to hand off.  
>   - **Tool Call Check:** If `ai_msg` contains a tool call, we extract the call ID, create a tool message, and return a `Command` object to hand off control to the `hotel_advisor`.  
>   - **Return Statement:** If no tool call is present, the agent directly returns the response to the user.

#### **Hotel Advisor Agent**

```python
def hotel_advisor(state: MessagesState) -> Command[Literal["travel_advisor", "__end__"]]:
    system_prompt = (
        "You are a hotel expert that can provide hotel recommendations for a given destination. "
        "If you need help picking travel destinations, ask 'travel_advisor' for help."
    )
    messages = [{"role": "system", "content": system_prompt}] + state["messages"]
    ai_msg = model.bind_tools([transfer_to_travel_advisor]).invoke(messages)
    
    if len(ai_msg.tool_calls) > 0:
        tool_call_id = ai_msg.tool_calls[-1]["id"]
        tool_msg = {
            "role": "tool",
            "content": "Successfully transferred",
            "tool_call_id": tool_call_id,
        }
        return Command(goto="travel_advisor", update={"messages": [ai_msg, tool_msg]})
    
    return {"messages": [ai_msg]}
```

> **Explanation:**  
> - This function works similarly to the travel advisor.  
> - It uses a custom prompt to define itself as a hotel expert.  
> - If the model indicates it needs help (via a tool call), it returns a `Command` to hand off control to the travel advisor.

---

### 3. Combine Agents into a State Graph

Now, we connect our agent nodes in a **StateGraph** so that they can interact.

```python
builder = StateGraph(MessagesState)
builder.add_node("travel_advisor", travel_advisor)
builder.add_node("hotel_advisor", hotel_advisor)
# The network starts with the travel advisor by default.
builder.add_edge(START, "travel_advisor")
graph = builder.compile()
```

> **Explanation:**  
> - **`StateGraph(MessagesState)`:** Initializes the graph with a state based on messages.  
> - **`add_node`:** Adds the `travel_advisor` and `hotel_advisor` functions as nodes.  
> - **`add_edge(START, "travel_advisor")`:** Sets the starting point of the conversation at the travel advisor.  
> - **`compile()`:** Finalizes the graph so it can execute the workflow.

---

## üé¨ Running the Multi-Agent Network

### **Pretty Print Function**

To display the conversation neatly, we define a helper function:

```python
from langchain_core.messages import convert_to_messages

def pretty_print_messages(update):
    if isinstance(update, tuple):
        ns, update = update
        if len(ns) == 0:  # Skip empty updates
            return
        graph_id = ns[-1].split(":")[0]
        print(f"Update from subgraph {graph_id}:\n")
    
    for node_name, node_update in update.items():
        print(f"Update from node {node_name}:\n")
        for m in convert_to_messages(node_update["messages"]):
            m.pretty_print()  # Nicely format and print each message
        print("\n")
```

> **Explanation:**  
> - **`convert_to_messages`:** Converts raw update data into a human-readable format.  
> - **`pretty_print`:** Method to print messages in a neat format for easier debugging and display.

### **Test the Graph with User Input**

Now, let‚Äôs test our multi-agent system with a sample query:

```python
for chunk in graph.stream(
    {"messages": [("user", "i wanna go somewhere warm in the caribbean")]}
):
    pretty_print_messages(chunk)
```

> **Explanation:**  
> - This sends a query from the user asking for travel advice.  
> - The `graph.stream()` function processes the query, and each update is printed by our helper function.

---

## üîÄ Extending the System

### **Advanced Interaction Scenario**

Now, suppose the user wants both a destination recommendation and hotel details. We can run:

```python
for chunk in graph.stream(
    {
        "messages": [
            (
                "user",
                "i wanna go somewhere warm in the caribbean. pick one destination and give me hotel recommendations",
            )
        ]
    }
):
    pretty_print_messages(chunk)
```

> **What Happens?**  
> - The **travel advisor** picks a destination (e.g., the Dominican Republic) and then hands off to the **hotel advisor** using the handoff tool.  
> - The **hotel advisor** then provides hotel recommendations for that destination.

---

## üèÜ Key Takeaways

- **Multi-Agent Architecture:**  
  Agents are designed as graph nodes that can talk to each other. They make decisions based on LLM outputs and hand off control as needed.

- **Real-World Applications:**  
  Such networks can be applied in complex systems like customer support, travel planning, or AI-powered tutoring, where different agents handle specialized tasks.

- **Handoffs:**  
  Handoffs ensure that the right agent processes the right part of a task, making the overall system modular and flexible.

- **StateGraph:**  
  The StateGraph orchestrates the flow between agents, handling the conversation state and transitions.

---

With this structure, you now have a powerful template for building multi-agent networks that can be adapted for a variety of real-world applications. Happy coding!