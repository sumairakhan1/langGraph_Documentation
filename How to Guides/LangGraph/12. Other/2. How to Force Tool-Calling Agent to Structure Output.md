# 2. How to Force Tool-Calling Agent to Structure Output

# üìä How to Force Tool-Calling Agent to Structure Output

In many cases, it's necessary to ensure that the output from an agent (a system that interacts with tools) is structured in a consistent way. This structured output can be important when the agent's output needs to be consumed by other software systems, or when consistency is crucial for downstream processing. In this tutorial, we will explore how to force a tool-calling agent to produce structured outputs using two different methods.

### 1. üéØ **Overview of the Process**

The main goal here is to ensure that the output of the agent is consistently structured, which means that we want to control how the agent's responses are formatted before they're given to the user or another system.

In this notebook, we'll work with a **ReAct agent**. This type of agent consists of a **model node** and a **tool-calling node**, with a third node that formats the response for the user.

We will cover two options for enforcing structured output:
- **Option 1**: Binding the output to a specific tool in the agent.
- **Option 2**: Using an additional LLM (Large Language Model) to structure the output.

### 2. üõ†Ô∏è **Option 1: Bind the Output to a Tool**

#### Concept:
In Option 1, we can bind the output of the tool that we want to use, forcing the agent to call that tool. Instead of allowing the agent to choose between tools or ending the conversation, the agent will directly choose between specific tools it needs to call.

**How does this work?**
- The agent selects an **action tool**, and after receiving the result from this action tool, it calls the **response tool**.
- The response tool formats the output and then sends it back to the user.

#### Advantages:
- You only need a **single LLM** (saving time and cost).
- **Lower latency** since fewer calls are made.
  
#### Disadvantages:
- The tool might not always be called correctly by the LLM.
- Multiple tools might be selected at once, requiring extra checks in the routing function.

#### Example Code for Option 1:
```python
from langchain_core.tools import tool
from langchain_anthropic import ChatAnthropic

# Tool for fetching weather
@tool
def get_weather(city: str):
    """Fetches weather for a given city."""
    if city == "nyc":
        return {"temperature": 70, "wind_direction": "NE", "wind_speed": 5}
    elif city == "sf":
        return {"temperature": 75, "wind_direction": "SE", "wind_speed": 3}

# Define model and bind tool
model = ChatAnthropic(model="claude-3-opus-20240229")
model_with_tools = model.bind_tools([get_weather])

# Example of invoking the tool
response = model_with_tools.invoke({"city": "nyc"})
print(response)
```

**Explanation of Code**:
- `get_weather(city: str)`: This tool returns weather information for a city.
- `model.bind_tools([get_weather])`: This binds the `get_weather` tool to the agent model, ensuring that the agent uses it when needed.
- `response = model_with_tools.invoke({"city": "nyc"})`: The agent invokes the weather tool with `"nyc"` as input.

---

### 3. ‚öôÔ∏è **Option 2: Using a Second LLM for Structured Output**

#### Concept:
In **Option 2**, instead of directly using the first LLM, we introduce an additional LLM that structures the output. This ensures that the final output follows the desired format.

**How does this work?**
- The agent node still selects the tool, but after that, the response is sent to a **second LLM** which will structure the output according to the predefined schema.
  
#### Advantages:
- **Guaranteed structured output**, as the second LLM is specifically designed to structure the response.
  
#### Disadvantages:
- **Higher cost and latency** due to the additional LLM call.

#### Example Code for Option 2:
```python
from pydantic import BaseModel, Field
from langchain_anthropic import ChatAnthropic
from langgraph.graph import MessagesState
from langchain_core.tools import tool

# Weather response model
class WeatherResponse(BaseModel):
    temperature: float
    wind_direction: str
    wind_speed: float

# Tool for fetching weather
@tool
def get_weather(city: str):
    """Fetches weather for a given city."""
    if city == "nyc":
        return {"temperature": 70, "wind_direction": "NE", "wind_speed": 5}
    elif city == "sf":
        return {"temperature": 75, "wind_direction": "SE", "wind_speed": 3}

# Define the agent and second LLM for structured output
model = ChatAnthropic(model="claude-3-opus-20240229")
model_with_tools = model.bind_tools([get_weather])
model_with_structured_output = model.with_structured_output(WeatherResponse)

# Example invocation
response = model_with_structured_output.invoke({"city": "nyc"})
print(response)
```

**Explanation of Code**:
- `WeatherResponse(BaseModel)`: This class defines the structured format for the weather data (temperature, wind direction, wind speed).
- `model.with_structured_output(WeatherResponse)`: This ensures the agent outputs the response in the `WeatherResponse` format.
- The agent will first call the `get_weather` tool, and then the second LLM will structure the output based on the `WeatherResponse` schema.

---

### 4. üí° **Real-World Use Cases**

#### 1. **Weather Application**:
   - When building a weather app, it is essential to get weather data from various sources. The structured format ensures that the data (e.g., temperature, wind speed, humidity) is returned in a consistent format every time. The agent ensures this data is structured in a predictable manner, so the app can easily parse and display it.

#### 2. **E-commerce Product Listings**:
   - Imagine an agent fetching product details like price, stock, and description. Using structured output ensures that the e-commerce platform always receives data in the same structure, making integration simpler and more reliable.

#### 3. **Customer Support Automation**:
   - In automated customer support, structured data (e.g., customer queries, solutions, and status updates) ensures that responses are consistent and easily understood by both customers and downstream systems.

---

### 5. üîÑ **Comparison of Both Options**

| **Feature**            | **Option 1**                           | **Option 2**                              |
|------------------------|----------------------------------------|-------------------------------------------|
| **Ease of Setup**      | Easier, uses one LLM                   | Requires an additional LLM                |
| **Cost**               | Lower, since it uses one LLM           | Higher, due to the extra LLM invocation   |
| **Output Structure**   | Not guaranteed                         | Guaranteed structured output              |
| **Latency**            | Lower, fewer calls                    | Higher, as it involves an additional step|

---

### Conclusion

By forcing the tool-calling agent to return structured output, you can ensure that the data your system receives is in a predictable, usable format. Depending on your requirements for consistency and performance, you can choose between the two options presented above.

# Option 1: Bind Output as Tool

In this section, we will dive deep into how to structure your agent‚Äôs output by **binding output as a tool**. This technique forces the agent to return structured data in a way that is consistent, no matter the context.

## üß† **What is this concept?**

This concept is about **forcing a tool-calling agent** to produce output in a **structured format** (such as a WeatherResponse object). The purpose is to ensure that no matter the tool or action, the final result will always follow the expected structure.

By binding the output as a tool, the agent is given instructions to select the **weather response tool** after it calls the initial weather-fetching tool. This ensures consistency and a structured format for each response.

---

## üèóÔ∏è **Real World Use Case:**

Imagine you have a **weather app** that queries different data sources (APIs) for weather information. You want your app to always return the weather data in a **consistent format** (e.g., temperature, wind speed, and wind direction) regardless of the source or tool used. Binding the output ensures the data is returned in the desired structure for processing or display.

---

## üñ•Ô∏è **Step-by-Step Code Explanation**

Let‚Äôs go through the code to understand how binding works. In this example, the goal is to fetch weather information and return it in a structured format.

### 1. **Imports & Setup:**

We first import the necessary components to set up the graph and tools.

```python
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
```

Here, `StateGraph` allows us to create a workflow, and `ToolNode` lets us define which tools will be used within the graph.

---

### 2. **Defining the Tools:**

```python
tools = [get_weather, WeatherResponse]
```

In this line, we define two tools:
- **`get_weather`**: The tool that retrieves weather data (e.g., fetching weather for SF).
- **`WeatherResponse`**: The structured format for the weather response (temperature, wind speed, etc.).

---

### 3. **Binding Tools to the Model:**

```python
model_with_response_tool = model.bind_tools(tools, tool_choice="any")
```

Here, we're binding our tools (`get_weather` and `WeatherResponse`) to the model, and using `tool_choice="any"` forces the model to choose any of the provided tools. This means the model must invoke a tool for every step.

---

### 4. **Calling the Model:**

```python
def call_model(state: AgentState):
    response = model_with_response_tool.invoke(state["messages"])
    return {"messages": [response]}
```

In this function, we are calling the model with the given **state** and retrieving a response. This is where the tools are used. The response is added to the list of **messages** and returned.

---

### 5. **Responding to the User:**

```python
def respond(state: AgentState):
    weather_tool_call = state["messages"][-1].tool_calls[0]
    response = WeatherResponse(**weather_tool_call["args"])
    tool_message = {
        "type": "tool",
        "content": "Here is your structured response",
        "tool_call_id": weather_tool_call["id"],
    }
    return {"final_response": response, "messages": [tool_message]}
```

In this function, we **extract the structured weather data** (e.g., temperature, wind speed) from the last tool call and use it to create a **WeatherResponse object**. This ensures that the output is always structured.

We also create a **tool message** to follow the AI's tool call requirements.

---

### 6. **Determining If the Process Should Continue:**

```python
def should_continue(state: AgentState):
    messages = state["messages"]
    last_message = messages[-1]
    if (
        len(last_message.tool_calls) == 1
        and last_message.tool_calls[0]["name"] == "WeatherResponse"
    ):
        return "respond"
    else:
        return "continue"
```

This function checks whether the model has finished processing and is ready to **respond to the user**. If the weather tool has been called and we are ready to provide a response, it triggers the **"respond"** function. Otherwise, it tells the model to continue.

---

### 7. **Setting Up the Workflow:**

```python
workflow = StateGraph(AgentState)

workflow.add_node("agent", call_model)
workflow.add_node("respond", respond)
workflow.add_node("tools", ToolNode(tools))

workflow.set_entry_point("agent")
workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        "continue": "tools",
        "respond": "respond",
    },
)

workflow.add_edge("tools", "agent")
workflow.add_edge("respond", END)
graph = workflow.compile()
```

Here, we define the **workflow** using `StateGraph` and specify how the nodes interact:
- The **"agent"** node is the starting point.
- The **"respond"** node provides the structured response.
- The **"tools"** node calls the necessary tools to fetch the data.

We also define **conditional edges** to determine whether the agent should continue or respond to the user.

---

### 8. **Running the Workflow:**

```python
answer = graph.invoke(input={"messages": [("human", "what's the weather in SF?")]})["final_response"]
```

Finally, we invoke the graph with an input message asking about the weather in SF. The graph processes the message and returns the structured **WeatherResponse** object.

---

## üèÜ **What Did We Accomplish?**

Using **Option 1: Bind Output as Tool**, we ensured that the agent always returns structured output, even when calling different tools. This method guarantees consistency in the response format.

### **Pros:**
- Reduced complexity by requiring only a single LLM.
- It‚Äôs cost-effective and fast.
  
### **Cons:**
- Not foolproof, as the LLM may not always select the correct tools.
- If the agent calls multiple tools, additional checks are needed.

---

## üåç **Conclusion:**

Binding the output as a tool allows you to control the structure of the agent‚Äôs response, ensuring consistency no matter the context. This is especially useful in applications like weather apps, data-fetching tools, or any system that requires structured data for downstream processing.

By following this approach, you can make sure that your agent‚Äôs responses are **reliable** and **predictable**, which is critical for real-world applications where structured data is needed.

## üåü Understanding the Use of Multiple LLMs in a Workflow

In this explanation, we'll walk through the concept of using two Large Language Models (LLMs) in a workflow to generate structured output. The goal is to understand how to define a workflow using two models, and how you can integrate them effectively to handle tasks that require structured responses, like weather forecasting.

This workflow is useful in real-world applications such as **AI-driven customer support systems**, where structured data (like weather information) is needed in a consistent format, or **virtual assistants** that provide structured outputs to integrate with other tools.

---

### üßë‚Äçüíª Code Walkthrough: Using Two LLMs

#### **1. Defining the Graph:**

To define the workflow, we create a graph where different tasks are represented as nodes. Here, we're adding LLM tools and defining how the model should behave based on incoming messages.

```python
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage
```

- **`StateGraph`**: This is where we define the flow of tasks. Each task or action will be represented as a node in the graph.
- **`END`**: Represents the end of the workflow once the task is complete.
- **`ToolNode`**: This represents a tool or action within the graph.
- **`HumanMessage`**: Represents a message coming from the user.

---

#### **2. Call the First LLM (Initial Model)**

The first step in the workflow is calling a model with the provided inputs to start processing.

```python
def call_model(state: AgentState):
    response = model_with_tools.invoke(state["messages"])
    return {"messages": [response]}
```

- **`state`**: This contains the current state of the conversation, including messages and responses.
- **`model_with_tools.invoke()`**: This is where we invoke the LLM to process the message and get a response.
- **`response`**: The response from the model is returned and added to the `messages` list for further processing.

---

#### **3. Handling Responses Using Structured Output**

Next, we define how the model will respond to the user. If the tool returns structured data, we make sure the response is consistent.

```python
def respond(state: AgentState):
    response = model_with_structured_output.invoke(
        [HumanMessage(content=state["messages"][-2].content)]
    )
    return {"final_response": response}
```

- **`model_with_structured_output.invoke()`**: The model is called here to process the structured message format. We take the message content and pass it to the model, which ensures the output is structured in a consistent format.
- **`HumanMessage(content=...)`**: This is a human-readable message sent to the model.

---

#### **4. Determining Whether to Continue or Respond**

The decision of whether to continue processing with another tool or respond to the user depends on the presence of tool calls in the conversation history.

```python
def should_continue(state: AgentState):
    messages = state["messages"]
    last_message = messages[-1]
    
    if not last_message.tool_calls:
        return "respond"
    else:
        return "continue"
```

- **`last_message.tool_calls`**: Checks whether there was a previous tool call. If there is no tool call, it means we can respond with the final answer; otherwise, we continue to the next tool.

---

#### **5. Workflow Definition**

Here, we define the entire workflow, setting entry points, conditional edges, and actions.

```python
workflow = StateGraph(AgentState)

workflow.add_node("agent", call_model)
workflow.add_node("respond", respond)
workflow.add_node("tools", ToolNode(tools))

workflow.set_entry_point("agent")

workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        "continue": "tools",
        "respond": "respond",
    },
)

workflow.add_edge("tools", "agent")
workflow.add_edge("respond", END)
graph = workflow.compile()
```

- **`add_node()`**: Adds nodes to the graph, representing different actions or stages in the workflow (calling the model, responding to the user, etc.).
- **`set_entry_point()`**: Specifies which node should be executed first in the workflow.
- **`add_conditional_edges()`**: Adds conditional logic to decide which path to follow (whether to continue or respond based on previous messages).
- **`compile()`**: Compiles the graph into a runnable object.

---

#### **6. Running the Graph**

Finally, the workflow is invoked, and the system processes the input to return a structured response.

```python
answer = graph.invoke(input={"messages": [("human", "what's the weather in SF?")]})["final_response"]
```

- **`graph.invoke()`**: This starts the workflow by providing the initial input (the user's message). The model processes this input, and the graph determines whether it should continue to another step or respond.
- **`final_response`**: The final output of the workflow, which would be the structured weather data in this case.

---

### üåç Real-World Example: Virtual Assistants

In real-world applications, this concept is highly useful for **virtual assistants** that need to perform multiple tasks, like gathering weather data, scheduling appointments, or fetching data from APIs.

For instance:
- **Weather forecasting**: The assistant asks for the weather, invokes a tool to fetch the data, and ensures the response is structured.
- **Customer support**: The assistant fetches structured data (order details, shipping status) and formats it appropriately before responding to the customer.

By using two LLMs (one for task execution and one for structured response), you ensure that your system can handle complex workflows and provide users with consistent and accurate information.

---

### üìä Summary

- **Two LLMs**: One LLM handles tasks (e.g., fetching weather data), and another ensures the output is structured for further use or user-friendly presentation.
- **State Graph**: Defines the workflow and how tasks should be executed based on conditions.
- **ToolNode**: Represents a specific action or tool in the workflow.
- **Real-World Use**: Ideal for virtual assistants, customer support bots, or any system that needs to process information and respond in a structured format.

---

# ü§ñ Option 2: Using Two LLMs for Structured Output

In this approach, we use a **second LLM** to ensure that the final output is structured exactly as we need it. This method forces the agent to reformat the output by making an additional call with a model that is set up to return responses in a defined schema. This is especially useful when downstream applications require data in a consistent format.

---

## üìù What Does This Mean?

Imagine you're building a weather application. The first LLM (the **agent**) fetches weather data via tools, but its output might be unstructured or vary slightly. By using a **second LLM** configured to produce structured output, you can convert the agent‚Äôs output into a predictable format‚Äîensuring that you always get data like temperature, wind speed, and wind direction in the same structure (e.g., as a `WeatherResponse` object).

---

## üåç Real-World Use Case

Consider a scenario in an enterprise system where multiple microservices interact. One service might collect data (like weather information) in a raw or unstructured format. However, another service that logs or displays this data might require it in a strict format for consistency, error checking, or further processing. Using two LLMs ensures that the final data conforms exactly to the expected schema.

---

## üîß Detailed Code Walkthrough

Below is the complete code to set up and run this two-LLM approach. We'll explain each part of the code in detail.

### Code Example

```python
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage

# Define the function that calls the model (agent node)
def call_model(state: AgentState):
    # Invoke the model (with tools bound) using the current state messages
    response = model_with_tools.invoke(state["messages"])
    # The response is added as a new message in the state.
    return {"messages": [response]}

# Define the function that responds to the user (respond node)
def respond(state: AgentState):
    # We want to structure the output from the previous tool call.
    # The last tool message (two messages ago) is converted into a human message.
    response = model_with_structured_output.invoke(
        [HumanMessage(content=state["messages"][-2].content)]
    )
    # The structured response is then returned as the final answer.
    return {"final_response": response}

# Define the function that determines whether to continue the loop or respond
def should_continue(state: AgentState):
    messages = state["messages"]
    last_message = messages[-1]
    # If there are no tool calls in the last message, it's time to respond.
    if not last_message.tool_calls:
        return "respond"
    # Otherwise, continue processing by calling the tool again.
    else:
        return "continue"

# Create a new state graph with AgentState as its state.
workflow = StateGraph(AgentState)

# Add nodes to the graph:
# 'agent' node calls the LLM to process the messages.
workflow.add_node("agent", call_model)
# 'respond' node processes the final output through the structured LLM.
workflow.add_node("respond", respond)
# 'tools' node handles calling the actual tools (e.g., get_weather).
workflow.add_node("tools", ToolNode(tools))

# Set the starting point (entry point) of the graph.
workflow.set_entry_point("agent")

# Add a conditional edge from the agent node:
workflow.add_conditional_edges(
    "agent",
    should_continue,  # Function to decide which edge to follow
    {
        "continue": "tools",  # If more processing is needed, go to tools node
        "respond": "respond", # If finished, move to respond node
    },
)

# Define the flow between nodes.
workflow.add_edge("tools", "agent")  # After tool processing, go back to agent
workflow.add_edge("respond", END)      # After responding, end the workflow

# Compile the graph into a runnable workflow.
graph = workflow.compile()
```

---

## üìñ Line-by-Line Code Explanation

1. **Imports and Setup**:
   ```python
   from langgraph.graph import StateGraph, END
   from langgraph.prebuilt import ToolNode
   from langchain_core.messages import HumanMessage
   ```
   - **Purpose**: Import necessary modules to create the workflow graph, define tool nodes, and handle messages.

2. **`call_model` Function**:
   ```python
   def call_model(state: AgentState):
       response = model_with_tools.invoke(state["messages"])
       return {"messages": [response]}
   ```
   - **Purpose**: This function acts as the **agent node**. It calls the LLM (with tools bound) using the current state messages. The response (which may contain tool outputs) is added as a new message in the state.

3. **`respond` Function**:
   ```python
   def respond(state: AgentState):
       response = model_with_structured_output.invoke(
           [HumanMessage(content=state["messages"][-2].content)]
       )
       return {"final_response": response}
   ```
   - **Purpose**: This function is used to format the final output. It converts a previous tool message into a human message and then invokes the second LLM (configured to enforce a structured output). The result is returned as the final structured response.

4. **`should_continue` Function**:
   ```python
   def should_continue(state: AgentState):
       messages = state["messages"]
       last_message = messages[-1]
       if not last_message.tool_calls:
           return "respond"
       else:
           return "continue"
   ```
   - **Purpose**: This function checks whether the process should continue or if it is time to respond to the user. If there are no tool calls in the last message, it directs the workflow to the **respond** node. Otherwise, it indicates that further processing is needed.

5. **Graph Construction**:
   ```python
   workflow = StateGraph(AgentState)
   workflow.add_node("agent", call_model)
   workflow.add_node("respond", respond)
   workflow.add_node("tools", ToolNode(tools))
   workflow.set_entry_point("agent")
   workflow.add_conditional_edges(
       "agent",
       should_continue,
       {
           "continue": "tools",
           "respond": "respond",
       },
   )
   workflow.add_edge("tools", "agent")
   workflow.add_edge("respond", END)
   graph = workflow.compile()
   ```
   - **Purpose**: 
     - **StateGraph**: Creates a new workflow that will manage the state throughout the process.
     - **Nodes**: The workflow includes three nodes: 
       - **agent**: Processes the current messages.
       - **respond**: Uses the structured output LLM.
       - **tools**: Handles tool calls (like fetching weather data).
     - **Edges**: Set the order of operations. For instance, after the tools node finishes, it returns control to the agent node; after a final response, the workflow ends.
     - **Conditional Edge**: Uses the `should_continue` function to decide whether to continue processing or to format the final response.
     - **Compile**: Finalizes the graph into a runnable object.

---

## üöÄ How to Use the Graph

To run the graph and see the structured output, you can invoke it as follows:

```python
# Invoke the graph with an initial human message.
answer = graph.invoke(input={"messages": [("human", "what's the weather in SF?")]})["final_response"]

# The answer should be a structured WeatherResponse object.
print(answer)
```

- **Explanation**:
  - **Input**: The graph is started with a human message asking for the weather in SF.
  - **Output**: The graph processes the input, and the second LLM enforces the structure, returning a `WeatherResponse` object with fields like temperature, wind direction, and wind speed.

---

## üåü Key Takeaways

- **Consistency**: Using two LLMs ensures that the final output is always in a structured format.
- **Flexibility**: The first LLM handles tool invocations, while the second one guarantees the final output conforms to the expected schema.
- **Real-World Utility**: This method is ideal for applications like weather apps, e-commerce data processing, or any system where consistent data formatting is crucial.

By following this approach, you can seamlessly integrate AI-generated content into larger software systems, confident that the output is predictable and easy to work with.

Feel free to ask if you have any questions or need further clarification on any part of the process!

