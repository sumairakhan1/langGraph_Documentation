# 1. How to set up app for deployment (requirements.txt)

# üöÄ How to Set Up an App for Deployment (requirements.txt)

When you're ready to deploy your LangGraph application, it's important to organize your code and dependencies correctly. In this guide, we will cover how to set up your LangGraph application for deployment, focusing on using `requirements.txt` to specify project dependencies.

### üìÅ File Structure

To get started, let's look at how the final file structure of your app will look:

```
my-app/
‚îú‚îÄ‚îÄ my_agent                 # All project code goes here
‚îÇ   ‚îú‚îÄ‚îÄ utils                # Utility files for your graph
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt     # Package dependencies
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ agent.py             # Code for your graph
‚îú‚îÄ‚îÄ .env                     # Environment variables
‚îî‚îÄ‚îÄ langgraph.json           # LangGraph configuration file
```

Each file has a specific purpose. Now, let‚Äôs dive into what each part does and how to set it up.

### üì¶ Specify Dependencies in `requirements.txt`

The `requirements.txt` file lists all the Python packages your project needs to run. This file allows you to install the dependencies using a simple command: `pip install -r requirements.txt`.

Here's an example of what your `requirements.txt` might look like:

```txt
langgraph
langchain_anthropic
tavily-python
langchain_community
langchain_openai
```

These packages are essential for the LangGraph application to function. For example:
- **`langgraph`**: The core LangGraph library.
- **`langchain`**: A tool for managing language models and tools.
- **`tavily-python`**: Another package to interact with specific APIs.

### ‚öôÔ∏è Specify Environment Variables in `.env`

The `.env` file is where you store configuration values and secrets like API keys and environment-specific settings. You‚Äôll need to reference this file in your deployment configuration to ensure your app has access to these values.

Example of `.env`:

```txt
MY_ENV_VAR_1=foo
MY_ENV_VAR_2=bar
OPENAI_API_KEY=your-api-key-here
```

Make sure this file is added to your `.gitignore` to avoid uploading sensitive data to GitHub or other repositories.

### üîÑ Define Graphs in `agent.py`

Graphs define the workflow of your LangGraph application. In the `agent.py` file, you'll specify how nodes (tasks) are connected and the logic behind each one.

Here‚Äôs a basic example of how to define a graph using LangGraph:

```python
# my_agent/agent.py
from typing import Literal
from langgraph.graph import StateGraph, END, START
from my_agent.utils.nodes import call_model, should_continue, tool_node

# Define the config for the graph
class GraphConfig(TypedDict):
    model_name: Literal["anthropic", "openai"]

# Create a new graph
workflow = StateGraph(AgentState, config_schema=GraphConfig)

# Add nodes to the graph
workflow.add_node("agent", call_model)
workflow.add_node("action", tool_node)

# Define the connections between nodes (edges)
workflow.add_edge(START, "agent")
workflow.add_conditional_edges(
    "agent", should_continue,
    {
        "continue": "action",
        "end": END,
    },
)
workflow.add_edge("action", "agent")

# Compile the graph to make it ready for execution
graph = workflow.compile()
```

### üõ†Ô∏è Explanation of Code:

1. **Importing Required Libraries:**
   ```python
   from langgraph.graph import StateGraph, END, START
   from my_agent.utils.nodes import call_model, should_continue, tool_node
   ```
   - These imports bring in essential modules like `StateGraph` for defining a graph, and `START`, `END` for defining the beginning and end of the workflow.
   - You also import your custom functions like `call_model` for handling tasks and `should_continue` for controlling workflow flow.

2. **Defining the Graph Configuration:**
   ```python
   class GraphConfig(TypedDict):
       model_name: Literal["anthropic", "openai"]
   ```
   - This defines the structure for the configuration of the graph, which includes the model name (such as "anthropic" or "openai") that the graph will interact with.

3. **Creating the Graph:**
   ```python
   workflow = StateGraph(AgentState, config_schema=GraphConfig)
   ```
   - Here, you create an instance of the `StateGraph` class, passing in the state of the agent (`AgentState`) and the configuration schema (`GraphConfig`).

4. **Adding Nodes to the Graph:**
   ```python
   workflow.add_node("agent", call_model)
   workflow.add_node("action", tool_node)
   ```
   - These lines add two nodes to the graph: `agent` and `action`. Each node represents a specific function or task that the graph will perform, like calling a model or taking an action.

5. **Defining Workflow Logic (Edges):**
   ```python
   workflow.add_edge(START, "agent")
   workflow.add_conditional_edges(
       "agent", should_continue,
       {
           "continue": "action",
           "end": END,
       },
   )
   workflow.add_edge("action", "agent")
   ```
   - You define the flow of the graph by connecting nodes with edges. The `START` node connects to the `agent` node. The `should_continue` function checks if the process should continue to the `action` node, or end the workflow.
   - After completing the `action` node, the graph returns to the `agent` node, creating a loop.

6. **Compiling the Graph:**
   ```python
   graph = workflow.compile()
   ```
   - Finally, you compile the graph so it‚Äôs ready for execution.

### üîß Create LangGraph API Configuration File (`langgraph.json`)

The LangGraph API configuration file (`langgraph.json`) is used to tell the LangGraph platform where to find your application code and configuration files.

Example `langgraph.json`:

```json
{
  "dependencies": ["./my_agent"],
  "graphs": {
    "agent": "./my_agent/agent.py:graph"
  },
  "env": ".env"
}
```

- **`dependencies`**: Specifies the path to your project code (in this case, the `my_agent` folder).
- **`graphs`**: Specifies which graph to use and where it's located (i.e., the `graph` variable defined in `agent.py`).
- **`env`**: Specifies the environment variable file (`.env`).

### üõ†Ô∏è Conclusion

After setting up these files, your LangGraph application will be ready for deployment. You can push the code to a Git repository, and LangGraph Cloud (or self-hosting) will use the configuration files to deploy the app.

#### Real-World Example: AI Chatbot

A real-world example of using LangGraph is for creating an AI chatbot. By defining workflows (graphs), you can design how the bot interacts with users:
- **Nodes** could represent actions like fetching data from APIs, analyzing the text, or generating responses.
- **Edges** could define the flow of conversation: starting with a greeting, checking for user input, and responding based on the user‚Äôs query.

This setup helps in scaling and automating tasks, similar to how workflows in a business process might work.