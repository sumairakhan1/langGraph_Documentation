# 🌐 **How to Integrate LangGraph into Your React Application** 

LangGraph is a platform designed to help you build powerful AI-driven applications. It provides tools to integrate machine learning models, allowing for seamless interaction between a user and AI agents. In this guide, we'll explore how to integrate LangGraph into your React application using the `useStream()` hook. This will allow you to create dynamic chat experiences, manage message streams, and handle different states in a React-based UI. Let’s break it down step by step for beginners.

---

## 🚀 **Prerequisites**

Before diving into the integration, you’ll need to have the following set up:

1. **LangGraph Platform**: This is the core platform where agents are deployed.
2. **LangGraph Server**: The server that handles requests to LangGraph, managing the backend operations for agent interactions.
3. **React**: A JavaScript library for building user interfaces. We’ll be using React to build the frontend of our application.

Once you have these prerequisites, you’ll be able to integrate LangGraph into your React app.

---

## 🧑‍💻 **Key Features of `useStream()` Hook**

The `useStream()` hook simplifies integrating LangGraph with React. It provides several important features for handling message streams in your chat application:

### 🎯 **Features of `useStream()`**:
1. **Messages Streaming**: It allows you to handle chunks of messages, which will eventually form a complete message.
2. **Automatic State Management**: This includes managing messages, loading states, and handling errors.
3. **Conversation Branching**: You can easily create alternate conversation paths.
4. **UI-Agnostic Design**: You can bring your own components and customize styling.

This is especially useful for applications where you need to handle real-time conversations or message flows.

---

## 💻 **How to Use `useStream()` in Your React Application**

Let’s walk through an example to see how `useStream()` works in practice. Below is the code that demonstrates how to integrate LangGraph’s message-streaming functionality into a React application.

### 📝 **Code Example**

```jsx
"use client";

import { useStream } from "@langchain/langgraph-sdk/react";
import type { Message } from "@langchain/langgraph-sdk";

export default function App() {
  // Using useStream hook to manage the message stream
  const thread = useStream<{ messages: Message[] }>({
    apiUrl: "http://localhost:2024",      // The URL of your LangGraph API server
    assistantId: "agent",                // The ID of the assistant (the AI agent)
    messagesKey: "messages",             // Key to access messages in the stream
  });

  return (
    <div>
      <div>
        {/* Displaying messages from the thread */}
        {thread.messages.map((message) => (
          <div key={message.id}>{message.content as string}</div>
        ))}
      </div>

      <form
        onSubmit={(e) => {
          e.preventDefault();

          const form = e.target as HTMLFormElement;
          const message = new FormData(form).get("message") as string;

          form.reset(); // Reset form after submitting
          
          // Sending the user's message to the thread
          thread.submit({ messages: [{ type: "human", content: message }] });
        }}
      >
        {/* Input field for sending messages */}
        <input type="text" name="message" />

        {/* Show "Stop" button while loading or "Send" button otherwise */}
        {thread.isLoading ? (
          <button key="stop" type="button" onClick={() => thread.stop()}>
            Stop
          </button>
        ) : (
          <button key="submit" type="submit">
            Send
          </button>
        )}
      </form>
    </div>
  );
}
```

---

### 🧑‍💻 **Explanation of Code Logic**

#### Step 1: **Import the `useStream` Hook**
```jsx
import { useStream } from "@langchain/langgraph-sdk/react";
```
- This imports the `useStream` hook from LangGraph’s SDK. The hook will help manage the state of messages between the user and the AI.

#### Step 2: **Initialize the `useStream` Hook**
```jsx
const thread = useStream<{ messages: Message[] }>({
  apiUrl: "http://localhost:2024", // URL of your LangGraph API server
  assistantId: "agent",           // ID of the assistant (the AI agent)
  messagesKey: "messages",        // The key for accessing the messages in the stream
});
```
- `useStream()` initializes the message thread between the user and the assistant. It takes an object with:
  - **apiUrl**: The URL where your LangGraph server is running.
  - **assistantId**: Identifies the AI assistant you want to interact with.
  - **messagesKey**: The key to access the messages array.

#### Step 3: **Display Messages**
```jsx
{thread.messages.map((message) => (
  <div key={message.id}>{message.content as string}</div>
))}
```
- This part renders the messages in the UI by looping through the `messages` array from the `thread`. Each message is displayed with its `content`.

#### Step 4: **Form Submission for New Messages**
```jsx
<form
  onSubmit={(e) => {
    e.preventDefault();

    const form = e.target as HTMLFormElement;
    const message = new FormData(form).get("message") as string;

    form.reset();
    thread.submit({ messages: [{ type: "human", content: message }] });
  }}
>
  <input type="text" name="message" />
```
- Here, we handle the form submission when the user types and sends a message. 
- `FormData(form).get("message")` retrieves the message the user typed in the input field.
- The `submit()` method sends the message to the thread.

#### Step 5: **Show "Stop" or "Send" Button Based on Loading State**
```jsx
{thread.isLoading ? (
  <button key="stop" type="button" onClick={() => thread.stop()}>
    Stop
  </button>
) : (
  <button key="submit" type="submit">
    Send
  </button>
)}
```
- When the thread is loading (waiting for a response from the assistant), a "Stop" button is shown. Otherwise, a "Send" button is displayed for sending the next message.
- `thread.stop()` stops the current operation if needed.

---

## 🔄 **Customizing Your UI**

LangGraph provides you with a **UI-agnostic design**. This means you can bring in your own components and styling. The `useStream()` hook takes care of the heavy lifting in terms of managing the message flow, leaving you with flexibility to design your UI as you wish.

### 🚦 **Loading States Example**

To handle loading states effectively, you can use the `isLoading` property. This will indicate whether the assistant is processing the message and responding.

```jsx
export default function App() {
  const { isLoading, stop } = useStream<{ messages: Message[] }>({
    apiUrl: "http://localhost:2024",
    assistantId: "agent",
    messagesKey: "messages",
  });

  return (
    <form>
      {isLoading && (
        <button key="stop" type="button" onClick={() => stop()}>
          Stop
        </button>
      )}
    </form>
  );
}
```
- The `isLoading` state is used to show a **"Stop"** button when the assistant is processing, allowing the user to stop the interaction if needed.

---

## 🌟 **Real-World Use Case**

Imagine building a **customer support chat system** for an e-commerce website. You can use LangGraph and the `useStream()` hook to create an interactive chat experience where the user interacts with an AI-powered assistant that responds in real-time.

For example:
- A user visiting your website has a query about a product.
- The `useStream()` hook handles the message flow between the user and the assistant in real-time, ensuring a smooth chat experience.
- The assistant responds to queries, and if necessary, can branch the conversation to other paths based on user inputs (e.g., offering product recommendations based on user preferences).

This makes your e-commerce site more interactive, offering a modern and dynamic customer support experience.

---

## 🏁 **Conclusion**

Integrating LangGraph into your React application using the `useStream()` hook provides a powerful way to manage real-time messaging and AI interaction. It streamlines many of the complexities associated with chat applications, allowing you to focus more on building an engaging user interface and experience.

By leveraging the `useStream()` hook, you can easily manage message streams, handle loading states, and branch conversations dynamically, all while customizing the UI to match your app's unique style.

# Thread Management in LangGraph and React Integration

Thread management in LangGraph allows you to track and manage conversations efficiently. In applications such as customer support chatbots or any real-time messaging platforms, it is essential to maintain a consistent flow of messages across different sessions. The useStream hook provided by LangGraph enables us to integrate this feature seamlessly into our React applications.

## 🔑 Key Concepts of Thread Management

Thread management involves keeping track of all messages within a conversation. You can:
- **Track conversation state**: You can access the current thread and its ID.
- **Resume conversations**: By storing the thread ID, you can resume the conversation even after a page refresh.
- **Support for message chunks**: Messages may arrive in multiple parts, and LangGraph helps you handle this by concatenating the chunks into a complete message.
- **Branching support**: You can create alternate conversation paths based on user interactions.

---

## 💡 Real-World Use Cases for Thread Management

In a **customer support application**, tracking a conversation’s thread is vital. Suppose a user has a conversation with a support agent. The support agent may refer to earlier messages, and the user may request to resume the conversation from where it left off. Using thread management, we ensure that the conversation is continued smoothly even after a page reload.

---

## 🧑‍💻 Code Example: Basic Thread Management

In the following code, we demonstrate how to manage threads in a React application using LangGraph’s `useStream()` hook. The `threadId` is used to track the current conversation, and it will help to resume the conversation even if the page is refreshed.

### Step 1: Set up the thread state using `useState`

```tsx
const [threadId, setThreadId] = useState<string | null>(null);
```

This creates a `threadId` state variable, which will store the ID of the conversation. It is initially set to `null`, indicating no active thread.

### Step 2: Integrate `useStream()` with thread management

```tsx
const thread = useStream<{ messages: Message[] }>({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
  threadId: threadId,
  onThreadId: setThreadId,
});
```

In this code:
- `apiUrl`: The URL of the LangGraph server that will provide messages.
- `assistantId`: Identifies which assistant (or bot) is responding.
- `threadId`: The `threadId` to track the specific conversation.
- `onThreadId`: This is a callback function to update the `threadId` whenever a new thread is created.

### Step 3: Store threadId in URL

For users to resume their conversation after a page refresh, you can store the `threadId` in the URL query parameters. Here is how you can update the URL with the thread ID:

```tsx
useEffect(() => {
  if (threadId) {
    window.history.pushState({}, "", `?threadId=${threadId}`);
  }
}, [threadId]);
```

This ensures that the `threadId` is saved in the URL, and the user can resume the conversation even after reloading the page.

---

## 🧩 Messages Handling

The `messagesKey` option in the `useStream` hook enables the handling of message chunks. These chunks are collected and concatenated to form a complete message.

```tsx
const thread = useStream<{ messages: Message[] }>({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
  messagesKey: "messages",
});
```

In this setup, LangGraph ensures that all message parts are combined and shown as one cohesive message.

### Displaying Messages

Here is a simple way to display the messages in the UI:

```tsx
<div>
  {thread.messages.map((message) => (
    <div key={message.id}>{message.content as string}</div>
  ))}
</div>
```

For each message in the `thread.messages` array, we display the message content. Each message is identified by its unique `id`.

---

## 🔀 Branching Support

Branching allows the conversation to have different paths depending on user input. In a chatbot, you might want to offer different responses based on a user’s earlier choices.

### Step 1: Enable Branching in the `useStream()` Hook

To enable branching, you need to handle the message chunks and provide options for branching:

```tsx
const thread = useStream<StateType<typeof AgentState.spec>, UpdateType<typeof AgentState.spec>>({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
  messagesKey: "messages",
});
```

The `StateType` and `UpdateType` are used for defining the structure of the state and updates.

### Step 2: Create Branch Options

The `BranchSwitcher` component is used to navigate between branches. This allows users to move back and forth between different paths in the conversation.

```tsx
function BranchSwitcher({
  branch,
  branchOptions,
  onSelect,
}: {
  branch: string | undefined;
  branchOptions: string[] | undefined;
  onSelect: (branch: string) => void;
}) {
  if (!branchOptions || !branch) return null;
  const index = branchOptions.indexOf(branch);

  return (
    <div className="flex items-center gap-2">
      <button
        type="button"
        onClick={() => {
          const prevBranch = branchOptions[index - 1];
          if (!prevBranch) return;
          onSelect(prevBranch);
        }}
      >
        Prev
      </button>
      <span>{index + 1} / {branchOptions.length}</span>
      <button
        type="button"
        onClick={() => {
          const nextBranch = branchOptions[index + 1];
          if (!nextBranch) return;
          onSelect(nextBranch);
        }}
      >
        Next
      </button>
    </div>
  );
}
```

This component provides buttons to navigate between different branches. It also displays the current position in the list of available branches.

---

## ✏️ Editing Messages

Users can also edit their previous messages or regenerate an AI response. Here’s an example of how to allow users to edit a message:

```tsx
function EditMessage({
  message,
  onEdit,
}: {
  message: Message;
  onEdit: (message: Message) => void;
}) {
  const [editing, setEditing] = useState(false);

  if (!editing) {
    return (
      <button type="button" onClick={() => setEditing(true)}>
        Edit
      </button>
    );
  }

  return (
    <form
      onSubmit={(e) => {
        e.preventDefault();
        const form = e.target as HTMLFormElement;
        const content = new FormData(form).get("content") as string;
        form.reset();
        onEdit({ type: "human", content });
        setEditing(false);
      }}
    >
      <input name="content" defaultValue={message.content as string} />
      <button type="submit">Save</button>
    </form>
  );
}
```

### Code Explanation:
- **useState**: Manages whether the user is editing the message.
- **onClick**: Shows the input form when the "Edit" button is clicked.
- **onSubmit**: Handles the form submission, updates the message, and saves the new content.

---

## 📝 TypeScript Integration

LangGraph is fully typed, which means you can define the structure of your state, updates, and custom events, helping prevent errors and providing better IDE support.

### Example of TypeScript Types:

```tsx
type State = {
  messages: Message[];
  context?: Record<string, unknown>;
};

type Update = {
  messages: Message[] | Message;
  context?: Record<string, unknown>;
};

type CustomEvent = {
  type: "progress" | "debug";
  payload: unknown;
};
```

By defining these types, you ensure that the data passed to the `useStream()` hook is always in the correct format.

---

## 🚀 Summary

In this guide, we covered:
- **Thread Management**: How to track and store conversation threads.
- **Message Handling**: Collecting and displaying message chunks.
- **Branching Support**: Creating and navigating conversation branches.
- **Message Editing**: Enabling users to edit or regenerate messages.
- **TypeScript**: How to define types for better development experience.

With these concepts, you can build powerful and interactive chat applications in React, while keeping track of user conversations seamlessly.

# **Understanding LangGraph.js for Thread Management & Event Handling** 🌐

In this section, we will explore **LangGraph.js**, specifically focusing on **annotation types** for reuse in a graph structure and how to handle **events** effectively. We'll break down the code, explain the concepts in simple terms, and show how this can be used in real-world applications. So, let's dive into it! 😄

## **Reusing Graph's Annotation Types with LangGraph.js** 🔄

LangGraph.js provides a way to define **annotations** within your graph structure. An annotation can be thought of as metadata attached to a particular node or message in a conversation thread. These annotations can represent different kinds of information, such as the state of a message or its content.

In this example, we’re creating **AgentState** using **Annotation.Root**, which holds information about the current state of a conversation thread, including messages and additional context. Let’s break it down:

### **Code Breakdown**

```typescript
import {
  Annotation,
  MessagesAnnotation,
  type StateType,
  type UpdateType,
} from "@langchain/langgraph/web";

// Creating an annotation for Agent's state
const AgentState = Annotation.Root({
  ...MessagesAnnotation.spec,   // Reusing pre-defined Message Annotation specification
  context: Annotation.Optional(Annotation.Any()),  // Adding an optional context (can be any data)
});

// Creating a thread using useStream hook and passing the annotation type
const thread = useStream<
  StateType<typeof AgentState.spec>,   // Define the shape of the state based on the annotation
  UpdateType<typeof AgentState.spec>   // Define the update format based on the annotation
>({
  apiUrl: "http://localhost:2024",    // API URL to get the data
  assistantId: "agent",              // Identifying the assistant
  messagesKey: "messages",           // The key for messages in the response
});
```

### **Explanation** 📚

1. **`Annotation.Root({...})`**:  
   This creates a **root annotation** that is the structure of our graph. Think of it as the blueprint or the skeleton that holds various pieces of information about the state of the conversation.

2. **`...MessagesAnnotation.spec`**:  
   By spreading `MessagesAnnotation.spec`, we reuse the pre-defined annotation that specifies how each message in the conversation is structured. This allows us to avoid defining this structure from scratch.

3. **`context: Annotation.Optional(Annotation.Any())`**:  
   This line is adding an **optional context** to the annotation. It can hold any type of data, which might be useful for storing extra information related to the conversation (e.g., user preferences, conversation history, etc.).

4. **`useStream<...>(...)`**:  
   We use the **`useStream`** hook to establish a **stream** for our conversation thread. This is where we specify:
   - `StateType<typeof AgentState.spec>`: The format of the initial state, based on the `AgentState` we just created.
   - `UpdateType<typeof AgentState.spec>`: The format for updates that we will receive while the conversation is ongoing.
   - We also define the `apiUrl`, `assistantId`, and the `messagesKey` that links to the specific thread of messages.

### **Real-World Example** 🌍

Think of this in a **customer service chatbot** scenario. You have a graph that tracks the conversation between a user and the chatbot. Each message exchanged between the user and the chatbot is annotated with specific details, such as:

- **Message content**: What was said.
- **Context**: Additional data such as user profile, previous conversations, or session ID.

This allows you to manage and structure the conversation effectively, store any extra information, and even track changes over time in a dynamic conversation.

## **Event Handling in LangGraph.js** 🔔

**Event handling** allows us to respond to different triggers during a conversation thread. LangGraph.js provides several built-in events that can be handled using **callback functions**. These events help us react to certain conditions or changes within the conversation.

### **Code Breakdown of Event Handling**

```typescript
const thread = useStream<...>({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
  messagesKey: "messages",
  // Event Handling
  onError: (error) => {
    console.error("Error:", error); // Called when there's an error
  },
  onFinish: () => {
    console.log("Stream finished"); // Called when the stream is finished
  },
  onUpdateEvent: (update) => {
    console.log("Update event received:", update); // Called when an update is received
  },
  onCustomEvent: (event) => {
    console.log("Custom event received:", event); // Handle custom events
  },
  onMetadataEvent: (metadata) => {
    console.log("Metadata event received:", metadata); // Handle metadata events
  },
});
```

### **Explanation** 📝

1. **`onError`**:  
   This callback function is called whenever there is an error in the conversation. You can use this to **log** or **display** an error message to the user. For example, if the connection to the server fails, the error will be caught here.

2. **`onFinish`**:  
   This event triggers when the conversation stream finishes. It's useful for **clean-up operations** or to let the user know that the conversation is over. For instance, after the chatbot finishes processing all the messages, this event can be used to show a summary or suggest next steps.

3. **`onUpdateEvent`**:  
   When the conversation thread is updated (for example, a new message is received), this event is triggered. You can use this to dynamically update the UI with the latest information, such as appending new messages to the chat.

4. **`onCustomEvent`**:  
   This handles any **custom events** that you might define for your application. A custom event could be a special action triggered during the conversation, such as updating user preferences or sending a survey.

5. **`onMetadataEvent`**:  
   This event triggers when **metadata** about the conversation is received. For example, you may want to track how many times the user has interacted with the chatbot, or fetch additional details that provide context to the current conversation.

### **Real-World Example** 🌍

Let’s consider a **support ticket system** in a SaaS application:

- When a user submits a new support ticket, you want to trigger an **`onUpdateEvent`** to refresh the UI with the latest status of the ticket (e.g., "Ticket received").
- If something goes wrong, the **`onError`** callback will be triggered to inform the user of the issue, such as "Sorry, we couldn't submit your ticket."
- When the support agent finishes responding to the ticket, you can use **`onFinish`** to notify the user that their issue has been resolved.

## **Summary** 📌

In this tutorial, we explored how to manage a conversation thread using **LangGraph.js** annotations and how to handle various events to make the application more interactive and dynamic. To summarize:

- **Graph Annotations**: Reuse existing annotation types to manage the state of messages and context in a conversation thread.
- **Event Handling**: Respond to key events during the conversation, such as errors, updates, and custom actions.

By understanding and utilizing these concepts, you can build more interactive applications like **chatbots**, **customer service platforms**, and **support systems**, where you need to track the state and respond to user interactions in real-time.

---

**Happy Coding!** 🎉