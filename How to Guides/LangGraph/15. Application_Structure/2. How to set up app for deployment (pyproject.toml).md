# 2. How to set up app for deployment (pyproject.toml)

# Setting Up LangGraph Application for Deployment

Deploying a LangGraph application requires some configuration, specifically defining dependencies and environment variables, creating the required files, and setting up the actual graph structure. This guide will help you understand the key steps needed to prepare your LangGraph project for deployment, including the **`pyproject.toml`** file.

---

## 1. What is LangGraph?

LangGraph is a framework for building, deploying, and managing language models in the form of graph-based applications. It allows users to build complex workflows involving multiple nodes (or steps), making it ideal for applications requiring sophisticated processing.

**Real-World Example**: Think of an AI chatbot system. LangGraph can be used to define the flow of interactions between the user and the chatbot, like processing input, generating responses, and making decisions based on context.

---

## 2. Project Structure for Deployment

Before getting into the deployment specifics, let’s look at how your project should be organized:

### Example Project Structure:

```plaintext
my-app/
├── my_agent  # All project code lies within this folder
│   ├── utils  # Utilities for your graph
│   │   ├── __init__.py
│   │   ├── tools.py  # Tools for your graph
│   │   ├── nodes.py  # Node functions for your graph
│   │   └── state.py  # State definition of your graph
│   ├── __init__.py
│   └── agent.py  # Code for constructing your graph
├── .env  # Environment variables file
├── langgraph.json  # LangGraph configuration file
└── pyproject.toml  # Defines dependencies for your project
```

Here, the project includes:
- **`my_agent/`**: The main code folder where graph logic resides.
- **`pyproject.toml`**: A file used to manage project dependencies (we will cover this in more detail).
- **`.env`**: This file stores environment variables, which can include API keys and other configuration details.
- **`langgraph.json`**: This configuration file is required for LangGraph deployment and specifies how your graph should run.

---

## 3. Managing Dependencies with **`pyproject.toml`**

The **`pyproject.toml`** file is used to define the Python dependencies for your LangGraph project. Here, you list the required Python packages that your application needs in order to run.

### Example **`pyproject.toml`** File:

```toml
[tool.poetry]
name = "my-agent"
version = "0.0.1"
description = "An excellent agent build for LangGraph cloud."
authors = ["Polly the parrot <1223+polly@users.noreply.github.com>"]
license = "MIT"
readme = "README.md"

[tool.poetry.dependencies]
python = ">=3.9.0,<3.13"
langgraph = "^0.2.0"
langchain-fireworks = "^0.1.3"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
```

### Key sections:
- **`[tool.poetry]`**: Provides metadata about the project, such as the project name, version, and license.
- **`[tool.poetry.dependencies]`**: Lists the dependencies your project requires (like `langgraph`, `langchain-fireworks`).
- **`[build-system]`**: Specifies the build system used (in this case, **Poetry**).

---

## 4. Environment Variables

Environment variables store important information that is needed to run your application, such as API keys and settings for different environments (development, production).

### Example **`.env`** File:

```plaintext
MY_ENV_VAR_1=foo
MY_ENV_VAR_2=bar
FIREWORKS_API_KEY=your_api_key
```

### Explanation:
- **`MY_ENV_VAR_1` and `MY_ENV_VAR_2`**: These are custom environment variables that your application might use.
- **`FIREWORKS_API_KEY`**: This could be an API key used to interact with external services.

---

## 5. Defining Your Graph (Agent Logic)

In LangGraph, your application is structured as a **graph**, which is made up of **nodes** (steps in the workflow) and **edges** (connections between nodes).

### Example **`agent.py`** File (Defining a Graph):

```python
from typing import Literal
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, END, START
from my_agent.utils.nodes import call_model, should_continue, tool_node
from my_agent.utils.state import AgentState

class GraphConfig(TypedDict):
    model_name: Literal["anthropic", "openai"]

workflow = StateGraph(AgentState, config_schema=GraphConfig)

workflow.add_node("agent", call_model)
workflow.add_node("action", tool_node)
workflow.add_edge(START, "agent")

workflow.add_conditional_edges(
    "agent", should_continue, {
        "continue": "action",
        "end": END,
    }
)
workflow.add_edge("action", "agent")

graph = workflow.compile()
```

### Explanation of Code:

- **`StateGraph(AgentState, config_schema=GraphConfig)`**: This defines a state graph using an initial state (`AgentState`) and a configuration schema.
- **`workflow.add_node()`**: Adds nodes to the graph. The nodes represent different actions or tasks in the workflow.
- **`workflow.add_edge()`**: Defines the connections between the nodes (from `START` to `agent`, and from `action` back to `agent`).
- **`graph = workflow.compile()`**: Compiles the graph into a format that can be deployed.

This setup defines a flow where an agent performs an action and then decides whether to continue or end based on conditions.

---

## 6. LangGraph API Configuration File (langgraph.json)

The **`langgraph.json`** file links the code you've written to the LangGraph API configuration. It tells LangGraph where to find your graph and any dependencies needed to run it.

### Example **`langgraph.json`** File:

```json
{
  "dependencies": ["."],
  "graphs": {
    "agent": "./my_agent/agent.py:graph"
  },
  "env": ".env"
}
```

### Key points:
- **`"graphs"`**: Specifies the path to the compiled graph (`agent` in this case).
- **`"env"`**: Points to the **`.env`** file, which contains environment variables.

---

## 7. Final Steps

Once you’ve configured your **`pyproject.toml`**, **`.env`**, and **`langgraph.json`**, you’re ready to deploy the application. The LangGraph framework will use these files to understand the dependencies and the graph structure, making it easy to deploy either to the LangGraph cloud or to a self-hosted environment.

---

## Real-World Example of LangGraph Use

Imagine you're building a **customer service chatbot** that processes customer queries. You could define different steps (nodes) in the LangGraph as follows:
1. **Input Node**: Receives the customer’s question.
2. **Processing Node**: Analyzes the question (perhaps using an NLP model).
3. **Response Node**: Sends the generated answer to the user.

This could be deployed on LangGraph Cloud, allowing the chatbot to scale efficiently.

---

## Summary

Setting up a LangGraph application for deployment involves:
1. **Specifying dependencies** in **`pyproject.toml`** to ensure the project has the required packages.
2. **Setting environment variables** in a **`.env`** file for configuration.
3. **Defining the graph** structure and nodes that represent the application's logic.
4. **Creating the LangGraph API configuration file** to specify how LangGraph should handle the graph.

These steps will allow you to deploy and manage your LangGraph-based applications efficiently.

--- 

Feel free to ask if you need more clarity or have specific questions!