# How to Test a LangGraph App Locally ðŸ§‘â€ðŸ’»ðŸš€

Testing a LangGraph app locally helps ensure that everything is working as expected before deploying it. In this guide, we'll explain how to set up and test your LangGraph app on your local machine, step by step.

### Prerequisites ðŸ› ï¸

Before diving into testing, you need to have:
1. A **LangGraph app** already set up with a valid configuration file.
2. The **compiled graph** that you want to test.
3. A valid **LangChain API key** to authenticate your app with LangGraph Cloud.

Let's break down the steps involved in testing the app locally.

## 1. Install the LangGraph CLI Package ðŸ’»

To test your LangGraph app locally, you first need to install the LangGraph CLI package. This is a command-line interface tool that allows you to interact with LangGraph from your terminal.

Run the following command in your terminal:

```bash
pip install -U "langgraph-cli[inmem]"
```

This command installs the LangGraph CLI in **in-memory mode**, which is suitable for development and testing.

### Explanation:
- `pip`: The Python package installer.
- `install -U`: Installs or upgrades the specified package.
- `"langgraph-cli[inmem]"`: Installs the LangGraph CLI with in-memory support.

---

## 2. Set Up Your API Key ðŸ”‘

To interact with LangGraph Cloud, you need to authenticate using an API key. You can generate an API key from the LangSmith UI.

Hereâ€™s how to do it:
1. Go to the LangSmith UI.
2. Navigate to **Settings > API Keys**.
3. Create a new API key and store it securely.

After obtaining the API key, add it to your `.env` file like this:

```bash
LANGSMITH_API_KEY = <your-api-key>
```

This makes your API key available to your LangGraph app for authentication.

---

## 3. Start the API Server for Local Testing ðŸš€

Now that you have everything set up, it's time to run the LangGraph API server locally.

To start the server, run:

```bash
langgraph dev
```

This will launch the LangGraph server on your local machine, and you should see an output like this:

```bash
Ready!
API: http://localhost:2024
Docs: http://localhost:2024/docs
LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
```

### Explanation:
- `langgraph dev`: This command starts the LangGraph server in **in-memory mode**, which is ideal for testing.
- `localhost:2024`: This is the local address where the API server is running.
- **Web UI**: The URL provided allows you to interact with LangGraph through a browser-based interface.

---

## 4. Interact with the Server Using LangGraph SDK ðŸ’¬

Once the server is up and running, you can interact with it using the LangGraph SDK. Letâ€™s start by initializing the client.

### Initialize with Authentication:

Hereâ€™s how to initialize the client with your API key in **Python**:

```python
from langgraph_sdk import get_client

# Initialize the client with the server URL and API key
client = get_client(url=<DEPLOYMENT_URL>, api_key=<LANGSMITH_API_KEY>)

# Choose the graph you want to test (in this case, "agent")
assistant_id = "agent"
# Create a new thread for the graph to run
thread = await client.threads.create()
```

### Explanation:
- `get_client`: Initializes the LangGraph client to interact with the server.
- `url=<DEPLOYMENT_URL>`: The local or cloud URL of the server.
- `api_key=<LANGSMITH_API_KEY>`: The authentication key for accessing LangGraph Cloud.
- `client.threads.create()`: Creates a new thread to initiate a conversation with the graph.

---

## 5. Test Your Graph ðŸš¦

Now that you have your client initialized, itâ€™s time to test the graph. In this example, we'll simulate a conversation where the user asks for the weather.

### Example Request:

```python
input = {"messages": [{"role": "user", "content": "what's the weather in sf"}]}

# Send the request to the graph and stream updates
async for chunk in client.runs.stream(
    thread["thread_id"],
    assistant_id,
    input=input,
    stream_mode="updates",
):
    print(f"Receiving new event of type: {chunk.event}...")
    print(chunk.data)
    print("\n\n")
```

### Explanation:
- `input`: The input message from the user. In this case, the user asks about the weather.
- `client.runs.stream()`: Sends the input to the LangGraph server and streams the response back.
- `chunk.event`: Prints the type of event (such as `response` or `error`).
- `chunk.data`: Displays the actual response from the graph.

When this code runs, you should see the graph's response displayed in your console.

---

## 6. In-Memory Mode vs. Persistent Storage ðŸ“‚

In **in-memory mode**, the LangGraph server keeps data temporarily in memory. This is perfect for testing and development. However, for production, it's recommended to use a persistent storage backend.

To use persistent storage, run:

```bash
langgraph up
```

This requires **Docker** to be installed on your machine.

### Why Use Persistent Storage?
- **In-Memory Mode**: Faster but not suitable for long-term storage or large-scale production.
- **Persistent Storage**: Better for real-world applications where data needs to be stored and accessed over time.

---

## Real-World Example: Testing a Virtual Assistant ðŸ¤–

Imagine you are building a virtual assistant with LangGraph. Youâ€™ve configured a graph called "agent" to respond to user queries. Using the steps above, you can test the assistant locally before deploying it to production.

1. **Set up**: You create a configuration file for the assistant, install necessary dependencies, and set up authentication.
2. **Test Locally**: You use the LangGraph CLI to start the server and interact with your assistant to ensure that it can correctly respond to user queries like "What's the weather?".
3. **Deploy**: Once everything works locally, you can deploy the assistant to LangGraph Cloud for production use.

This process ensures that your virtual assistant works flawlessly in real-world conditions before going live.

---

### Conclusion âœ¨

Testing your LangGraph app locally is crucial for ensuring that everything works as expected before you move to production. By following the steps outlined above, you can set up a local environment, interact with the LangGraph server, and test your graphâ€™s functionality efficiently.