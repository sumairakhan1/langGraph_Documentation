# 3. How to set up app for deployment (JavaScript)


# How to Set Up a LangGraph.js Application for Deployment

In this guide, we will walk through how to deploy a LangGraph.js application. LangGraph.js is a powerful JavaScript framework for building graph-based applications. To deploy your app, you need to configure it with necessary dependencies, environment variables, and define your graphs. Let's dive into the details!

---

### 1. Folder Structure üìÇ

Before setting up the app for deployment, it's essential to understand the folder structure of the LangGraph.js application. Here‚Äôs an example of how the project might be organized:

```
my-app/
‚îú‚îÄ‚îÄ src/                # All the project code lies within this folder
‚îÇ   ‚îú‚îÄ‚îÄ utils/          # Optional utilities for your graph
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools.ts    # Tools for your graph
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nodes.ts    # Node functions for your graph
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ state.ts    # State definition of your graph
‚îÇ   ‚îî‚îÄ‚îÄ agent.ts        # Code for constructing your graph
‚îú‚îÄ‚îÄ package.json        # Project dependencies
‚îú‚îÄ‚îÄ .env                # Environment variables
‚îî‚îÄ‚îÄ langgraph.json      # Configuration file for LangGraph
```

### 2. Specify Dependencies üì¶

A **`package.json`** file is where you list all the project dependencies. Dependencies are external packages or libraries that your application needs to run properly.

**Example `package.json`:**

```json
{
  "name": "langgraphjs-studio-starter",
  "packageManager": "yarn@1.22.22",
  "dependencies": {
    "@langchain/community": "^0.2.31",
    "@langchain/core": "^0.2.31",
    "@langchain/langgraph": "^0.2.0",
    "@langchain/openai": "^0.2.8"
  }
}
```

### **Explanation of `package.json` fields:**
- **name**: The name of your project.
- **packageManager**: Specifies the package manager, in this case, Yarn.
- **dependencies**: A list of all external libraries that your application will use (LangChain, LangGraph, OpenAI, etc.).

By adding these dependencies, you ensure your app has all the necessary libraries to interact with LangGraph, OpenAI, and other services.

---

### 3. Specify Environment Variables üåç

Environment variables store configuration details like API keys and other sensitive data. These variables can be kept in a `.env` file for easy access and security.

**Example `.env`:**

```env
MY_ENV_VAR_1=foo
MY_ENV_VAR_2=bar
OPENAI_API_KEY=key
TAVILY_API_KEY=key_2
```

### **Explanation of `.env` file:**
- These variables store configuration details that the app needs for execution. 
- **OPENAI_API_KEY**: The API key for interacting with OpenAI models.
- **TAVILY_API_KEY**: API key for using the Tavily search tool.

By using `.env`, you keep your sensitive data out of your main codebase, which helps prevent accidental exposure.

---

### 4. Define Graphs and Agents üß†

In LangGraph, **graphs** are the core building blocks of your app. A graph is a set of connected nodes, where each node performs a specific task. You define these nodes in your `agent.ts` file.

**Example `agent.ts`:**

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { TavilySearchResults } from "@langchain/community/tools/tavily_search";
import { StateGraph } from "@langchain/langgraph";

const tools = [new TavilySearchResults({ maxResults: 3 })];

// Define the function that calls the model
async function callModel(state) {
  const model = new ChatOpenAI({ model: "gpt-4" }).bindTools(tools);
  const response = await model.invoke([
    { role: "system", content: `You are a helpful assistant. The current date is ${new Date().getTime()}.` },
    ...state.messages
  ]);
  return { messages: response };
}

// Define the function that determines whether to continue or not
function routeModelOutput(state) {
  const messages = state.messages;
  const lastMessage = messages[messages.length - 1];
  if (lastMessage?.tool_calls?.length > 0) {
    return "tools";
  }
  return "__end__";
}

// Define a new graph
const workflow = new StateGraph()
  .addNode("callModel", callModel)
  .addNode("tools", new ToolNode(tools))
  .addEdge("__start__", "callModel")
  .addConditionalEdges("callModel", routeModelOutput, ["tools", "__end__"])
  .addEdge("tools", "callModel");

// Compile the graph
export const graph = workflow.compile();
```

### **Explanation of Code:**
- **`callModel()`**: This function interacts with the OpenAI model and fetches a response based on the current state.
- **`routeModelOutput()`**: Determines which node to execute next, based on the state of the conversation.
- **`StateGraph()`**: This is where the graph is created, nodes are added, and edges (connections between nodes) are defined.
- **`workflow.compile()`**: Compiles the graph, making it ready for deployment.

---

### 5. Assign Compiled Graph to Variable üîó

After you define your graph, you need to assign the compiled graph to a variable. This is essential for LangGraph Cloud to recognize your graph.

---

### 6. Create LangGraph API Configuration File üîß

The **`langgraph.json`** file is used to configure the deployment settings for your application. It specifies where to find the graph and what dependencies are required.

**Example `langgraph.json`:**

```json
{
  "node_version": "20",
  "dockerfile_lines": [],
  "dependencies": ["."],
  "graphs": {
    "agent": "./src/agent.ts:graph"
  },
  "env": ".env"
}
```

### **Explanation of `langgraph.json`:**
- **`node_version`**: Specifies which version of Node.js to use.
- **`graphs`**: Points to the location of the compiled graph (`agent.ts:graph`).
- **`env`**: Specifies the `.env` file that contains environment variables.

---

### Real-World Example üåç

Imagine you're building a customer service chatbot that helps users with various queries about products. You can define a graph where:
1. The **`callModel()`** node interacts with OpenAI to fetch responses.
2. The **`tools`** node uses a search tool (like **TavilySearchResults**) to gather product details.
3. The chatbot can ask for more information or end the conversation, depending on the user's queries.

This setup can be deployed to a cloud server or hosted locally for use in a production environment.

---

### 7. Final Steps üöÄ

1. **Push the code to GitHub**: Once your code is ready, upload it to GitHub.
2. **Deploy your app**: Follow the steps to deploy your LangGraph application on LangGraph Cloud or self-host it.

---

By following these steps, you can deploy your LangGraph.js application, integrate various tools, and make it interact with services like OpenAI!