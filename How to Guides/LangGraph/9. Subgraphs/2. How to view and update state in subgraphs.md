# 2. How to view and update state in subgraphs

# ğŸŒŸ Understanding Subgraphs in LangGraph: Viewing and Updating State

When working with **LangGraph**, subgraphs allow you to break down complex workflows into manageable parts. This guide will cover:

âœ… **How to view and update the state of subgraphs**  
âœ… **Real-world use cases**  
âœ… **Step-by-step breakdown of the code**  

---

## ğŸ“Œ **What is a Subgraph?**
A **subgraph** is a smaller, self-contained graph inside a larger parent graph. It has its own state and logic. 

For example, in a chatbot application, a **subgraph** might handle weather queries, while the **parent graph** handles general conversations.

ğŸŸ¢ **Real-World Example:**  
Imagine you are building an AI assistant for a travel booking website. Users can ask about flights, hotels, or the weather.  
- The **parent graph** handles all types of user queries.  
- The **subgraph** specifically fetches weather data when needed.

---

## ğŸš€ **Why View and Update State in Subgraphs?**
Once you **add persistence**, you can:
1. **Inspect** the state during an interaction to help users make decisions.  
2. **Rewind** the subgraph to debug or correct errors.  
3. **Modify** the state dynamically to fine-tune responses.

---
## âš™ **Step 1: Install Required Packages**
To get started, install the `langgraph` package:
```python
%%capture --no-stderr
%pip install -U langgraph
```
This installs the **LangGraph** library, which helps in building AI-powered graphs.

---
## ğŸ”‘ **Step 2: Set API Keys**
We need an **API key** for OpenAI to use language models.

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("OPENAI_API_KEY")
```
ğŸ”¹ This function checks if an **environment variable** is set.  
ğŸ”¹ If not, it **prompts the user** to enter the key.

---
## ğŸŒ **Step 3: Define a Subgraph**
The **subgraph** in our example fetches weather data for a city.

### âœ… **1. Import Required Libraries**
```python
from langgraph.graph import StateGraph, END, START, MessagesState
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
```
- `StateGraph` â†’ Creates the graph.  
- `START` and `END` â†’ Define the beginning and end of a graph.  
- `MessagesState` â†’ Manages messages between nodes.  
- `ChatOpenAI` â†’ Calls OpenAIâ€™s GPT model.

### âœ… **2. Define a Tool to Get Weather Data**
```python
@tool
def get_weather(city: str):
    """Get the weather for a specific city"""
    return f"It's sunny in {city}!"
```
- The `@tool` decorator registers this as a **callable tool**.  
- It takes a **city name** and returns a **weather update**.

### âœ… **3. Initialize the LLM (Language Model)**
```python
raw_model = ChatOpenAI(model="gpt-4o")
model = raw_model.with_structured_output(get_weather)
```
- We use `ChatOpenAI` to load **GPT-4o**.
- `with_structured_output(get_weather)` tells the model to return **structured data**.

### âœ… **4. Define Subgraph State**
```python
class SubGraphState(MessagesState):
    city: str
```
- This defines the **state** that our subgraph will manage.
- The subgraph will track a **city name**.

### âœ… **5. Define Nodes in the Subgraph**
```python
def model_node(state: SubGraphState):
    result = model.invoke(state["messages"])
    return {"city": result["city"]}
```
- This node **processes input messages** and extracts the city name.

```python
def weather_node(state: SubGraphState):
    result = get_weather.invoke({"city": state["city"]})
    return {"messages": [{"role": "assistant", "content": result}]}
```
- This node **fetches the weather** based on the extracted city.

### âœ… **6. Build and Compile the Subgraph**
```python
subgraph = StateGraph(SubGraphState)
subgraph.add_node(model_node)
subgraph.add_node(weather_node)
subgraph.add_edge(START, "model_node")
subgraph.add_edge("model_node", "weather_node")
subgraph.add_edge("weather_node", END)
subgraph = subgraph.compile(interrupt_before=["weather_node"])
```
- `add_node()` â†’ Adds nodes to the graph.
- `add_edge()` â†’ Defines the **execution order**.
- `interrupt_before=["weather_node"]` â†’ Allows us to **pause execution** before fetching weather.

---
## ğŸŒ **Step 4: Define the Parent Graph**
The **parent graph** decides whether to **call the weather subgraph** or use a standard chatbot.

### âœ… **1. Define a Router State**
```python
from typing import Literal
from typing_extensions import TypedDict
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()

class RouterState(MessagesState):
    route: Literal["weather", "other"]
```
- `RouterState` keeps track of whether the query is about **weather** or **something else**.
- `MemorySaver()` helps **persist data** across executions.

### âœ… **2. Define a Router Model**
```python
class Router(TypedDict):
    route: Literal["weather", "other"]

router_model = raw_model.with_structured_output(Router)
```
- The router **classifies** the query into `"weather"` or `"other"`.

### âœ… **3. Define Routing Logic**
```python
def router_node(state: RouterState):
    system_message = "Classify the incoming query as either about weather or not."
    messages = [{"role": "system", "content": system_message}] + state["messages"]
    route = router_model.invoke(messages)
    return {"route": route["route"]}
```
- This node **analyzes** the query and **routes** it to the correct branch.

### âœ… **4. Define a Default Chatbot Node**
```python
def normal_llm_node(state: RouterState):
    response = raw_model.invoke(state["messages"])
    return {"messages": [response]}
```
- If the query is **not about weather**, this node handles it normally.

### âœ… **5. Define Routing Conditions**
```python
def route_after_prediction(state: RouterState) -> Literal["weather_graph", "normal_llm_node"]:
    if state["route"] == "weather":
        return "weather_graph"
    else:
        return "normal_llm_node"
```
- This function **decides** where to send the input.

---
## ğŸ— **Step 5: Build the Parent Graph**
```python
graph = StateGraph(RouterState)
graph.add_node(router_node)
graph.add_node(normal_llm_node)
graph.add_node("weather_graph", subgraph)
graph.add_edge(START, "router_node")
graph.add_conditional_edges("router_node", route_after_prediction)
graph.add_edge("normal_llm_node", END)
graph.add_edge("weather_graph", END)
graph = graph.compile(checkpointer=memory)
```
- The **parent graph**:
  - Starts at `router_node`.
  - Routes the query **dynamically**.
  - Uses **subgraph** if the query is about **weather**.

---
## ğŸ¯ **Final Thoughts**
âœ… **Subgraphs** make it easy to break down complex AI workflows.  
âœ… **State management** lets us **pause, inspect, or modify execution**.  
âœ… **Real-world use case**: AI assistants that handle different tasks dynamically.  

---
## ğŸ“¢ **What Next?**
ğŸš€ Try **customizing** the subgraph to handle **multiple queries (e.g., weather + flights)**!

## 2. How to View and Update State in Subgraphs ğŸ§ 

### Introduction to Subgraphs and State Persistence

In programming, particularly in graph-based systems like LangGraph, we can create **subgraphs** to model smaller units of logic that can be reused in multiple places. These subgraphs help us manage complex workflows and allow us to **pause**, **resume**, or **update** their states during execution. With **state persistence**, we can store, update, and manage this information at various stages, enabling better control and human-in-the-loop interactions.

### Real-World Example ğŸŒ

Think of an **online banking system**. You might want to display the current balance and transaction history to a user, and based on that, decide whether to allow a transfer or not. If a user asks about their balance, you can pause the process, show the data, let the user confirm, and then resume. Similarly, when the system asks for further actions, you might want to update the state based on user feedback.

### Key Concepts in Subgraph States

#### 1. **Persistent State** ğŸ”’
State refers to the **information** held at any point during execution, such as variables, messages, or user actions. This information can be stored across **interrupts**, allowing you to modify it during an ongoing process. For example, when the system asks for the weather, you may store the city, like "San Francisco," and use this information later.

#### 2. **State Transitions** ğŸ”„
As your program runs, the state transitions from one node to another. Each node in the graph does a specific task. In our example, nodes might check weather, confirm actions, or route different queries.

#### 3. **Interrupts** â¸ï¸
An interrupt happens when the system temporarily pauses execution and requires a decision from the user, such as confirming whether to proceed with an action or to correct something in the input.

---

## Let's Walk Through the Code ğŸ–¥ï¸

Hereâ€™s how we can implement and test these subgraphs with a simple weather-checking example. We will go through each part of the code, explain it, and break down its functionality.

### Step 1: Installing Required Packages ğŸ“¦

```bash
%%capture --no-stderr
%pip install -U langgraph
```
This installs the `langgraph` package, which helps us work with stateful graphs for complex interactions. The `%%capture` command ensures that the output is captured silently.

### Step 2: Define Subgraph and Nodes ğŸ§©

Here, we define a **subgraph** for checking the weather. It will use a node to fetch the weather for a given city and another node to process the response.

```python
from langgraph.graph import StateGraph, END, START, MessagesState
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI


@tool
def get_weather(city: str):
    """Get the weather for a specific city"""
    return f"It's sunny in {city}!"
```

- **`get_weather` Function**: This is a tool that returns a hardcoded weather report. The function takes `city` as input and returns a message like "It's sunny in San Francisco!"
- **`@tool` Decorator**: This tells LangGraph that `get_weather` is a tool that can be invoked in our graph.

### Step 3: Create Nodes and Graph ğŸ’¡

```python
raw_model = ChatOpenAI(model="gpt-4o")
model = raw_model.with_structured_output(get_weather)

class SubGraphState(MessagesState):
    city: str

def model_node(state: SubGraphState):
    result = model.invoke(state["messages"])
    return {"city": result["city"]}

def weather_node(state: SubGraphState):
    result = get_weather.invoke({"city": state["city"]})
    return {"messages": [{"role": "assistant", "content": result}]}

subgraph = StateGraph(SubGraphState)
subgraph.add_node(model_node)
subgraph.add_node(weather_node)
subgraph.add_edge(START, "model_node")
subgraph.add_edge("model_node", "weather_node")
subgraph.add_edge("weather_node", END)
subgraph = subgraph.compile(interrupt_before=["weather_node"])
```

- **State Graph**: `StateGraph` is a container for the graph's logic. It manages the state transitions between nodes (like `model_node` and `weather_node`).
- **Nodes**: `model_node` uses the OpenAI model to process messages and identify the city; `weather_node` calls the `get_weather` function to get weather data.
- **State Transitions**: We link these nodes using `add_edge`, and the graph will execute in sequence from `START` â†’ `model_node` â†’ `weather_node` â†’ `END`.
- **Interrupt Before**: The `interrupt_before` keyword allows us to pause the execution right before the `weather_node`.

### Step 4: Define Parent Graph ğŸŒ³

In a larger application, you might have a **parent graph** that coordinates multiple subgraphs. For example, you could route a user's query to either the weather subgraph or another normal query handling process.

```python
from typing import Literal
from typing_extensions import TypedDict
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()

class RouterState(MessagesState):
    route: Literal["weather", "other"]

router_model = raw_model.with_structured_output(Router)

def router_node(state: RouterState):
    system_message = "Classify the incoming query as either about weather or not."
    messages = [{"role": "system", "content": system_message}] + state["messages"]
    route = router_model.invoke(messages)
    return {"route": route["route"]}

graph = StateGraph(RouterState)
graph.add_node(router_node)
graph.add_node("weather_graph", subgraph)
graph.add_edge(START, "router_node")
graph.add_conditional_edges("router_node", route_after_prediction)
graph.add_edge("weather_graph", END)
graph = graph.compile(checkpointer=memory)
```

- **Router Node**: This node checks if the user's query is related to weather. If yes, it routes the query to the `weather_graph`, otherwise, it proceeds to the next node (normal LLM handling).
- **Conditional Edges**: `add_conditional_edges` lets you decide which path the graph will take based on the output of the `router_node`.

### Step 5: Test the System with Queries ğŸ§ª

Now weâ€™ll test our graph with two types of inputs: one for weather and another for general queries.

```python
# Test with a normal query
inputs = {"messages": [{"role": "user", "content": "hi!"}]}
for update in graph.stream(inputs, config=config, stream_mode="updates"):
    print(update)
```

- **Normal Query (`hi!`)**: This doesnâ€™t relate to weather, so the system responds normally.

### Step 6: Handle Breakpoints and State Resumption â©

```python
# Query that goes to the weather subgraph
inputs = {"messages": [{"role": "user", "content": "what's the weather in SF"}]}
for update in graph.stream(inputs, config=config, stream_mode="updates"):
    print(update)
```

- **Weather Query**: This routes to the weather subgraph. We can pause the execution at any breakpoint (before the `weather_node`) and later resume it. 

```python
# Resume execution from the breakpoint
for update in graph.stream(None, config=config, stream_mode="values", subgraphs=True):
    print(update)
```

### Explanation of Results:
- The graph successfully identifies the route and updates the state at different nodes.
- The system pauses at the weather node, updates the city state (`San Francisco`), and resumes execution once the state is updated.

---

## Conclusion: The Power of Subgraphs and State Management ğŸ’¥

By using **subgraphs** with state persistence, you can create complex workflows that interact with users, pause for inputs, and resume based on updated states. This system can be applied to various use cases like:

- **Customer support bots** that need to pause for user approval before proceeding.
- **Interactive assistants** that adjust responses based on ongoing conversations.

Through this approach, you ensure that your applications are **dynamic**, **interactive**, and **user-friendly**!

# ğŸ® Resuming from Specific Subgraph Node

In complex graph-based systems, there may be times when you need to pause the flow at a certain node, and later resume from that specific point, even if it's deep inside a subgraph. Let's break this down in a beginner-friendly manner and explore how to achieve this functionality, with detailed examples and real-world applications.

## ğŸ§© Concept: Subgraphs and State History

A **subgraph** refers to a portion of a graph that performs its own computation but is part of a larger process. These subgraphs can have states, which track the progress of execution.

### Real-World Example: 
Imagine a chatbot with a multi-step conversation flow. Each part of the conversation is handled by a different subgraph (e.g., weather query, booking a ticket). If the chatbot gets paused in the middle of a conversation, we can resume from the exact point where it stoppedâ€”whether that's the weather query or the ticket booking process.

## ğŸ”„ Example Explained: Resuming from a Subgraph Node

Let's say you have a **weather graph** that handles a conversation about weather queries. When the graph is paused, we want to resume from a specific point (say, the "model_node" which decides the weather conditions). 

### Code Example 1: Replay from Subgraph

Here's how we can replay from a specific subgraph state:

```python
# 1. Get the state before the weather subgraph
parent_graph_state_before_subgraph = next(
    h for h in graph.get_state_history(config) if h.next == ("weather_graph",)
)

# 2. Get the state before the "model_node" inside the weather subgraph
subgraph_state_before_model_node = next(
    h
    for h in graph.get_state_history(parent_graph_state_before_subgraph.tasks[0].state)
    if h.next == ("model_node",)
)
```

**Explanation of Code:**
- **Step 1:** We retrieve the state history of the entire graph before it entered the "weather_graph" subgraph.
- **Step 2:** From the state of the `weather_graph`, we explore its history further to get the state before the "model_node".

### Real-World Usage:
This can be useful in debugging or in situations where you want to test a particular portion of a flow without running the entire sequence.

## ğŸ¯ Example 2: Resuming Execution from Specific Node

Now that we've identified the right state, let's resume execution from the "model_node" inside the subgraph.

```python
# 3. Resume streaming from the exact point inside the subgraph
for value in graph.stream(
    None,
    config=subgraph_state_before_model_node.config,
    stream_mode="values",
    subgraphs=True,
):
    print(value)
```

**Explanation of Code:**
- **Line 1:** We call `graph.stream()` to resume execution. The `config` parameter is set to the configuration that was captured from the exact state we paused at (`subgraph_state_before_model_node.config`).
- **Line 2:** The `stream_mode="values"` allows us to see the actual values as the subgraph is resumed. The `subgraphs=True` ensures that we include subgraph data in the streaming output.

### Real-World Usage:
Imagine you want to resume a chatbot interaction from a specific point (e.g., after asking for the user's location) to continue where you left off. This technique allows precise control over which part of the process you want to test or continue.

## ğŸ› ï¸ Modifying State Inside a Subgraph

If we need to modify the state of a subgraph (e.g., update the message from "San Francisco" to "Los Angeles"), we can do so by passing the configuration of the subgraph and calling the `update_state` method.

### Code Example 3: Updating State

```python
# 1. Set the configuration for the subgraph
config = {"configurable": {"thread_id": "4"}}
inputs = {"messages": [{"role": "user", "content": "what's the weather in sf"}]}

# 2. Stream updates based on the inputs
for update in graph.stream(inputs, config=config, stream_mode="updates"):
    print(update)
```

**Explanation of Code:**
- **Step 1:** We set up a configuration with a `thread_id` to track the specific subgraph instance we are working with. The `inputs` define the user's message (asking about the weather in San Francisco).
- **Step 2:** We use `graph.stream()` to send updates with the inputs and configuration. This simulates the userâ€™s request to the graph and updates the subgraph state accordingly.

### Real-World Usage:
This can be applied in cases where a chatbot needs to change the context, such as switching from one topic to another (e.g., from weather in SF to weather in LA). You can dynamically change the conversation based on user input.

## ğŸ”„ Acting as a Subgraph Node

Sometimes, instead of modifying the state of a subgraph, we may want to simulate the behavior of a node within the subgraph. By using the `as_node` argument, we can "act" as that node and directly provide the output without executing it.

### Code Example 4: Acting as a Node in Subgraph

```python
# 1. Set up the configuration and inputs
config = {"configurable": {"thread_id": "14"}}
inputs = {"messages": [{"role": "user", "content": "what's the weather in sf"}]}

# 2. Stream updates to simulate action before the weather node
for update in graph.stream(inputs, config=config, stream_mode="updates", subgraphs=True):
    print(update)

print("interrupted!")

# 3. Update the state directly with a custom response
state = graph.get_state(config, subgraphs=True)
graph.update_state(
    state.tasks[0].state.config,
    {"messages": [{"role": "assistant", "content": "rainy"}]},
    as_node="weather_node",  # Act as the weather_node
)

# 4. Continue streaming with the custom response
for update in graph.stream(None, config=config, stream_mode="updates", subgraphs=True):
    print(update)

# 5. Verify the updated message
print(graph.get_state(config).values["messages"])
```

**Explanation of Code:**
- **Step 1:** Set up the configuration and input for the user's message.
- **Step 2:** Start the graph stream, but we "interrupt" the normal flow to act before the `weather_node`.
- **Step 3:** We manually update the state of the `weather_node` to provide a custom message, "rainy", instead of relying on the graph's execution.
- **Step 4:** Continue the streaming process with the updated message.
- **Step 5:** Finally, we verify the state and see that the chatbot outputs the message "rainy" instead of continuing with the original graph logic.

### Real-World Usage:
This method can be useful in situations where you need to mock or simulate responses from certain nodes in a workflow, such as testing different responses for weather conditions without actually querying a weather API.

---

# Conclusion

### ğŸš€ Key Takeaways:
- **Subgraph Resumption:** Allows you to resume the execution of a process from a specific point within a subgraph, making it easier to debug or test individual parts of complex workflows.
- **State Modifications:** You can modify the state of a subgraph to dynamically update the configuration or inputs, helping to simulate user interactions or real-time data changes.
- **Node Simulation:** By acting as a specific node within a subgraph, you can control the flow of data, mock responses, and influence outcomes in a granular manner.

These techniques are useful in any system where complex, multi-step workflows need to be paused, resumed, or modified at any stage. They provide powerful tools for testing, debugging, and enhancing dynamic systems.

---

# ğŸŒ **Understanding Acting as the Entire Subgraph in LangGraph**  

## ğŸ” **Introduction**  
When working with LangGraph, you may need to update the state of a graph at different levels. One powerful method is acting as the entire **subgraph** rather than just a single node. This means updating the whole structure of a nested computation at once.

This concept is useful in real-world scenarios like **chatbots** or **AI assistants**, where you need to manipulate conversation states at different levels of abstraction.

---

## ğŸ— **What Does Acting as a Subgraph Mean?**  
In a LangGraph structure, a subgraph is a part of a larger graph. Instead of controlling a single node, we can control the whole subgraph, which allows us to manage complex AI workflows.

For example, if our AI assistant has a **weather module**, we can:
- Update the **entire weather subgraph** instead of just the weather response node.
- Control state at a **higher level**, making the system more flexible.

---

## ğŸ“ **Code Example: Acting as the Entire Subgraph**  
Let's look at a practical example where we query the weather in San Francisco and update the subgraph state.

### **ğŸ“Œ Step 1: Setting Up Configurations and Input**
```python
config = {"configurable": {"thread_id": "8"}}
inputs = {"messages": [{"role": "user", "content": "what's the weather in sf"}]}
```
- `config`: Contains a `thread_id` that uniquely identifies our request.
- `inputs`: Represents a user query asking about the weather.

---

### **ğŸ“Œ Step 2: Streaming the Graph Execution**
```python
for update in graph.stream(
    inputs, config=config, stream_mode="updates", subgraphs=True
):
    print(update)
print("interrupted!")
```
- `graph.stream()`: Streams execution updates from the graph.
- `stream_mode="updates"`: Ensures we receive updates incrementally.
- `subgraphs=True`: Enables subgraph processing.
- The loop **prints intermediate updates**, and execution is interrupted before reaching the weather node.

---

### **ğŸ“Œ Step 3: Updating the Subgraph State**
```python
graph.update_state(
    config,
    {"messages": [{"role": "assistant", "content": "rainy"}]},
    as_node="weather_graph",
)
```
- `graph.update_state()`: Updates the state of the graph.
- `as_node="weather_graph"`: Specifies that we are updating the **entire weather subgraph** rather than just a node.
- The assistant responds with `"rainy"`.

---

### **ğŸ“Œ Step 4: Fetching Updated Messages**
```python
for update in graph.stream(None, config=config, stream_mode="updates"):
    print(update)

print(graph.get_state(config).values["messages"])
```
- The final state is retrieved, showing the expected AI response `"rainy"`.

---

## ğŸ¯ **Real-World Use Case: AI Chatbot for Customer Support**  
Imagine building a **customer support chatbot** for an e-commerce site:
1. A **router node** determines if the query is about **order status** or **product details**.
2. If it's about **order status**, it routes the request to the **order subgraph**.
3. Acting as the entire subgraph allows us to **update order status** dynamically, without modifying individual nodes.

This approach improves **flexibility** and **scalability** in AI-driven applications.

---

## ğŸ”„ **Handling Double-Nested Subgraphs**  
What if we have multiple levels of graphs? Let's explore how LangGraph manages **double-nested** structures.

### **ğŸ“Œ Step 1: Defining the Router and State**
```python
from typing import Literal
from typing_extensions import TypedDict
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()

class RouterState(MessagesState):
    route: Literal["weather", "other"]

class Router(TypedDict):
    route: Literal["weather", "other"]

router_model = raw_model.with_structured_output(Router)
```
- `RouterState`: Defines a state object for routing.
- `route`: Determines if the query is **weather-related** or **not**.
- `MemorySaver()`: Helps track changes to graph states.

---

### **ğŸ“Œ Step 2: Implementing a Router Node**
```python
def router_node(state: RouterState):
    system_message = "Classify the incoming query as either about weather or not."
    messages = [{"role": "system", "content": system_message}] + state["messages"]
    route = router_model.invoke(messages)
    return {"route": route["route"]}
```
- The `router_node()` function classifies queries.
- It prepends a system message and sends data to the AI model.

---

### **ğŸ“Œ Step 3: Building the Graph with Nested Subgraphs**
```python
graph = StateGraph(RouterState)
graph.add_node(router_node)
graph.add_node(normal_llm_node)
graph.add_node("weather_graph", subgraph)
graph.add_edge(START, "router_node")
graph.add_conditional_edges("router_node", route_after_prediction)
graph.add_edge("normal_llm_node", END)
graph.add_edge("weather_graph", END)
graph = graph.compile()
```
- **Graph Structure**:
  - `router_node`: Routes queries.
  - `normal_llm_node`: Handles general queries.
  - `"weather_graph"`: A subgraph for weather queries.
- **Conditional Edges**:
  - If `route == "weather"`, it calls the `weather_graph`.
  - Otherwise, it calls `normal_llm_node`.

---

## ğŸ“Œ **Handling Grandparent Graphs (3 Levels of Nesting)**
In complex workflows, we may have **three levels** of subgraphs. Here's how to manage them.

### **ğŸ“Œ Step 1: Define the Grandfather State**
```python
class GrandfatherState(MessagesState):
    to_continue: bool

def router_node(state: GrandfatherState):
    return {"to_continue": True}  # Always continue processing
```
- `GrandfatherState`: Tracks whether to continue processing.
- `router_node()`: Always sets `to_continue=True`.

---

### **ğŸ“Œ Step 2: Build the Grandparent Graph**
```python
grandparent_graph = StateGraph(GrandfatherState)
grandparent_graph.add_node(router_node)
grandparent_graph.add_node("graph", graph)
grandparent_graph.add_edge(START, "router_node")
grandparent_graph.add_conditional_edges(
    "router_node", route_after_prediction, ["graph", END]
)
grandparent_graph.add_edge("graph", END)
grandparent_graph = grandparent_graph.compile(checkpointer=MemorySaver())
```
- The **grandparent graph** wraps around the parent and subgraph.
- It **conditionally routes queries** to the right graph.

---

### **ğŸ“Œ Step 3: Streaming and Updating State**
```python
config = {"configurable": {"thread_id": "2"}}
inputs = {"messages": [{"role": "user", "content": "what's the weather in sf"}]}
for update in grandparent_graph.stream(
    inputs, config=config, stream_mode="updates", subgraphs=True
):
    print(update)
```
- Similar to before, we process a **weather query** at three levels.

---

### **ğŸ“Œ Step 4: Inspecting State History**
```python
state = grandparent_graph.get_state(config, subgraphs=True)
print("Grandparent State:", state.values)
print("Parent Graph State:", state.tasks[0].state.values)
print("Subgraph State:", state.tasks[0].state.tasks[0].state.values)
```
- Retrieves the state of **all three graphs**.
- Useful for debugging nested AI workflows.

---

## âœ… **Conclusion**  
Acting as the **entire subgraph** rather than a single node is a **powerful technique** in LangGraph. It allows:
- **Efficient state updates** for complex AI workflows.
- **Better scalability** in chatbots, assistants, and decision trees.
- **Easier debugging** of multi-layered processing graphs.

---

### **ğŸ’¡ Key Takeaways**
âœ” Subgraphs allow **higher-level state updates**  
âœ” Used in **chatbots, AI assistants, and automation**  
âœ” Supports **multi-level graph nesting**  
âœ” Helps **debug and track AI decisions**  

Would you like a **real-world chatbot implementation** using this concept? ğŸš€