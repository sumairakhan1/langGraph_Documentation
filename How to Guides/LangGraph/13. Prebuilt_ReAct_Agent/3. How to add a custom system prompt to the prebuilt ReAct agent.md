# 3. How to add a custom system prompt to the prebuilt ReAct agent

# How to Add a Custom System Prompt to the Prebuilt ReAct Agent

In this tutorial, we will learn how to add a custom system prompt to a prebuilt **ReAct agent** using LangGraph and LangChain libraries. A **system prompt** is an instruction that tells the model how to behave or respond to the user's input.

This guide will help you modify the agent's behavior by adding a custom system prompt. Let‚Äôs dive into how we can do this.

## üì¶ Prerequisites

### Required Libraries
We will use the following libraries:
- **LangGraph**: For managing LLM (Large Language Model) workflows.
- **LangChain-OpenAI**: For interacting with OpenAI's GPT models.

### Setup

Before we start coding, make sure you have these libraries installed:

```bash
pip install -U langgraph langchain-openai
```

### Set Your OpenAI API Key

You need to set your OpenAI API key in your environment. The `getpass.getpass()` method will help to securely input your API key.

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("OPENAI_API_KEY")
```

Here, we check if the environment variable is already set. If it‚Äôs not, we will prompt the user to input the key securely.

## üöÄ Code Walkthrough

Now, let's look at the code where we add a custom system prompt.

### Step 1: Initialize the Model

We start by importing the necessary libraries and setting up the model using the `ChatOpenAI` class from LangChain. 

```python
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4", temperature=0)
```

- **ChatOpenAI**: We use the `gpt-4` model to interact with OpenAI's GPT API.
- **temperature=0**: This controls the randomness of the model‚Äôs responses. A value of `0` ensures deterministic outputs.

### Step 2: Define a Custom Tool

Next, we define a custom tool that can provide weather information based on the city. Here, we use the `tool` decorator from LangChain.

```python
from typing import Literal
from langchain_core.tools import tool

@tool
def get_weather(city: Literal["nyc", "sf"]):
    """Use this to get weather information."""
    if city == "nyc":
        return "It might be cloudy in NYC"
    elif city == "sf":
        return "It's always sunny in SF"
    else:
        raise AssertionError("Unknown city")
```

- **@tool decorator**: This makes the `get_weather` function available as a callable tool in our ReAct agent.
- **Literal["nyc", "sf"]**: This is a type hint to specify that the function only accepts "nyc" or "sf" as input for the city.

### Step 3: Set Up the System Prompt

Now, we add the custom **system prompt**. The system prompt modifies the behavior of the agent by providing a clear instruction on how the agent should respond.

```python
prompt = "Respond in Italian"
```

- **Respond in Italian**: This tells the agent to respond in the Italian language, no matter what the user inputs.

### Step 4: Create the ReAct Agent

Using LangGraph‚Äôs `create_react_agent()` function, we create the agent, passing the model, tools, and the custom prompt.

```python
from langgraph.prebuilt import create_react_agent

graph = create_react_agent(model, tools=tools, prompt=prompt)
```

### Step 5: Interact with the Agent

Finally, we send messages to the agent and print its responses using the `print_stream` function. This allows us to see how the agent behaves with the custom prompt.

```python
def print_stream(stream):
    for s in stream:
        message = s["messages"][-1]
        if isinstance(message, tuple):
            print(message)
        else:
            message.pretty_print()

inputs = {"messages": [("user", "What's the weather in NYC?")]}

print_stream(graph.stream(inputs, stream_mode="values"))
```

- **inputs**: We pass a user message asking about the weather in NYC.
- **graph.stream()**: This function sends the input to the agent and streams the response.
- **stream_mode="values"**: This ensures that we get the values from the stream instead of the entire metadata.

### Step 6: Output

Here is the expected output:

```plaintext
Human Message: What's the weather in NYC?
AI Message:
Tool Calls:
  get_weather (call_xxxxxxx)
  Args: city: nyc
Tool Message: It might be cloudy in NYC
AI Message: A New York potrebbe essere nuvoloso. (Translation: "New York might be cloudy.")
```

The agent responds in **Italian**, as instructed by the custom system prompt.

---

## üåç Real-World Use Case

### Language Localization

This technique is useful in real-world applications like **chatbots**, **customer service agents**, or **multilingual applications** where you need to respond in different languages based on the user‚Äôs preference. For instance:

- A **hotel booking assistant** that provides information in the user‚Äôs preferred language (e.g., Italian).
- **Customer support bots** that respond in the language specified by the user in their profile settings.

---

## üìù Key Takeaways

- **System prompts** are powerful tools to control the behavior of AI agents.
- You can modify the response style, tone, or even language by passing a custom system prompt.
- LangGraph and LangChain make it easy to integrate these changes with minimal code.

---

Let me know if you have any further questions or need additional help!