# 4. How to add human-in-the-loop processes to the prebuilt ReAct agent

# Adding Human-in-the-Loop Processes to Prebuilt ReAct Agent

In this tutorial, we will learn how to add a **Human-in-the-loop (HITL)** process to the prebuilt ReAct agent. The ReAct agent allows AI models to interact with external tools to carry out tasks based on user inputs. Human-in-the-loop adds an additional layer where humans can intervene or verify the tool‚Äôs actions before continuing, which is useful for handling ambiguous or sensitive situations.

Let's break this down and walk through how we can implement this in a way that is easy to understand for a beginner.

### üéØ What Is Human-in-the-loop?

Human-in-the-loop (HITL) is a system design that allows humans to intervene in an automated process to provide feedback, corrections, or additional information when necessary. This concept is widely used in **AI systems** and **machine learning** models where human oversight can be crucial.

#### üåç Real-World Example

Think about **self-driving cars**. While the car can drive autonomously most of the time, there are situations where a human driver might need to take control, such as navigating through an unknown or dangerous situation. This intervention process is an example of human-in-the-loop.

Similarly, in AI-powered chatbots or virtual assistants, a human might be required to review and approve certain actions (like interpreting ambiguous user requests or handling unusual situations).

---

### üì¶ Setup and Requirements

To begin with, we will need to install the required packages and set up our API keys for OpenAI.

```bash
%%capture --no-stderr
%pip install -U langgraph langchain-openai
```

Next, we will define our **environment variables** for the OpenAI API key. This will authenticate the AI model.

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("OPENAI_API_KEY")
```

- **Explanation**: `_set_env` ensures that the OpenAI API key is set up properly. If the key is not already available in the environment, it prompts you to input it securely.

---

### üßë‚Äçüíª Define Custom Tools

Now, let's define a simple **weather tool** that provides predefined responses based on the city. This tool will simulate a real-world scenario like fetching weather data.

```python
from typing import Literal
from langchain_core.tools import tool

@tool
def get_weather(location: str):
    """Use this to get weather information from a given location."""
    if location.lower() in ["nyc", "new york"]:
        return "It might be cloudy in nyc"
    elif location.lower() in ["sf", "san francisco"]:
        return "It's always sunny in sf"
    else:
        raise AssertionError("Unknown Location")
```

- **Explanation**:
  - `@tool` is a decorator that marks the function `get_weather` as a tool. The tool is used to fetch weather info.
  - The `location` parameter checks the city passed and returns a corresponding weather message.
  - If the location is unrecognized, it raises an `AssertionError`.

---

### ü§ñ Initialize the Model and Tools

Next, we'll initialize the AI model and specify the **tools** (in our case, the weather tool) that the AI agent will use to answer questions.

```python
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o", temperature=0)

tools = [get_weather]
```

- **Explanation**:
  - `ChatOpenAI` initializes the GPT-4 model with a temperature of 0, meaning the responses will be more deterministic and less random.
  - We associate our weather tool with the AI agent using `tools = [get_weather]`.

---

### üß† Human-in-the-loop Setup

To implement human-in-the-loop functionality, we need to create a **checkpoint system**. This allows the agent to pause before calling the tool, and the human can either approve or modify the request.

```python
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
```

- **Explanation**: `MemorySaver` is used to store the state of the agent, so we can pause and resume the process at the right points.

---

### üö¶ Interruption Before Tool Calls

We then use the `create_react_agent` function, with the `interrupt_before=["tools"]` option. This tells the agent to pause before calling the tools, allowing human oversight.

```python
from langgraph.prebuilt import create_react_agent

graph = create_react_agent(
    model, tools=tools, interrupt_before=["tools"], checkpointer=memory
)
```

- **Explanation**:
  - `interrupt_before=["tools"]` sets a breakpoint before any tool is called, ensuring the human can intervene.
  - `checkpointer=memory` ensures the state of the agent is saved and can be resumed after human intervention.

---

### üñºÔ∏è Stream Data and Verify

Now, we will create a function to print out the messages as the agent processes them.

```python
def print_stream(stream):
    """A utility to pretty print the stream."""
    for s in stream:
        message = s["messages"][-1]
        if isinstance(message, tuple):
            print(message)
        else:
            message.pretty_print()
```

- **Explanation**: This function iterates over the stream and prints out the AI's messages for review.

Now, let‚Äôs simulate a user asking for the weather in **San Francisco**.

```python
inputs = {"messages": [("user", "What is the weather in SF, CA?")]}
print_stream(graph.stream(inputs, stream_mode="values"))
```

- **Explanation**: The AI will stop before calling the `get_weather` tool. The system will print out the messages it receives, including the user‚Äôs query, but it won‚Äôt proceed to fetch the weather until we approve it.

---

### üõ†Ô∏è Handle Errors and Correct Inputs

During the human review process, the agent might produce errors due to unexpected inputs. In this case, we need to handle these errors and provide corrections manually.

For example, the agent may mistakenly send `"SF, CA"`, which the tool does not recognize. The human operator can correct the input to `"San Francisco"` before the tool is called.

```python
state = graph.get_state(config)
last_message = state.values["messages"][-1]
last_message.tool_calls[0]["args"] = {"location": "San Francisco"}
graph.update_state(config, {"messages": [last_message]})

print_stream(graph.stream(None, config, stream_mode="values"))
```

- **Explanation**:
  - We fetch the current state of the agent and modify the input to ensure it‚Äôs valid.
  - `graph.update_state` updates the state with the new message and resumes the process.

---

### üèÅ Conclusion

The human-in-the-loop system adds an essential layer of control and supervision to AI-powered agents, making sure that tools are used appropriately. Whether it's correcting a misinterpreted query or handling complex situations that require judgment, HITL ensures the AI behaves reliably and accurately.

---

### üöÄ Practical Application

This concept is valuable in many real-world applications, such as:

1. **Customer Service Chatbots**: Where a human agent can step in if the AI fails to understand a customer‚Äôs query.
2. **Financial Tools**: Where human oversight is necessary before making financial recommendations or transactions.
3. **Healthcare Assistants**: For reviewing medical queries and ensuring that sensitive data is handled correctly.

Human-in-the-loop ensures that automation can be as reliable as human intervention, making it a powerful tool in systems that require both automation and human expertise.