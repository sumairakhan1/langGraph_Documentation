# 7. How to create a ReAct agent from scratch

Here's a detailed and beginner-friendly explanation of how to create a **ReAct Agent from Scratch** using **LangGraph**, complete with real-world use cases and examples.  

---

# 🌟 **How to Create a ReAct Agent from Scratch**
ReAct (Reasoning + Acting) agents use a structured approach where they **reason** about a task and **act** based on their findings. Instead of generating a response directly, the agent follows a step-by-step **reasoning process** and decides whether it needs to use external tools (APIs, databases, etc.) before responding.

## 📌 **Why Create a Custom ReAct Agent?**
Prebuilt ReAct agents (like `create_react_agent`) make it easy to get started, but **custom agents** offer:
✅ More control over agent behavior  
✅ Ability to integrate **custom tools & APIs**  
✅ Enhanced debugging & optimization  

---

## 🚀 **Step 1: Setting Up the Environment**
Before we start coding, we need to install the required dependencies and set up API keys.

### 📥 **Install Required Packages**
Run the following command in your terminal or Jupyter Notebook:
```bash
pip install -U langgraph langchain-openai
```

### 🔑 **Set Up API Keys**
We need an **OpenAI API key** to use GPT models.

```python
import os
import getpass

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("OPENAI_API_KEY")
```
This will prompt you to enter your OpenAI API key securely.

---

## 🏗 **Step 2: Defining the ReAct Agent**
The ReAct agent follows a structured approach:
1️⃣ **Receives a user query**  
2️⃣ **Decides whether to call an external tool or answer directly**  
3️⃣ **Uses the tool (if needed) and generates a response**  

---

## 📌 **Step 3: Defining the Agent's State**
An **agent state** holds the messages exchanged during the conversation.

```python
from typing import Annotated, Sequence, TypedDict
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages

class AgentState(TypedDict):
    """The state of the agent."""
    messages: Annotated[Sequence[BaseMessage], add_messages]
```

✅ The `AgentState` class stores the conversation history.  
✅ `add_messages` is a **reducer function** that appends new messages to the state.

---

## 🔧 **Step 4: Defining the Model and Tools**
We'll use **GPT-4o-mini** as our model and create a tool to fetch weather information.

### ✨ **Define the AI Model**
```python
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4o-mini")
```

### 🌦 **Create a Weather Tool**
```python
from langchain_core.tools import tool

@tool
def get_weather(location: str):
    """Call to get the weather from a specific location."""
    if any([city in location.lower() for city in ["sf", "san francisco"]]):
        return "It's sunny in San Francisco, but you better look out if you're a Gemini 😈."
    else:
        return f"I am not sure what the weather is in {location}"

tools = [get_weather]
model = model.bind_tools(tools)
```
✅ The `@tool` decorator defines a function as an external **tool**.  
✅ The agent **checks if the location is San Francisco** and responds accordingly.  
✅ `bind_tools()` connects the model with the defined tools.

---

## 🔗 **Step 5: Defining Nodes and Edges**
Now, we'll define:
- **Nodes**: Components in the agent's workflow.
- **Edges**: The logic that decides the next step.

### 🛠 **Tool Node (Calling External APIs)**
```python
import json
from langchain_core.messages import ToolMessage

tools_by_name = {tool.name: tool for tool in tools}

def tool_node(state: AgentState):
    outputs = []
    for tool_call in state["messages"][-1].tool_calls:
        tool_result = tools_by_name[tool_call["name"]].invoke(tool_call["args"])
        outputs.append(ToolMessage(
            content=json.dumps(tool_result),
            name=tool_call["name"],
            tool_call_id=tool_call["id"],
        ))
    return {"messages": outputs}
```
✅ This function **executes the tool** (e.g., `get_weather()`) and stores the result.  
✅ It returns a `ToolMessage` containing the tool’s response.  

### 🤖 **AI Model Node (Generating Responses)**
```python
from langchain_core.messages import SystemMessage
from langchain_core.runnables import RunnableConfig

def call_model(state: AgentState, config: RunnableConfig):
    system_prompt = SystemMessage("You are a helpful AI assistant.")
    response = model.invoke([system_prompt] + state["messages"], config)
    return {"messages": [response]}
```
✅ The `call_model` function generates AI responses **using GPT-4o-mini**.  
✅ It **includes a system prompt** to guide the assistant's behavior.

### 🔄 **Conditional Logic (When to Stop or Continue)**
```python
def should_continue(state: AgentState):
    messages = state["messages"]
    last_message = messages[-1]
    return "continue" if last_message.tool_calls else "end"
```
✅ If the last AI message **contains a tool call**, the agent **continues**.  
✅ Otherwise, it **ends the conversation**.

---

## 🏗 **Step 6: Building the Graph**
LangGraph helps **structure** the workflow.

```python
from langgraph.graph import StateGraph, END

workflow = StateGraph(AgentState)

workflow.add_node("agent", call_model)
workflow.add_node("tools", tool_node)

workflow.set_entry_point("agent")

workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        "continue": "tools",
        "end": END,
    },
)

workflow.add_edge("tools", "agent")

graph = workflow.compile()
```
✅ **StateGraph** defines the workflow.  
✅ `add_node()` creates two nodes: `agent` (AI) and `tools` (external APIs).  
✅ `set_entry_point("agent")` starts with AI processing.  
✅ The conditional edge (`should_continue()`) **decides whether to call a tool or stop**.  

---

## 🎯 **Step 7: Using the ReAct Agent**
Now, let's **test the agent**.

```python
def print_stream(stream):
    for s in stream:
        message = s["messages"][-1]
        print(message.pretty_print())

inputs = {"messages": [("user", "what is the weather in sf")]}
print_stream(graph.stream(inputs, stream_mode="values"))
```
### ✅ **Expected Output**
```
================================= Human Message =================================
what is the weather in sf
================================= AI Message =================================
Tool Calls:
  get_weather (call_ID)
================================= Tool Message =================================
Name: get_weather
"It's sunny in San Francisco, but you better look out if you're a Gemini 😈."
================================= AI Message =================================
The weather in San Francisco is sunny! However, it seems there's a playful warning for Geminis. Enjoy the sunshine!
```
🔥 The agent **called the weather tool, processed the response, and answered correctly!** 🎉

---

## 🌍 **Real-World Applications of ReAct Agents**
Here are some **real-world use cases** for ReAct agents:

💬 **Chatbots with external API calls** (e.g., weather bots, stock price fetchers)  
🛒 **E-commerce assistants** (e.g., fetching product prices, checking stock availability)  
📅 **Smart scheduling assistants** (e.g., booking meetings, managing calendars)  
💡 **Customer support agents** (e.g., fetching order status, troubleshooting issues)  

---

## 🎯 **Key Takeaways**
✅ **ReAct agents** combine reasoning & tool usage for intelligent decision-making.  
✅ **Custom ReAct agents** offer more flexibility than prebuilt ones.  
✅ **LangGraph** helps structure agents using **nodes and edges**.  
✅ **Agents can call external tools** (like weather APIs) dynamically.  

By following this guide, you now have a **fully functional ReAct agent** that can call tools and process responses dynamically! 🚀