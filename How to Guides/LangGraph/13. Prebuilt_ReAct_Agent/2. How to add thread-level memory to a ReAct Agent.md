# 2. How to add thread-level memory to a ReAct Agent

# How to Add Thread-Level Memory to a ReAct Agent üß†

In this tutorial, we'll learn how to add memory to a **ReAct agent** using LangGraph. This will allow the agent to retain information across multiple interactions, making it more intelligent and capable of remembering prior conversations. Let's go step-by-step and break down how this can be achieved, along with real-world examples of when it might be useful.

## üõ†Ô∏è Overview of ReAct Agents

ReAct agents are intelligent systems that interact with the environment using tools and models. They can execute tasks like checking the weather, answering questions, or performing calculations. The key benefit of using **memory** is that the agent can recall past information to improve its responses.

### Why Add Memory to an Agent? ü§î

Imagine you're using a virtual assistant like Siri or Google Assistant. You ask it, "What's the weather in New York?" and then later ask, "What should I pack for my trip?" It makes sense for the assistant to remember that you're talking about your trip to New York. Without memory, every conversation would be a brand-new interaction, and the assistant wouldn't be able to recall useful information. This is where **thread-level memory** comes in.

---

## üöÄ Step-by-Step Guide to Add Memory

### 1. **Install Required Packages**

Before we dive into the code, you need to install the required libraries. These include **LangGraph** and **LangChain**.

```bash
%%capture --no-stderr
%pip install -U langgraph langchain-openai
```

- `langgraph`: A framework for building intelligent agents that can interact with users and tools.
- `langchain-openai`: A library that connects OpenAI's models with LangGraph.

### 2. **Set Up API Keys**

LangGraph uses OpenAI models, so you'll need to provide your OpenAI API key for authentication.

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("OPENAI_API_KEY")
```

Here, we use the `getpass` module to securely input the API key and store it as an environment variable.

---

### 3. **Initialize the Model**

The next step is to initialize the language model (LLM) that the agent will use. In this case, we're using the **GPT-4** model.

```python
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o", temperature=0)
```

- **ChatOpenAI**: This is the class used to interact with OpenAI's GPT models.
- **temperature**: This controls how creative or random the model's responses will be. A lower value (like 0) makes the output more deterministic.

---

### 4. **Define Tools (e.g., Weather Tool)**

We'll define a tool that returns pre-defined weather information for two cities, **New York** (NYC) and **San Francisco** (SF).

```python
from typing import Literal
from langchain_core.tools import tool

@tool
def get_weather(city: Literal["nyc", "sf"]):
    """Use this to get weather information."""
    if city == "nyc":
        return "It might be cloudy in NYC"
    elif city == "sf":
        return "It's always sunny in SF"
    else:
        raise AssertionError("Unknown city")

tools = [get_weather]
```

- **@tool**: This decorator tells LangGraph that this function is a tool that the agent can use.
- **get_weather**: This function takes a city name and returns a weather update for that city.

---

### 5. **Add Memory to the Agent**

Now, we introduce memory to the agent so that it can remember the conversation context. We'll use the **MemorySaver** class from LangGraph to add memory.

```python
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
```

- **MemorySaver**: This class is responsible for saving and retrieving the memory of the agent.

---

### 6. **Create the ReAct Agent with Memory**

Now we can create the **ReAct agent** using the `create_react_agent` function. We'll pass the `model`, `tools`, and `memory` objects to this function.

```python
from langgraph.prebuilt import create_react_agent

graph = create_react_agent(model, tools=tools, checkpointer=memory)
```

- **create_react_agent**: This function initializes the ReAct agent with the provided model, tools, and memory.
- **checkpointer**: This argument is responsible for managing the agent's memory.

---

### 7. **Test the Agent's Memory**

Let's interact with the agent multiple times to show that it can remember previous interactions.

#### First interaction (Weather in NYC):

```python
config = {"configurable": {"thread_id": "1"}}
inputs = {"messages": [("user", "What's the weather in NYC?")]}
print_stream(graph.stream(inputs, config=config, stream_mode="values"))
```

In this interaction, we ask the agent about the weather in **New York City (NYC)**. The agent will call the `get_weather` tool and provide the answer.

#### Second interaction (NYC Facts):

Now, we'll ask the agent about what New York City is known for. Since the agent has memory, it will remember the previous context.

```python
inputs = {"messages": [("user", "What's it known for?")]}
print_stream(graph.stream(inputs, config=config, stream_mode="values"))
```

In this case, the agent remembers that we're asking about New York City and provides a list of things NYC is known for.

---

### 8. **What Happens Behind the Scenes?**

When the agent interacts with the user, it processes the conversation as follows:

1. **Memory Check**: The agent checks if there's any existing memory for the current conversation (thread ID "1").
2. **Tool Call**: If necessary, it calls the relevant tools (like `get_weather` for weather-related queries).
3. **Response Generation**: The agent generates a response based on the conversation history and tools it uses.
4. **Memory Update**: After each interaction, the agent updates its memory to retain context for future conversations.

---

## Real-World Example of Thread-Level Memory üåç

### Example: Virtual Shopping Assistant

Imagine you‚Äôre interacting with a **virtual shopping assistant** that helps you find products based on your preferences. As you ask about different products, the assistant can remember your preferences (e.g., "I like winter jackets" or "I prefer blue over red"). The assistant's memory can help it suggest products that match your style more accurately in future interactions.

For example:
- **User**: "What jackets do you have?"
- **Assistant**: "We have a variety of jackets. Are you looking for something warm for winter?"
- **User**: "Yes, I need a winter jacket."
- **Assistant**: "Great! Here are some options for warm winter jackets."

In the next session:
- **User**: "I need a jacket for hiking."
- **Assistant**: "Since you like winter jackets, I‚Äôll suggest some insulated jackets for hiking."

By retaining previous context (winter jackets), the assistant makes smarter, more personalized recommendations.

---

## Conclusion üéâ

Adding **thread-level memory** to a ReAct agent helps make the agent more intelligent and able to remember past conversations. This improves the user experience by making interactions feel more personal and context-aware. Whether you're building a **virtual assistant**, a **customer support bot**, or a **shopping assistant**, adding memory can take your ReAct agent to the next level.