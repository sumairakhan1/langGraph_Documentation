# 1. How to use the pre-built ReAct agent


# üöÄ How to Use the Pre-Built ReAct Agent

In this tutorial, we'll explore how to create a simple ReAct agent that can check the weather. The ReAct agent involves a language model (LLM) and tools that the agent uses to interact with the world. We'll go through the process step-by-step, explain each line of code in detail, and look at a real-world use case for better understanding.

### üåü What is a ReAct Agent?

ReAct agents use an approach where the agent (powered by a language model like GPT) decides whether to perform actions (like calling tools) based on the input. If the agent determines that a specific tool is required, it will execute the tool and return the result. This is done in a loop, where the agent keeps interacting with the tools until no further actions are needed.

### üõ†Ô∏è Step 1: Setting Up the Environment

Before we start building the app, we need to set up our environment by installing the required libraries and setting API keys for OpenAI.

```python
%%capture --no-stderr
%pip install -U langgraph langchain-openai
```

This command installs the necessary packages:
- `langgraph`: The framework for building agent-driven applications.
- `langchain-openai`: An interface for OpenAI models, allowing us to use GPT-4.

We also need to securely set our API key for OpenAI using the `getpass` library, which prompts us to enter the API key without displaying it on the screen:

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("OPENAI_API_KEY")
```

### üåç Step 2: Initialize the Language Model

Now, we will initialize the language model (LLM) that the ReAct agent will use. We'll use GPT-4 for this example:

```python
from langchain_openai import ChatOpenAI

# Initialize the model with the GPT-4 configuration
model = ChatOpenAI(model="gpt-4o", temperature=0)
```

- `model="gpt-4o"` specifies that we want to use the GPT-4 model.
- `temperature=0` ensures deterministic (non-random) responses from the model.

### ‚òÄÔ∏è Step 3: Creating a Custom Tool

In this example, we want our agent to check the weather for two cities: New York (NYC) and San Francisco (SF). We‚Äôll create a custom tool that returns predefined weather information for these cities.

```python
from typing import Literal
from langchain_core.tools import tool

# Define a custom tool for weather information
@tool
def get_weather(city: Literal["nyc", "sf"]):
    """Use this to get weather information."""
    if city == "nyc":
        return "It might be cloudy in NYC"
    elif city == "sf":
        return "It's always sunny in SF"
    else:
        raise AssertionError("Unknown city")
```

Here:
- `@tool`: This decorator marks `get_weather` as a tool that the agent can call.
- `Literal["nyc", "sf"]`: Restricts the input to only "nyc" or "sf".
- If the city is neither "nyc" nor "sf", an error is raised.

### ‚öôÔ∏è Step 4: Define the Graph

Now, we will create the ReAct agent using the model and tools we‚Äôve set up.

```python
from langgraph.prebuilt import create_react_agent

# Create the ReAct agent with the weather tool
graph = create_react_agent(model, tools=[get_weather])
```

This line creates an agent called `graph`, which uses the model and weather tool. The agent can now decide when to call the `get_weather` tool based on the user's input.

### üîÑ Step 5: Visualizing the Graph

We can visualize the flow of the ReAct agent using the Mermaid diagram. This diagram helps us understand how the agent works behind the scenes.

```python
from IPython.display import Image, display

# Display the Mermaid diagram for the agent
display(Image(graph.get_graph().draw_mermaid_png()))
```

### üí¨ Step 6: Running the App

Now, we‚Äôre ready to run the app and see how it works in action. We'll start by testing the app with a query asking about the weather in San Francisco.

```python
inputs = {"messages": [("user", "what is the weather in sf")]}
print_stream(graph.stream(inputs, stream_mode="values"))
```

Here:
- `inputs` is the input message from the user: "what is the weather in sf".
- `graph.stream(inputs, stream_mode="values")` sends the input to the agent, which processes it and decides whether to call a tool (in this case, the `get_weather` tool for "sf").

#### Example Output:

```
================================ Human Message =================================
what is the weather in sf
```

The agent would then call the `get_weather` tool, get the response "It's always sunny in SF", and return it to the user.

### üß† Step 7: Testing Without Tool Call

Now, let‚Äôs test a question that doesn‚Äôt need any tools, such as asking "who built you?".

```python
inputs = {"messages": [("user", "who built you?")]}
print_stream(graph.stream(inputs, stream_mode="values"))
```

Since this question doesn't require a tool (the agent will simply respond based on its model), the agent will return an answer directly without calling any tools.

#### Example Output:

```
================================ Human Message =================================
who built you?
```

### üèÜ Real-World Use Case

A practical example of this setup could be a virtual assistant that checks the weather for a user. Suppose you are building a customer support chatbot that helps users with various tasks. The chatbot can integrate with multiple tools to perform tasks like checking the weather, setting reminders, or looking up flight information. Using a ReAct agent, the chatbot can intelligently decide when to call these tools and provide accurate answers.

For example:
- **User:** "What's the weather like in NYC?"
- **Chatbot (ReAct agent):** "It might be cloudy in NYC."

### üéâ Conclusion

In this tutorial, we learned how to create a simple ReAct agent that interacts with tools based on user input. We used a prebuilt agent architecture to quickly get started, but LangGraph also allows us to build more customized agents as we gain more experience.

By understanding how the agent interacts with tools and makes decisions based on inputs, we can extend this to create more complex, real-world applications like virtual assistants, automated help desks, or intelligent bots for various purposes.