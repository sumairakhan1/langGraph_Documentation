# 1. How to add a breakpoint

# Human-in-the-loop (HITL) Concept Explained üß†

Human-in-the-loop (HITL) is a concept where human intervention is integrated into automated processes, particularly when machines or AI systems make decisions or execute actions. The purpose is to ensure oversight, control, and validation before proceeding with an automated task.

In this specific context, HITL involves adding **breakpoints** in a LangGraph agent's workflow, allowing humans to review and approve actions before they are carried out. Let's break it down step by step.

---

## What Are Breakpoints? ‚è∏Ô∏è

### **Purpose** of Breakpoints:
Breakpoints are points in the workflow where execution is paused, giving humans the opportunity to approve or intervene in the process before it continues. This is crucial when you're dealing with automation, but need to ensure that decisions made by the system are appropriate or correct before final action is taken.

For example:
- A robot in a factory performing assembly might stop and ask a supervisor whether the part is aligned correctly before proceeding.
- An AI system might suggest a marketing strategy, but before launching it, a human must review and approve the plan.

### **Where Breakpoints Are Used in LangGraph?**
LangGraph allows you to set up automated workflows with AI agents. When a process in LangGraph reaches a particular node (task), you can add a breakpoint to stop the execution before moving forward, giving the human user control.

---

## Example Workflow of LangGraph with Breakpoints ‚öôÔ∏è

Let‚Äôs break down the setup in LangGraph, step by step, and understand how **breakpoints** work in practice.

### 1. **Setting Up Your LangGraph Agent** üñ•Ô∏è

LangGraph uses nodes to represent different tasks or steps in a workflow. In this case, we‚Äôre dealing with two nodes:
- **Agent Node**: This node is responsible for running a task using an LLM (Large Language Model), like fetching data.
- **Action Node**: This node is where the agent calls a tool (like weather API).

### **SDK Initialization**
First, we initialize the client using the LangGraph SDK, which helps us interact with the hosted agent. Here‚Äôs how it works:

```python
from langgraph_sdk import get_client
client = get_client(url=<DEPLOYMENT_URL>)
assistant_id = "agent"  # Your LangGraph agent ID
thread = await client.threads.create()  # Creating a new thread for the interaction
```

- **`get_client`**: Initializes the connection to LangGraph's backend.
- **`client.threads.create()`**: Starts a new session for the agent to work in.

### 2. **Adding Breakpoints** üöß

Now, to ensure that we pause before the **action node**, we add a breakpoint. We use the `interrupt_before=["action"]` parameter to achieve this.

```python
input = {"messages": [{"role": "user", "content": "what's the weather in SF"}]}
async for chunk in client.runs.stream(
    thread["thread_id"],
    assistant_id,
    input=input,
    stream_mode="updates",
    interrupt_before=["action"],  # Pause before calling the action node
):
    print(f"Receiving new event of type: {chunk.event}...")
    print(chunk.data)
    print("\n\n")
```

- **`interrupt_before=["action"]`**: Tells the system to pause before it moves on to the "action" node. This is the breakpoint.
- **`stream_mode="updates"`**: Streams updates in real-time so you can monitor the progress of the task.

### 3. **Output of the Process** üìä

After implementing the breakpoint, the system pauses, and you get outputs showing the state of the process at different stages. For example:

```plaintext
Receiving new event of type: metadata...
{'run_id': '3b77ef83-687a-4840-8858-0371f91a92c3'}

Receiving new event of type: data...
{'agent': {'messages': [{'content': [{'id': 'toolu_01HwZqM1ptX6E15A5LAmyZTB', 'input': {'query': 'weather in San Francisco'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]}}}

Receiving new event of type: end...
None
```

These outputs show the metadata, data, and final state of the task once it‚Äôs finished. You can review these at the breakpoint before the system proceeds with the action.

---

## Real-World Use Cases of Human-in-the-loop (HITL) üîç

### Example 1: **AI Customer Support System** üìû

In an AI-powered customer support system, the bot automatically answers user queries. However, sensitive issues like billing, account suspension, or refund requests may require human oversight. The system uses HITL to pause after generating a response and asks the human agent for approval before proceeding.

**How HITL helps:**
- **Ensures Accuracy**: The human agent can verify if the response or action is appropriate.
- **Prevents Mistakes**: In case of complex issues, human intervention can prevent the AI from making wrong decisions.

### Example 2: **Medical Diagnosis System** üè•

AI can analyze medical data and suggest diagnoses, but these are often sensitive and require human approval. For example, an AI may detect signs of cancer, but a doctor needs to review the result and confirm the diagnosis before proceeding with treatment plans.

**How HITL helps:**
- **Human Expertise**: The doctor reviews and confirms AI's suggestions.
- **Safety**: Ensures that no incorrect medical decisions are made without human review.

### Example 3: **Autonomous Vehicles** üöó

In autonomous vehicles, the AI system makes decisions based on sensor data and surroundings. However, certain situations (like uncertain weather or complex road scenarios) may require a human to intervene and take control.

**How HITL helps:**
- **Safety**: In unpredictable situations, the driver can take control, ensuring safety.
- **Decision-Making**: In some situations, the vehicle's AI may not be 100% sure, so human oversight ensures the right actions are taken.

---

## Alternatives to Human-in-the-loop (HITL) üõ†Ô∏è

While HITL provides human intervention, there are alternative approaches to integrating automation:

### 1. **Fully Automated Systems** ü§ñ
- These systems do not require human approval. They are designed to operate independently once deployed, relying on robust AI algorithms and pre-configured logic.
- **Example**: A fully automated stock trading algorithm that makes decisions based solely on market trends without human oversight.

### 2. **Human-on-the-loop (HOTL)** üßë‚Äçüíª
- Unlike HITL, where humans intervene actively, HOTL allows a human to monitor an automated process and intervene only when something goes wrong. Humans do not approve every decision but are ready to intervene if necessary.
- **Example**: A traffic management system that automatically adjusts traffic signals but allows a human operator to take over in case of emergencies.

### 3. **Rule-Based Systems** üìö
- These systems follow pre-defined rules and make decisions without AI or human input. They are often used in structured environments where the conditions and actions are known in advance.
- **Example**: A simple vending machine that dispenses snacks based on user input.

---

## Conclusion üåü

Human-in-the-loop (HITL) is a powerful concept that bridges the gap between automation and human oversight. By implementing breakpoints in LangGraph, you allow humans to intervene and approve actions before they are carried out, ensuring that critical decisions are always validated.

- **Purpose of Breakpoints**: Ensure the system pauses to ask for human approval before taking critical actions.
- **Real-World Uses**: Customer support, medical diagnostics, autonomous vehicles, and more.

By using HITL, we can ensure that automated systems work safely and accurately, while allowing for human intervention when necessary.

---

# Human-in-the-Loop (HITL) with Breakpoints

Human-in-the-loop (HITL) is a concept used to involve a human operator in an automated process. This ensures that a human can oversee, validate, or intervene before certain actions are taken by the system. HITL is particularly useful in situations where automated systems need human approval or oversight to ensure correct, safe, and ethical outcomes. This approach helps combine the power of automation with the decision-making ability of humans.

In this tutorial, we'll explore how **Human-in-the-loop** works with LangGraph agents, focusing on **adding breakpoints** where human intervention is required before executing specific actions.

## Purpose of HITL and Breakpoints

### What is the Purpose of HITL?

HITL is used to add human judgment to a system, especially when automated processes may make decisions that require further review. By introducing breakpoints, we can pause an automated process at critical points, allowing human operators to approve or reject actions before the system continues.

### Why Add Breakpoints in LangGraph?

When working with **LangGraph agents**, breakpoints act as stopping points in a workflow, giving the human the ability to approve or inspect actions before they are executed. In automated systems, especially those involving AI, this ensures that the outcomes are safe, accurate, and aligned with human values.

---

## How to Add Breakpoints to LangGraph Agents

To use breakpoints with LangGraph, we first need to **set up the graph**, and then implement the breakpoint before an action node is executed. Let's break it down:

### Setup for LangGraph

1. **Create the Graph**:
   - In LangGraph, you define a workflow or graph with multiple nodes. For example, one node could call an AI agent (LLM - Large Language Model), and another node could trigger a specific action (like calling an external tool).
   
2. **Define Routing**:
   - The routing function determines whether to call the next action or end the graph's run. The action node will always call the agent node after execution.

### Adding Breakpoints: `interrupt_before`

To introduce human oversight, we add **interrupt points** (breakpoints) before calling the action node.

#### Example:

- **Step 1**: Set up a LangGraph SDK client and create a thread for the workflow.
- **Step 2**: Add `interrupt_before=["action"]` when starting the graph run to halt the execution right before the action node.

---

## Code Walkthrough: Adding Breakpoints

Let's go through the example code to see how this works.

### SDK Initialization:

```python
from langgraph_sdk import get_client
client = get_client(url=<DEPLOYMENT_URL>)

# Initialize the LangGraph agent (the workflow)
assistant_id = "agent"
thread = await client.threads.create()
```

#### Explanation:
- **`get_client(url=<DEPLOYMENT_URL>)`**: Initializes the LangGraph client using a specific deployment URL.
- **`assistant_id = "agent"`**: Specifies the name of the agent you will use in the workflow.
- **`client.threads.create()`**: Creates a new thread for the graph to run.

### Setting the Breakpoint:

```python
input = {"messages": [{"role": "user", "content": "what's the weather in sf"}]}
async for chunk in client.runs.stream(
    thread["thread_id"],
    assistant_id,
    input=input,
    stream_mode="updates",
    interrupt_before=["action"],
):
    print(f"Receiving new event of type: {chunk.event}...")
    print(chunk.data)
    print("\n\n")
```

#### Explanation:
- **`interrupt_before=["action"]`**: This is the key part where the execution is interrupted before the action node (the part where a tool is called). The process will stop here, allowing the human to intervene and approve the action.
- **`client.runs.stream()`**: Starts streaming updates for the graph, receiving chunks of data.
  - The **`input`** represents a message from the user (like asking about the weather).
  - Each **chunk** represents a piece of data that can trigger events.
  
### Sample Output:

```
Receiving new event of type: metadata...
{'run_id': '3b77ef83-687a-4840-8858-0371f91a92c3'}

Receiving new event of type: data...
{'agent': {'messages': [{'content': [{'id': 'toolu_01HwZqM1ptX6E15A5LAmyZTB', 'input': {'query': 'weather in san francisco'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e5d17791-4d37-4ad2-815f-a0c4cba62585', 'example': False, 'tool_calls': [{'name': 'tavily_search_results_json', 'args': {'query': 'weather in san francisco'}, 'id': 'toolu_01HwZqM1ptX6E15A5LAmyZTB'}], 'invalid_tool_calls': []}]}}
```

#### Explanation:
- **Metadata**: The system identifies the process with a unique `run_id`.
- **Data**: The agent prepares a response, such as querying a weather tool for San Francisco's weather.
- **End**: The process ends once all nodes have been processed.

---

## Real-World Example: Human-in-the-Loop in Autonomous Vehicles

### Use Case in Autonomous Vehicles:
In self-driving cars, the car's AI system makes decisions like steering, braking, and accelerating based on sensor data. However, critical decisions (e.g., emergency braking in certain scenarios) might require a human driver to intervene.

- **Human Oversight**: If the car's system detects an obstacle or a dangerous situation, it may pause its decision-making (using a breakpoint) to ask the driver: "Do you approve braking immediately?"
- **Approval Process**: The human driver can approve or override the decision, ensuring safety.

This is an example of **HITL** in a real-world situation where human judgment is essential.

---

## Alternative Examples of HITL in Action

### Example 1: Fraud Detection in Banking

- **Problem**: A fraud detection system flags a transaction as suspicious.
- **HITL Solution**: Before freezing the account or rejecting the transaction, a bank officer reviews the transaction.
- **Purpose**: Ensures that legitimate transactions are not mistakenly flagged as fraud.

### Example 2: Content Moderation in Social Media

- **Problem**: An automated content moderation system detects inappropriate posts.
- **HITL Solution**: A human moderator reviews the flagged posts to determine if they violate community guidelines.
- **Purpose**: Avoids false positives and ensures fairness in moderation.

### Example 3: AI Customer Support

- **Problem**: An AI chatbot is handling customer queries but encounters a request that needs manual approval (e.g., refund request).
- **HITL Solution**: The system pauses and asks a human agent for approval before processing the refund.
- **Purpose**: Ensures that high-stakes actions, like refunds, are verified by a human to prevent errors.

---

## Key Takeaways

- **Human-in-the-loop** ensures human oversight in automated processes, particularly for decisions requiring human judgment.
- **Breakpoints** allow the process to pause at critical points, giving humans the opportunity to approve or reject actions before they proceed.
- **LangGraph** allows adding breakpoints in workflows, enabling human validation before critical actions like using a tool.
- HITL is widely used in safety-critical applications like autonomous vehicles, fraud detection, and content moderation.

---

By understanding and implementing **Human-in-the-loop** with **breakpoints**, we can combine automation with human expertise, ensuring that automated systems make better decisions, especially when the stakes are high.