# 4. How to add node retry policies

# 🛠 How to Add Node Retry Policies in LangGraph  

When working with LangGraph, you may need to implement **retry policies** to handle failures gracefully. This is especially useful when calling APIs, querying databases, or interacting with Large Language Models (LLMs).  

This guide will explain retry policies in **a beginner-friendly manner** with **real-world use cases**, **step-by-step code explanations**, and **practical examples**.  

---

## 🧐 What is a Retry Policy?  

A **retry policy** defines rules for **re-attempting failed operations** in case of temporary failures.  

For example, if your API call fails due to a **network timeout**, a retry policy can **retry the request automatically** instead of failing immediately.  

### 🔍 **Real-World Use Case**  
Imagine you have an **e-commerce website** where users search for products. If the **database query fails** due to temporary unavailability, a retry policy can **retry the query** instead of showing an error message to the user.

---

## 🚀 Setting Up the Environment  

Before implementing retry policies, we need to install the required libraries and set up API keys.  

### 📌 **Step 1: Install Required Packages**  

```python
%%capture --no-stderr
%pip install -U langgraph langchain_anthropic langchain_community
```
📌 **Explanation:**  
- `langgraph` – For defining state graphs.  
- `langchain_anthropic` – For integrating with **Claude** models.  
- `langchain_community` – For accessing various **LangChain utilities**.  

---

### 📌 **Step 2: Set API Keys**  

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):  # Only set if not already set
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("ANTHROPIC_API_KEY")
```
📌 **Explanation:**  
- `_set_env()` function **prompts for an API key** if it's not already set.  
- This ensures secure storage of **Anthropic API keys**.  

---

## 🔄 Defining a Retry Policy  

LangGraph provides a `RetryPolicy` class, which defines **how failures should be handled**.  

### 📌 **Creating a Retry Policy**  

```python
from langgraph.pregel import RetryPolicy

# Default retry policy
retry_policy = RetryPolicy()

print(retry_policy)
```

📌 **Explanation:**  
- `RetryPolicy()` creates a default retry policy.  
- By default, it **retries on all exceptions except**:  
  - `ValueError`, `TypeError`, `ArithmeticError`, etc.  
- HTTP request failures (`requests`, `httpx`) **only retry on 5xx errors**.  

---

### 🔧 **Customizing Retry Parameters**  

We can customize the **retry behavior** by adjusting the parameters.  

```python
retry_policy = RetryPolicy(
    initial_interval=0.5,  # Wait 0.5 seconds before first retry
    backoff_factor=2.0,  # Double the wait time on each retry
    max_interval=128.0,  # Max wait time is 128 seconds
    max_attempts=3,  # Try up to 3 times
    jitter=True,  # Add randomness to avoid retry collisions
)

print(retry_policy)
```

📌 **Explanation:**  
- `initial_interval=0.5` → Starts with **0.5 sec** delay before retrying.  
- `backoff_factor=2.0` → **Doubles** the delay after each failed attempt.  
- `max_attempts=3` → **Retries up to 3 times** before giving up.  
- `jitter=True` → **Adds randomness** to prevent multiple retries at the same time.  

---

## 🔗 Adding a Retry Policy to Nodes  

### 📌 **Step 1: Define a Graph**  

We define a **LangGraph state machine** to query a database and call an LLM.  

```python
import operator
import sqlite3
from typing import Annotated, Sequence
from typing_extensions import TypedDict

from langchain_anthropic import ChatAnthropic
from langchain_core.messages import BaseMessage
from langgraph.graph import END, StateGraph, START
from langchain_community.utilities import SQLDatabase
from langchain_core.messages import AIMessage
```
📌 **Explanation:**  
- `StateGraph` → Creates a **state-based workflow**.  
- `SQLDatabase` → Allows querying an **SQLite database**.  
- `ChatAnthropic` → Uses **Claude** for AI responses.  

---

### 📌 **Step 2: Initialize Database and LLM**  

```python
db = SQLDatabase.from_uri("sqlite:///:memory:")  # In-memory database
model = ChatAnthropic(model_name="claude-2.1")  # AI Model
```

📌 **Explanation:**  
- Creates an **in-memory SQLite database** (temporary database).  
- Initializes the **Claude LLM model**.  

---

### 📌 **Step 3: Define Query Functions**  

#### 1️⃣ **Querying the Database**  

```python
def query_database(state):
    query_result = db.run("SELECT * FROM Artist LIMIT 10;")
    return {"messages": [AIMessage(content=query_result)]}
```
📌 **Explanation:**  
- Runs an **SQL query** to fetch **10 artists** from the database.  
- Returns the result **as an AI message**.  

---

#### 2️⃣ **Calling the LLM Model**  

```python
def call_model(state):
    response = model.invoke(state["messages"])
    return {"messages": [response]}
```
📌 **Explanation:**  
- Passes previous messages to the **Claude LLM**.  
- Returns **the AI-generated response**.  

---

### 📌 **Step 4: Create a Graph with Retry Policies**  

```python
# Define a new graph
builder = StateGraph(AgentState)

# Node 1: Query Database with Retry on SQLite Errors
builder.add_node(
    "query_database",
    query_database,
    retry=RetryPolicy(retry_on=sqlite3.OperationalError),
)

# Node 2: Call AI Model with Max 5 Retries
builder.add_node(
    "model",
    call_model,
    retry=RetryPolicy(max_attempts=5),
)

# Define edges (workflow sequence)
builder.add_edge(START, "model")
builder.add_edge("model", "query_database")
builder.add_edge("query_database", END)

# Compile the graph
graph = builder.compile()
```

📌 **Explanation:**  
- `add_node("query_database", query_database, retry=RetryPolicy(...))`  
  - Retries **only** on `sqlite3.OperationalError`.  
- `add_node("model", call_model, retry=RetryPolicy(max_attempts=5))`  
  - Retries **up to 5 times** for the AI model.  
- `add_edge(START, "model")` → Start with the LLM model.  
- `add_edge("model", "query_database")` → Query database **after** the model.  
- `compile()` → **Finalizes the graph** before execution.  

---

## 🎯 Key Takeaways  

✅ **Retry policies prevent failures from breaking applications**  
✅ **Customizable settings allow fine-grained control over retries**  
✅ **LangGraph simplifies integrating retry policies into workflows**  
✅ **Useful for APIs, databases, and LLM interactions**  

---

## 🔥 **Next Steps**  

Want to go deeper? Try:  
🔹 Adding **logging** to track retry attempts  
🔹 Experimenting with **different backoff strategies**  
🔹 Implementing **circuit breakers** for excessive failures  

Happy coding! 🚀


---
# O3 mini Response:
---

# 🚀 Adding Node Retry Policies

In many applications, you may call APIs, query databases, or interact with language models where failures might occur temporarily. To handle these transient issues gracefully, **retry policies** are used. Retry policies automatically re-run a failing node a specified number of times with delays between attempts until it succeeds or the attempts are exhausted.

This guide will explain:
- What retry policies are and why they are useful
- How to configure and use them in a LangGraph node
- A detailed, beginner-friendly, line-by-line code explanation
- Real-world scenarios where retry policies can be beneficial

---

## 🛠️ Setup: Installing Packages & Setting API Keys

Before we can add retry policies, we need to install the required packages and set up our API keys. This ensures that our graph can communicate with the necessary services.

```python
%%capture --no-stderr
%pip install -U langgraph langchain_anthropic langchain_community
```

**Explanation:**
- **`%%capture --no-stderr`**: Hides the installation output for a cleaner notebook.
- **`%pip install -U ...`**: Installs (or updates) `langgraph`, `langchain_anthropic`, and `langchain_community` which are required for building the graph, interacting with the Anthropic model, and working with additional utilities.

Next, we set up our API key:

```python
import getpass
import os

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("ANTHROPIC_API_KEY")
```

**Explanation:**
- **Import Libraries**:  
  - `getpass` is used to securely get input from the user.
  - `os` is used to access environment variables.
- **Function `_set_env`**:  
  - Checks if an environment variable is already set.
  - If not, it prompts the user to enter the key securely.
- **Setting the Key**:  
  - `_set_env("ANTHROPIC_API_KEY")` ensures your API key for Anthropic is available in the environment.

---

## 📚 What Are Retry Policies?

Retry policies help manage transient errors by automatically retrying a node's operation if it fails. In LangGraph, you configure retry policies by passing a `RetryPolicy` object to the `add_node` function. This object allows you to specify:

- **Initial interval**: The wait time before the first retry.
- **Backoff factor**: How the wait time increases after each retry.
- **Max interval**: The maximum wait time between retries.
- **Max attempts**: The maximum number of retries.
- **Jitter**: Adds randomness to avoid simultaneous retries.
- **Retry on**: Specifies the exceptions that should trigger a retry.

By default, the retry policy will not retry on common errors like `ValueError`, `TypeError`, etc., but will retry on most transient errors (for example, HTTP 5xx errors).

---

## 📝 Code Example: Adding Retry Policies

Below is an example graph with two nodes: one that queries a database and one that calls a language model. Each node is configured with its own retry policy.

```python
import operator
import sqlite3
from typing import Annotated, Sequence
from typing_extensions import TypedDict

from langchain_anthropic import ChatAnthropic
from langchain_core.messages import BaseMessage
from langgraph.graph import END, StateGraph, START
from langchain_community.utilities import SQLDatabase
from langchain_core.messages import AIMessage
from langgraph.pregel import RetryPolicy

# Create an in-memory SQL database.
db = SQLDatabase.from_uri("sqlite:///:memory:")

# Initialize the Anthropic model with a specific model name.
model = ChatAnthropic(model_name="claude-2.1")

# Define the state of our graph using a TypedDict.
class AgentState(TypedDict):
    # The messages field will accumulate our message sequence.
    messages: Annotated[Sequence[BaseMessage], operator.add]

# Node function that queries the database.
def query_database(state):
    # Execute a sample SQL query.
    query_result = db.run("SELECT * FROM Artist LIMIT 10;")
    # Wrap the query result in an AIMessage and return it.
    return {"messages": [AIMessage(content=query_result)]}

# Node function that calls the language model.
def call_model(state):
    # Invoke the model using the current messages in the state.
    response = model.invoke(state["messages"])
    # Return the model's response encapsulated in a list.
    return {"messages": [response]}

# Build the graph.
builder = StateGraph(AgentState)

# Add the 'query_database' node with a custom retry policy.
builder.add_node(
    "query_database",
    query_database,
    retry=RetryPolicy(
        # Retry only if a sqlite3.OperationalError occurs.
        retry_on=sqlite3.OperationalError,
    ),
)

# Add the 'model' node with a retry policy that allows up to 5 attempts.
builder.add_node(
    "model",
    call_model,
    retry=RetryPolicy(
        max_attempts=5,  # Increase the maximum retry attempts.
    ),
)

# Define the flow of the graph:
# - Start with the model node,
# - then move to the query_database node,
# - and finally end the graph.
builder.add_edge(START, "model")
builder.add_edge("model", "query_database")
builder.add_edge("query_database", END)

# Compile the graph into an executable application.
graph = builder.compile()
```

---

## 🔍 Detailed Code Walkthrough

### 1. Importing Libraries and Setting Up the Environment

```python
import operator
import sqlite3
from typing import Annotated, Sequence
from typing_extensions import TypedDict
```

- **`operator`**: Used for merging messages from multiple nodes.
- **`sqlite3`**: Imported to specify which errors (e.g., `sqlite3.OperationalError`) should trigger a retry.
- **`typing` & `TypedDict`**: Used for defining the state structure.

### 2. Model and Database Setup

```python
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import BaseMessage
from langgraph.graph import END, StateGraph, START
from langchain_community.utilities import SQLDatabase
from langchain_core.messages import AIMessage
from langgraph.pregel import RetryPolicy

db = SQLDatabase.from_uri("sqlite:///:memory:")
model = ChatAnthropic(model_name="claude-2.1")
```

- **`ChatAnthropic`**: Initializes the language model.
- **`SQLDatabase.from_uri(...)`**: Creates an in-memory SQLite database.
- **`RetryPolicy`**: Imported for configuring retry behavior.

### 3. Defining the Graph State

```python
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
```

- **`AgentState`**: Defines our graph's state with a single key `messages` which holds a sequence of messages.  
- **`operator.add`**: Used to merge messages from different nodes seamlessly.

### 4. Defining Node Functions

#### a. Database Query Node

```python
def query_database(state):
    query_result = db.run("SELECT * FROM Artist LIMIT 10;")
    return {"messages": [AIMessage(content=query_result)]}
```

- **Purpose**: Executes an SQL query to fetch data from the `Artist` table.
- **Returns**: Wraps the result in an `AIMessage` and returns it as part of the state.

#### b. Language Model Node

```python
def call_model(state):
    response = model.invoke(state["messages"])
    return {"messages": [response]}
```

- **Purpose**: Invokes the language model with the current state messages.
- **Returns**: The response from the model as a new message.

### 5. Adding Nodes with Retry Policies

```python
builder.add_node(
    "query_database",
    query_database,
    retry=RetryPolicy(
        retry_on=sqlite3.OperationalError,
    ),
)
```

- **`add_node`**: Adds the `query_database` node.
- **`retry=RetryPolicy(...)`**:  
  - Configures a retry policy that will only retry if a `sqlite3.OperationalError` is raised.
  
```python
builder.add_node(
    "model",
    call_model,
    retry=RetryPolicy(
        max_attempts=5,
    ),
)
```

- **Node 'model'**:  
  - The retry policy here sets `max_attempts` to 5, meaning if the model call fails, it will retry up to 5 times.

### 6. Defining Graph Flow and Compiling

```python
builder.add_edge(START, "model")
builder.add_edge("model", "query_database")
builder.add_edge("query_database", END)
graph = builder.compile()
```

- **Edges**:  
  - Connect the start of the graph to the model node.
  - Connect the model node to the query_database node.
  - Connect the query_database node to the end.
- **Compile**:  
  - `builder.compile()` transforms the graph definition into an executable application.

---

## 🌍 Real-World Example: API Calls in a Microservice

Imagine you have a microservice that needs to fetch data from an external API. External APIs can be unpredictable due to network issues or server load. By using a retry policy, your service can automatically retry the API call if it fails due to a temporary error (like a 500 Internal Server Error). This ensures better resilience and reliability in production environments without manual intervention.

---

## 💡 Key Takeaways

- **Retry Policies**:  
  Allow nodes to automatically re-attempt operations on failure, which is essential when dealing with unreliable external systems.

- **Configuration Flexibility**:  
  You can tailor the retry behavior (number of attempts, intervals, backoff, etc.) to match the characteristics of the service you’re interacting with.

- **Resilience in Production**:  
  Implementing retry logic makes your applications more robust and improves user experience by reducing transient errors.

By mastering node retry policies, you can build more reliable and fault-tolerant workflows in LangGraph.

Happy coding!