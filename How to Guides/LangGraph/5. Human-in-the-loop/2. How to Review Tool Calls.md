# 2. How to Review Tool Calls

# 2. How to Review Tool Calls 🔍

In agentic systems, **Human-in-the-loop (HIL)** interactions are essential to ensure that automated actions are safe and correct. One common pattern is reviewing **tool calls** before executing them. A tool call might represent actions like executing SQL queries or generating summaries. With human review, you have options to:

- **Approve** the tool call and continue.
- **Modify** the tool call manually before continuing.
- Provide **natural language feedback** and then pass that back to the agent.

We can achieve this using LangGraph’s `interrupt()` function to pause execution, let a human review and respond, and then resume with the appropriate action.

---

## 🎯 Real-World Example

Imagine a financial application that generates SQL commands to update account balances. Before executing any SQL command, a supervisor can review the command. They can:
- Approve it to execute the SQL,
- Update the command if there are errors, or
- Provide feedback (e.g., “Double-check the amount”) to adjust the automated reasoning.

This extra layer of human validation can prevent costly mistakes in critical systems.

---

## 🛠️ Code Walkthrough

Below is a detailed code example with explanations for each part. We’ll create a node called `human_review_node` that handles reviewing tool calls.

### Code Example with Detailed Explanations

```python
def human_review_node(state) -> Command[Literal["call_llm", "run_tool"]]:
    # Retrieve the last message from the conversation history.
    # This is typically an AI message that contains one or more tool calls.
    last_message = state["messages"][-1]
    
    # Extract the last tool call from the message for review.
    tool_call = last_message.tool_calls[-1]

    # Pause execution and ask the human to review the tool call.
    # The `interrupt()` function stops the graph and collects human input.
    human_review = interrupt(
        {
            "question": "Is this correct?",
            # Include the tool call details so the human can review it.
            "tool_call": tool_call,
        }
    )

    # The human response is expected to include an "action" and optionally "data".
    review_action = human_review["action"]
    review_data = human_review.get("data")

    # If the human approves the tool call:
    if review_action == "continue":
        # Resume execution by going to the "run_tool" node.
        return Command(goto="run_tool")

    # If the human wants to update the tool call manually:
    elif review_action == "update":
        # Create an updated AI message that includes the human-provided changes.
        updated_message = {
            "role": "ai",
            "content": last_message.content,
            "tool_calls": [
                {
                    "id": tool_call["id"],
                    "name": tool_call["name"],
                    # Replace the original arguments with the updated data.
                    "args": review_data,
                }
            ],
            # It's crucial that the ID remains the same to update the existing message.
            "id": last_message.id,
        }
        # Resume execution, sending the updated message.
        return Command(goto="run_tool", update={"messages": [updated_message]})

    # If the human provides natural language feedback:
    elif review_action == "feedback":
        # Create a tool message with the feedback.
        tool_message = {
            "role": "tool",
            # The human's natural language feedback.
            "content": review_data,
            "name": tool_call["name"],
            "tool_call_id": tool_call["id"],
        }
        # Resume by sending the feedback back to the LLM for further processing.
        return Command(goto="call_llm", update={"messages": [tool_message]})
```

---

### Line-by-Line Explanation

1. **Function Definition:**
   ```python
   def human_review_node(state) -> Command[Literal["call_llm", "run_tool"]]:
   ```
   - **Purpose:** Define a node that reviews a tool call.
   - **Return Type:** A command directing the graph to either call the LLM again or run the tool.

2. **Retrieve the Last Message:**
   ```python
   last_message = state["messages"][-1]
   ```
   - **Purpose:** Get the most recent message from the conversation history, which contains tool calls.

3. **Extract the Tool Call:**
   ```python
   tool_call = last_message.tool_calls[-1]
   ```
   - **Purpose:** Focus on the last tool call within the message for review.

4. **Interrupt to Request Human Review:**
   ```python
   human_review = interrupt(
       {
           "question": "Is this correct?",
           "tool_call": tool_call,
       }
   )
   ```
   - **Purpose:** Pause execution and ask the human to review the tool call.
   - **Details:** The interrupt passes a question and the tool call details to the human interface.

5. **Extract Human Response:**
   ```python
   review_action = human_review["action"]
   review_data = human_review.get("data")
   ```
   - **Purpose:** Capture what the human decides: continue, update, or provide feedback.
   - **`review_data`:** Contains any modifications or feedback provided by the human.

6. **Decision Branches:**
   - **Approve and Continue:**
     ```python
     if review_action == "continue":
         return Command(goto="run_tool")
     ```
     - **Purpose:** If approved, instruct the graph to proceed with running the tool.
   - **Update the Tool Call:**
     ```python
     elif review_action == "update":
         updated_message = {
             "role": "ai",
             "content": last_message.content,
             "tool_calls": [
                 {
                     "id": tool_call["id"],
                     "name": tool_call["name"],
                     "args": review_data,
                 }
             ],
             "id": last_message.id,
         }
         return Command(goto="run_tool", update={"messages": [updated_message]})
     ```
     - **Purpose:** If the human updates the tool call, modify the existing message with new arguments.
     - **Key Point:** The message ID is kept the same to replace the original message.
   - **Provide Feedback:**
     ```python
     elif review_action == "feedback":
         tool_message = {
             "role": "tool",
             "content": review_data,
             "name": tool_call["name"],
             "tool_call_id": tool_call["id"],
         }
         return Command(goto="call_llm", update={"messages": [tool_message]})
     ```
     - **Purpose:** If feedback is provided, send that feedback as a tool message back to the LLM.
     - **Why:** The LLM can then adjust its subsequent responses based on this natural language input.

---

## 🧩 Integrating into a Workflow

Below is a simplified example of a complete workflow using LangGraph. In this example, after calling the LLM, the agent reviews the tool call with the human before either running the tool or feeding back to the LLM.

### Complete Example

```python
from typing_extensions import TypedDict, Literal
from langgraph.graph import StateGraph, START, END, MessagesState
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, interrupt
from langchain_anthropic import ChatAnthropic
from langchain_core.tools import tool
from langchain_core.messages import AIMessage
from IPython.display import Image, display

# Define a tool to search for weather.
@tool
def weather_search(city: str):
    """Search for the weather"""
    print("----")
    print(f"Searching for: {city}")
    print("----")
    return "Sunny!"

# Bind the tool to our chat model.
model = ChatAnthropic(model_name="claude-3-5-sonnet-latest").bind_tools(
    [weather_search]
)

# Define a simple state to hold messages.
class State(MessagesState):
    """Simple state."""

# Node: Call the LLM with current messages.
def call_llm(state):
    return {"messages": [model.invoke(state["messages"])]}

# Node: Review the tool call with human input.
def human_review_node(state) -> Command[Literal["call_llm", "run_tool"]]:
    last_message = state["messages"][-1]
    tool_call = last_message.tool_calls[-1]

    human_review = interrupt(
        {
            "question": "Is this correct?",
            "tool_call": tool_call,
        }
    )

    review_action = human_review["action"]
    review_data = human_review.get("data")

    if review_action == "continue":
        return Command(goto="run_tool")
    elif review_action == "update":
        updated_message = {
            "role": "ai",
            "content": last_message.content,
            "tool_calls": [
                {
                    "id": tool_call["id"],
                    "name": tool_call["name"],
                    "args": review_data,
                }
            ],
            "id": last_message.id,
        }
        return Command(goto="run_tool", update={"messages": [updated_message]})
    elif review_action == "feedback":
        tool_message = {
            "role": "tool",
            "content": review_data,
            "name": tool_call["name"],
            "tool_call_id": tool_call["id"],
        }
        return Command(goto="call_llm", update={"messages": [tool_message]})

# Node: Run the tool based on the (possibly updated) tool call.
def run_tool(state):
    new_messages = []
    tools = {"weather_search": weather_search}
    tool_calls = state["messages"][-1].tool_calls
    for tool_call in tool_calls:
        tool = tools[tool_call["name"]]
        result = tool.invoke(tool_call["args"])
        new_messages.append(
            {
                "role": "tool",
                "name": tool_call["name"],
                "content": result,
                "tool_call_id": tool_call["id"],
            }
        )
    return {"messages": new_messages}

# Node: Decide the next step after LLM invocation.
def route_after_llm(state) -> Literal[END, "human_review_node"]:
    if len(state["messages"][-1].tool_calls) == 0:
        return END
    else:
        return "human_review_node"

# Build the graph with nodes and edges.
builder = StateGraph(State)
builder.add_node(call_llm)
builder.add_node(run_tool)
builder.add_node(human_review_node)
builder.add_edge(START, "call_llm")
builder.add_conditional_edges("call_llm", route_after_llm)
builder.add_edge("run_tool", "call_llm")

# Set up memory for the state.
memory = MemorySaver()

# Compile the graph into a runnable application.
graph = builder.compile(checkpointer=memory)

# Display the workflow diagram.
display(Image(graph.get_graph().draw_mermaid_png()))
```

---

## ✅ Summary

- **Reviewing Tool Calls:**  
  - A human can approve, update, or provide feedback on automated tool calls.
  - This ensures actions (like SQL execution or weather searches) are verified before proceeding.

- **Key Techniques:**  
  - **Interrupting Execution:** Use `interrupt()` to pause the workflow and request human input.
  - **Command Patterns:** Based on human feedback, return commands to either run the tool or adjust the LLM call.
  - **State Management:** Update the message history with either an updated tool call or feedback message.

- **Real-World Use:**  
  - In financial applications, reviewing transaction commands before execution can prevent errors.
  - In healthcare, reviewing diagnostic suggestions before acting can safeguard patient care.

This approach makes your system both robust and flexible, ensuring that automated processes are enhanced by timely human oversight.

---
# Example with No Review 📄

In some cases, the agent’s process doesn’t involve any tool calls that require human review. In these cases, the conversation flows directly without any interruption for human feedback.

---

## 🔍 What’s Happening?

- **Input:** A simple user message (`"hi!"`) is provided.
- **Process:** The agent receives the message, processes it through its language model, and responds accordingly.
- **Outcome:** Since no tool calls are involved (e.g., no weather lookup), the conversation finishes without any need for human intervention.

---

## 💻 Code Example

```python
# Input: A basic message from the user.
initial_input = {"messages": [{"role": "user", "content": "hi!"}]}

# Thread: Configuration that helps the system track this conversation.
thread = {"configurable": {"thread_id": "1"}}

# Running the graph until its execution is complete.
for event in graph.stream(initial_input, thread, stream_mode="updates"):
    print(event)
    print("\n")
```

### Line-by-Line Explanation

- **`initial_input`**:  
  - This dictionary contains a key `"messages"`, which is a list of message objects.
  - Here, we provide one message from the user with the content `"hi!"`.

- **`thread`**:  
  - This dictionary sets up the configuration for the conversation, assigning it a unique thread ID (`"1"`).
  - Thread IDs help the agent maintain state between interactions.

- **`for event in graph.stream(...):`**:  
  - This loop runs the graph (the agent's workflow) using the provided `initial_input` and `thread`.
  - `stream_mode="updates"` ensures that the graph outputs intermediate updates.
  - Each `event` printed shows the progress of the conversation.
  
- **Output:**  
  - The printed event is a dictionary with a key like `'call_llm'` containing an AI message.
  - Example output (abbreviated):
    ```python
    {'call_llm': {'messages': [AIMessage(content="Hello! I'm here to help you. ...", ...)]}}
    ```
  - Since no tool call was made, the conversation state is complete.

---

## Real-World Example

**Chatbot Greeting:**  
Imagine a customer support chatbot that simply greets a user when they start a conversation. If the user says "hi!", the bot replies with a greeting without needing to perform any additional actions (like checking account details), so no review step is needed.

---

# Example of Approving Tool Call ✅

Now, let’s see a case where a tool call is made and requires human review before execution.

---

## 🔍 What’s Happening?

- **Input:** The user asks, `"what's the weather in sf?"`.
- **Process:**
  1. The agent processes the input and calls the language model, which generates a response that includes a tool call.
  2. The tool call in this example is for the weather search tool, designed to look up the weather.
  3. Before executing the tool call, the system pauses and waits for human review.
- **Outcome:**  
  - The human reviews the tool call.
  - In this example, the human approves it by indicating `"continue"`.
  - The agent then proceeds to execute the tool, fetches the weather data, and resumes the conversation.

---

## 💻 Code Example: Initiating the Tool Call

```python
# Input: User asks about the weather in San Francisco.
initial_input = {"messages": [{"role": "user", "content": "what's the weather in sf?"}]}

# Thread: Setting a unique thread ID for this conversation.
thread = {"configurable": {"thread_id": "2"}}

# Running the graph to process the input and generate tool calls.
for event in graph.stream(initial_input, thread, stream_mode="updates"):
    print(event)
    print("\n")
```

### Explanation of the Above Code

- **`initial_input`**:  
  - The message from the user is now a question about the weather in San Francisco (`"sf"`).
  
- **`thread`**:  
  - A different thread ID (`"2"`) is used to separate this conversation from the previous one.

- **Graph Execution:**  
  - As the graph runs, it processes the input.
  - The agent calls the language model (LLM) which generates a response that includes a tool call for `weather_search`.

- **Output Example:**  
  - The output includes:
    - An AI message: `"I'll help you check the weather in San Francisco."`
    - A tool call object for `weather_search` with parameters like `{'city': 'sf'}`.
  - The system then pauses with an **interrupt**, waiting for human review:
    ```python
    {'__interrupt__': (Interrupt(value={'question': 'Is this correct?', 'tool_call': {...}}, resumable=True, ...),)}
    ```
  - The graph state now indicates it is waiting for review:
    ```python
    print(graph.get_state(thread).next)
    # Output: ('human_review_node',)
    ```

---

## 💻 Code Example: Approving the Tool Call

Once the agent is waiting for human review, we need to approve the tool call so that it can proceed.

```python
from langgraph.types import Command

# Approving the tool call by providing a resume command.
for event in graph.stream(
    Command(resume={"action": "continue"}),
    thread,
    stream_mode="updates",
):
    print(event)
    print("\n")
```

### Line-by-Line Explanation

- **`Command(resume={"action": "continue"})`**:
  - This command tells the agent to approve the tool call.
  - The value `{"action": "continue"}` indicates that the human review is approved as-is.
  
- **Graph Execution:**  
  - When the graph receives this command, it resumes from the human review node.
  - The agent then executes the `run_tool` node, which calls the `weather_search` tool with the provided parameters.
  
- **Output:**
  - You will see an output message like:
    ```python
    {'human_review_node': None}
    ----
    Searching for: sf
    ----
    {'run_tool': {'messages': [{'role': 'tool', 'name': 'weather_search', 'content': 'Sunny!', 'tool_call_id': 'toolu_...'}]}}
    ```
  - Finally, the agent resumes with another LLM call, providing the final message:
    ```python
    {'call_llm': {'messages': [AIMessage(content="According to the search, it's sunny in San Francisco today!", ...)]}}
    ```

---

## Real-World Example

**Weather Chatbot with Approval:**  
Consider a weather chatbot used in a critical environment (like an airport information system). Before the system retrieves weather data via an automated tool call:
- A human supervisor may review the request (for example, to ensure that location data is accurate).
- Once approved (or modified if necessary), the tool call executes, and the user receives the accurate weather update.
- This extra layer of validation helps prevent errors due to misinterpretation of location or data.

---

## ✅ Summary

- **No Review Scenario:**  
  - **Process:** The agent processes a simple message without any tool calls, leading to a direct response.
  - **Use-Case:** Simple greetings or basic inquiries where no external data retrieval is necessary.

- **Tool Call with Review:**  
  - **Process:**  
    1. The agent generates a response that includes a tool call.
    2. The system pauses for human review.
    3. The human approves the tool call.
    4. The tool call is executed, and the final response is generated.
  - **Use-Case:** Critical applications (e.g., financial systems, healthcare, or weather updates in dynamic environments) where human oversight is needed to ensure data accuracy and safety.

- **Key Techniques:**
  - **Interrupting Execution:**  
    - Using `interrupt()` pauses the graph for human feedback.
  - **Resuming Execution:**  
    - A command with `Command(resume=...)` is used to approve or update the tool call.
  - **State Management:**  
    - The conversation state is maintained and updated based on human input, ensuring robust and dynamic interactions.

This design allows the system to blend automated responses with human oversight, making it both efficient and reliable for real-world applications.

---
# Edit Tool Call ✏️

In many agentic systems, it is sometimes necessary to **edit a tool call** before it executes. This allows a human to modify parameters (or even change the tool being called) based on the context or additional information. For example, if the agent initially calls a weather lookup tool with `"sf"`, a human reviewer may decide to change this to `"San Francisco, USA"` for more accuracy.

Below, we’ll walk through an example of editing a tool call, explain each code snippet in detail, and then show how this concept is applied in real-world scenarios.

---

## 🔧 What Is an "Edit Tool Call"?

- **Definition:**  
  An edit tool call allows a human reviewer to update the arguments of a tool call before it is executed.  
- **Why is it useful?**  
  It gives an opportunity to fix or enhance the parameters, ensuring the tool executes with the correct data.  
- **Real-World Example:**  
  In a travel assistant app, if a user says "What's the weather in sf?", a human reviewer might update the location to "San Francisco, USA" to remove ambiguity.

---

## 💻 Code Example: Editing a Tool Call

Below is a code snippet that demonstrates the process. We start with an initial input, let the agent create a tool call for weather lookup, and then we update the call through human review.

### Step 1: Running the Graph Until the Tool Call Is Created

```python
# Input: User asks about the weather in SF.
initial_input = {"messages": [{"role": "user", "content": "what's the weather in sf?"}]}

# Thread: Unique configuration for this conversation.
thread = {"configurable": {"thread_id": "3"}}

# Run the graph until the tool call is generated and then interrupted for review.
for event in graph.stream(initial_input, thread, stream_mode="updates"):
    print(event)
    print("\n")
```

**Explanation:**
- **Initial Input:**  
  A message is provided where the user asks, "what's the weather in sf?"
- **Thread Configuration:**  
  A unique `thread_id` of `"3"` is set so that this conversation is tracked separately.
- **Graph Execution:**  
  The graph runs, processing the message and creating an AI response that includes a tool call to `weather_search` with parameters `{'city': 'sf'}`.
- **Interruption:**  
  The execution stops with an interrupt, waiting at the `human_review_node` for a human review.

**Sample Output:**

```python
{'call_llm': {'messages': [AIMessage(...)]}}
{'__interrupt__': (Interrupt(value={'question': 'Is this correct?', 'tool_call': {'name': 'weather_search', 'args': {'city': 'sf'}, 'id': 'toolu_013eUXow3jwM6eekcDJdrjDa', 'type': 'tool_call'}}, ...),)}
print("Pending Executions!")
print(graph.get_state(thread).next)
# Output: ('human_review_node',)
```

---

## 💻 Code Example: Editing the Tool Call

Once the graph is waiting for human review, we update the tool call with new parameters.

```python
from langgraph.types import Command

# Resume the graph with an update command: change city to "San Francisco, USA"
for event in graph.stream(
    Command(resume={"action": "update", "data": {"city": "San Francisco, USA"}}),
    thread,
    stream_mode="updates",
):
    print(event)
    print("\n")
```

**Explanation:**
- **Command with Update:**  
  We use `Command(resume={"action": "update", "data": {"city": "San Francisco, USA"}})` to signal that we want to update the existing tool call.
  - `"action": "update"` tells the system that the human is providing an update.
  - `"data": {"city": "San Francisco, USA"}` contains the new arguments for the tool call.
- **Graph Execution:**  
  The human review node combines the original tool call with the new arguments, updates the AI message, and then resumes execution by moving to the `run_tool` node.
- **Output:**  
  The updated tool call now has the parameter `{"city": "San Francisco, USA"}`, and when executed, it runs the `weather_search` tool with the corrected location.

**Sample Output:**

```python
{'human_review_node': {'messages': [{'role': 'ai', 'content': [...], 'tool_calls': [{'id': 'toolu_013eUXow3jwM6eekcDJdrjDa', 'name': 'weather_search', 'args': {'city': 'San Francisco, USA'}}], ...}]}}
---- 
Searching for: San Francisco, USA
----
{'run_tool': {'messages': [{'role': 'tool', 'name': 'weather_search', 'content': 'Sunny!', 'tool_call_id': 'toolu_013eUXow3jwM6eekcDJdrjDa'}]}}
{'call_llm': {'messages': [AIMessage(content="According to the search, it's sunny in San Francisco right now!", ...)]}}
```

---

## 🔍 Real-World Application of Editing Tool Calls

**Scenario:**  
In a customer service system for a travel website, a chatbot initially receives vague location data (e.g., "NY"). A human reviewer can update the tool call to change "NY" to "New York, USA" to ensure that the subsequent weather lookup or flight search is performed accurately. This prevents errors and improves the accuracy of responses, leading to better customer satisfaction.

---

# Give Feedback to a Tool Call 💬

Sometimes, rather than editing a tool call, a human reviewer might want to provide **natural language feedback**. This feedback is then used to guide the agent to adjust its actions without manually modifying the tool call parameters.

---

## 🔧 What Is "Feedback to a Tool Call"?

- **Definition:**  
  It’s a process where the human reviewer gives a feedback message that serves as a proxy result for the tool call.
- **Why Use It?**  
  This approach is useful when the reviewer wants to provide insights or additional context rather than making specific parameter edits.
- **Real-World Example:**  
  In an e-commerce chatbot, if a tool call to fetch product details is made and the response is ambiguous, a reviewer might provide feedback like, "Please check the product description for more clarity," which the agent then uses to refine its next actions.

---

## 💻 Code Example: Providing Feedback to a Tool Call

Below is a code snippet that demonstrates giving feedback to a tool call. The process is similar to editing, but instead of updating parameters, we inject a natural language feedback message.

### Step 1: Run the Graph Until Interruption

```python
# Input: User asks about the weather in SF.
initial_input = {"messages": [{"role": "user", "content": "what's the weather in sf?"}]}

# Thread: Unique configuration for this conversation.
thread = {"configurable": {"thread_id": "4"}}

# Run the graph until it pauses for human review.
for event in graph.stream(initial_input, thread, stream_mode="updates"):
    print(event)
    print("\n")
```

**Explanation:**
- The setup is similar to the previous example, but with a different thread ID (`"4"`).
- The graph generates a tool call and then pauses for review.

**Sample Output:**

```python
{'call_llm': {'messages': [AIMessage(...)]}}
{'__interrupt__': (Interrupt(value={'question': 'Is this correct?', 'tool_call': {'name': 'weather_search', 'args': {'city': 'sf'}, 'id': 'toolu_01QxXNTCasnNLQCGAiVoNUBe', 'type': 'tool_call'}}, ...),)}
print("Pending Executions!")
print(graph.get_state(thread).next)
# Output: ('human_review_node',)
```

---

### Step 2: Provide Feedback Instead of Updating

```python
# Resume the graph by providing natural language feedback.
for event in graph.stream(
    Command(
        resume={
            "action": "feedback",
            "data": "User requested changes: use <city, country> format for location"
        }
    ),
    thread,
    stream_mode="updates",
):
    print(event)
    print("\n")
```

**Explanation:**
- **Command with Feedback:**  
  We use `Command(resume={"action": "feedback", "data": <feedback message>})`.
  - `"action": "feedback"` tells the system that the reviewer is providing natural language feedback.
  - `"data": "User requested changes: use <city, country> format for location"` contains the feedback text.
- **Graph Execution:**  
  The human review node creates a new tool message that merges the original tool call with the feedback. This new message is then passed back to the LLM by transitioning to the `call_llm` node.
- **Output:**  
  The graph displays a tool message with the feedback, and then the LLM is invoked again with this feedback incorporated into the conversation.

**Sample Output:**

```python
{'human_review_node': {'messages': [{'role': 'tool', 'content': 'User requested changes: use <city, country> format for location', 'name': 'weather_search', 'tool_call_id': 'toolu_01QxXNTCasnNLQCGAiVoNUBe'}]}}
{'call_llm': {'messages': [AIMessage(content=[{'text': 'Let me try again with the full city name.', 'type': 'text'}, {'id': 'toolu_01WBGTKBWusaPNZYJi5LKmeQ', 'input': {'city': 'San Francisco, USA'}, 'name': 'weather_search', 'type': 'tool_use'}], ...)]}}
```

The graph then pauses again for review on the new tool call. Finally, by approving the new tool call, the tool is executed and the final response is generated.

---

## 🔍 Real-World Application of Feedback

**Scenario:**  
In a healthcare assistant system, if a tool call retrieves patient data but the response seems ambiguous, a medical reviewer might not know exactly how to adjust the parameters. Instead, they can provide feedback like, "The patient’s condition seems to be chronic rather than acute; please verify the diagnosis." This feedback is then processed by the agent to refine its next actions or queries.

---

## ✅ Summary

- **Edit Tool Call:**  
  - **Purpose:** Allows human reviewers to update tool call parameters before execution.  
  - **Example:** Changing `"sf"` to `"San Francisco, USA"` for more precise weather data.
  - **Process:**  
    1. The graph pauses with an interrupt.
    2. A resume command with `{"action": "update", "data": {...}}` is sent.
    3. The graph updates the tool call and resumes execution.

- **Give Feedback to a Tool Call:**  
  - **Purpose:** Enables reviewers to provide natural language feedback instead of directly modifying the call.  
  - **Example:** "User requested changes: use <city, country> format for location."
  - **Process:**  
    1. The graph pauses with an interrupt.
    2. A resume command with `{"action": "feedback", "data": <feedback message>}` is sent.
    3. The feedback is added as a tool message, and the agent re-invokes the LLM with the updated context.

This flexible approach ensures that your agentic system can either directly update tool calls or incorporate human feedback to refine its behavior, making it robust and adaptable for real-world applications.