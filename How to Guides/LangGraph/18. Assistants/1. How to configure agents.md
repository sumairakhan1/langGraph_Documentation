# 1. How to create agents with configuration

# Understanding Assistants and Their Configuration

In this article, we will dive deep into the concept of **Assistants** within the LangGraph API and how they can be configured to perform various tasks. We will explain the concept step by step in a beginner-friendly manner, with examples to help you understand how you can use these configurations in the real world.

## üéØ What Are Assistants?

Assistants are basically **customizable agents** created from a template. These agents are designed to perform specific tasks or respond to user inputs, much like virtual assistants (e.g., Siri, Alexa). However, in the context of LangGraph, they are much more flexible and configurable.

### Why Use Assistants?
- **Cognitive Architecture:** You can define a general architecture for your assistant once and reuse it in different scenarios.
- **Configuration Flexibility:** You can easily change certain aspects of the assistant, like which **model** it uses or what kind of responses it provides, by just tweaking configurations.
- **Future Use:** You can save these configured assistants and use them again in the future, making it easier to deploy them in new situations.

### Real World Example
Think about a customer service chatbot for an online store. You could have an assistant configured to respond using a specific model, say OpenAI‚Äôs GPT model for handling queries about product details, or another model for handling return requests. These configurations allow you to switch between different AI providers or configurations as per your needs.

---

## ‚öôÔ∏è How to Create and Configure Agents

### Step 1: Define Your Cognitive Architecture

You first define a basic architecture for the assistant. This architecture could be anything from simple text responses to complex decision-making processes. Here is an example of how you might define an assistant's architecture:

```python
def call_model(state, config):
    messages = state["messages"]
    model_name = config.get('configurable', {}).get("model_name", "anthropic")
    model = _get_model(model_name)
    response = model.invoke(messages)
    return {"messages": [response]}
```

In this example, the assistant is set to call a model based on the configuration provided. By default, it uses the **Anthropic** model, but you can change this to **OpenAI** or any other model by modifying the configuration.

---

### Step 2: Initialize Your Assistant

Now that you've defined the structure of your assistant, you can initialize it using **LangGraph SDK**. Here's how you can get started:

```python
from langgraph_sdk import get_client

client = get_client(url=<DEPLOYMENT_URL>)
assistants = await client.assistants.search()
assistant = [a for a in assistants if not a["config"]][0]
```

This snippet initializes a client to interact with LangGraph, and then it searches for assistants that have not been configured yet.

---

### Step 3: Access the Config Schema

Before configuring an assistant, you may want to see what parameters can be modified. You can fetch the schema of the assistant‚Äôs configuration, which tells you what attributes can be changed.

```python
schemas = await client.assistants.get_schemas(
    assistant_id=assistant["assistant_id"]
)
print(schemas["config_schema"])
```

Example output:
```json
{
    'model_name': {
        'title': 'Model Name',
        'enum': ['anthropic', 'openai'],
        'type': 'string'
    }
}
```

This output shows that the **model_name** parameter can either be **"anthropic"** or **"openai"**, and it is of type string.

---

### Step 4: Configure the Assistant

Now that you know what configurations are available, you can create a new assistant with specific settings. For example, let‚Äôs create an assistant that uses OpenAI instead of Anthropic:

```python
openai_assistant = await client.assistants.create(
    "agent", config={"configurable": {"model_name": "openai"}}
)

print(openai_assistant)
```

The assistant now uses the **OpenAI** model to generate responses. You can see in the output that the configuration has been applied correctly.

---

### Step 5: Verify the Configuration

To check if the configuration is working, you can test the assistant by sending a message and seeing the response.

```python
thread = await client.threads.create()
input = {"messages": [{"role": "user", "content": "who made you?"}]}
async for event in client.runs.stream(
    thread["thread_id"],
    openai_assistant["assistant_id"],
    input=input,
    stream_mode="updates",
):
    print(f"Receiving event of type: {event.event}")
    print(event.data)
```

This will print the assistant‚Äôs responses, and you can verify if the correct model (OpenAI) is being used to generate the response.

---

## üåç Real World Use Case: Chatbots in Customer Support

One of the most common use cases of assistants like this is **chatbots** for customer service. Imagine you're running an e-commerce website, and you want your customers to get instant help when they have questions. By using a configurable assistant, you can:

- Choose the model (e.g., OpenAI‚Äôs GPT) that suits your needs.
- Create a personalized response based on the user‚Äôs queries.
- Switch between different AI providers to optimize response quality or cost.

### Example:
- **Customer Query:** "What is the status of my order?"
- **Assistant's Response:** Using the OpenAI model, the assistant could pull the customer‚Äôs order status from the backend and respond with something like, "Your order is being processed and will be shipped tomorrow."

---

## üõ†Ô∏è Benefits of Using Configurable Assistants

- **Flexibility:** You can change the assistant‚Äôs behavior by modifying configuration parameters.
- **Scalability:** You can easily deploy different assistants for different tasks (e.g., sales, support, etc.).
- **Future-Proof:** Save and reuse configured assistants, making it easier to manage them over time.

## Conclusion

Assistants provide a powerful way to build and deploy intelligent agents that can interact with users in a variety of ways. By configuring these assistants with different parameters, you can customize their behavior to suit specific needs. Whether it's for customer support, content generation, or any other task, configurable assistants can be an invaluable tool in the world of AI.